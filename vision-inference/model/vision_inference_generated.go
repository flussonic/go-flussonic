// Code generated by cmd/main. DO NOT EDIT.
package model

// base64
type Base64 string

// bytes
type Bytes int

// hexbinary
type Hexbinary string

// media_name
type MediaName string

// milliseconds
type Milliseconds int

// network_port
type NetworkPort int

// server_version
type ServerVersion string

// snowflake_id
type SnowflakeID int

// url
type URL string

// uuid
type UUID string

// Unix timestamp in seconds
type Utc int

// Unix timestamp in milliseconds
type UtcMs int

// The algorithm used for video analytics.
type VisionSpecAlg string

const (
	// The algorithm for face recognition is used.
	VisionSpecAlgFaces VisionSpecAlg = "faces"
	// The algorithm for license plate recognition is used.
	VisionSpecAlgPlates VisionSpecAlg = "plates"
)

type EpisodeCloseReason string

const (
	// Episode was closed because of no activity was detected in it.
	EpisodeCloseReasonTimeout EpisodeCloseReason = "timeout"
)

type StreamStatus string

const (
	// Input is OK, stream is ready to be served to your audience.
	StreamStatusRunning StreamStatus = "running"
	// Flussonic awaits for input (publish) or it's an 'on demand' stream waiting for client.
	StreamStatusWaiting StreamStatus = "waiting"
	// Something is wrong and Flussonic is not able to serve the stream to your audience.
	StreamStatusError StreamStatus = "error"
)

type TlsVersion string

const (
	TlsVersionTlsv1  TlsVersion = "tlsv1"
	TlsVersionTlsv11 TlsVersion = "tlsv1.1"
	TlsVersionTlsv12 TlsVersion = "tlsv1.2"
	TlsVersionTlsv13 TlsVersion = "tlsv1.3"
)

type VisionDetector string

const (
	VisionDetectorFaces    VisionDetector = "faces"
	VisionDetectorVehicles VisionDetector = "vehicles"
	VisionDetectorMotion   VisionDetector = "motion"
	VisionDetectorQrCodes  VisionDetector = "qr-codes"
	VisionDetectorHumans   VisionDetector = "humans"
)

type VisionHardwareType string

const (
	// NVIDIA Jetson board
	VisionHardwareTypeJetson VisionHardwareType = "jetson"
	// CUDA-capable NVIDIA graphic card
	VisionHardwareTypeCuda VisionHardwareType = "cuda"
	// Generic CPU
	VisionHardwareTypeCpu VisionHardwareType = "cpu"
	// Vulkan
	VisionHardwareTypeVulkan VisionHardwareType = "vulkan"
)

type VisionImageMimetype string

const (
	// jpeg
	VisionImageMimetypeImageJpeg VisionImageMimetype = "image/jpeg"
)

// The level of logging according to event importance. Several values separated by comma.
type VisionLoglevel string

const (
	// Messages of all types are logged.
	VisionLoglevelDebug VisionLoglevel = "debug"
	// Log info messages.
	VisionLoglevelInfo VisionLoglevel = "info"
	// Log warnings.
	VisionLoglevelWarning VisionLoglevel = "warning"
	// Log errors.
	VisionLoglevelError VisionLoglevel = "error"
)

// Object class
type VisionObjectClass string

const (
	VisionObjectClassFace         VisionObjectClass = "face"
	VisionObjectClassLicensePlate VisionObjectClass = "license_plate"
	VisionObjectClassVehicle      VisionObjectClass = "vehicle"
	VisionObjectClassHuman        VisionObjectClass = "human"
)

type VisionPersonOriginator string

const (
	// Person is created by operator or external system via API.
	// For example, when you add the person in Watcher UI, it has `originator=api`.
	// But when you edit an automatically created person in UI, `originator=identification_service` remains.
	//
	VisionPersonOriginatorAPI VisionPersonOriginator = "api"
	// Person is created automatically by the Identification service
	// because no matching person was found in the persons database.
	//
	// The Identification service stores unrecognized persons and matches new episodes with them
	// in case if it becomes known who this is (i.e. if operator edits such person in UI to specify name).
	//
	VisionPersonOriginatorIdentificationService VisionPersonOriginator = "identification_service"
)

// Emergency type of the vehicle, e.g. ambulance, police, firetruck.
type VisionVehicleEmergencySubtype string

const (
	// ambulance car
	VisionVehicleEmergencySubtypeAmbulance VisionVehicleEmergencySubtype = "ambulance"
	// police car
	VisionVehicleEmergencySubtypePolice VisionVehicleEmergencySubtype = "police"
	// firetruck car
	VisionVehicleEmergencySubtypeFiretruck VisionVehicleEmergencySubtype = "firetruck"
)

// Shows from which side the vehicle was detected.
type VisionVehicleFacingSide string

const (
	// The vehicle was detected from the front.
	VisionVehicleFacingSideFront VisionVehicleFacingSide = "front"
	// The vehicle was detected from the rear.
	VisionVehicleFacingSideRear VisionVehicleFacingSide = "rear"
)

// The purpose of the vehicle, e.g. emergency or regular.
// Police, ambulance cars and firetrucks are being detected by the videoanalytics as `emergency`.
// Any other type of vehicle is marked as `regular`.
type VisionVehiclePurpose string

const (
	// Regular car
	VisionVehiclePurposeRegular VisionVehiclePurpose = "regular"
	// Emergency vehicle (police, ambulance or firetruck)
	VisionVehiclePurposeEmergency VisionVehiclePurpose = "emergency"
)

type CollectionResponse interface {
	// Estimated total number of records for the query (regardless of the cursors).
	// Example: 5
	EstimatedCount() *int
	// Estimated total number of records for the query (regardless of the cursors).
	// Example: 5
	SetEstimatedCount(int) CollectionResponse
	// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fZ3Q9MA==
	Next() *string
	// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fZ3Q9MA==
	SetNext(string) CollectionResponse
	// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
	Prev() *string
	// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
	SetPrev(string) CollectionResponse
	// An object with a list of different timings measured during this API call.
	Timing() any
	// An object with a list of different timings measured during this API call.
	SetTiming(any) CollectionResponse
}

type ConfigVision interface {
	// Key used for HTTP API authorization
	// Example: secret
	APIKey() *string
	// Key used for HTTP API authorization
	// Example: secret
	SetAPIKey(string) ConfigVision
	// External configuration backend settings
	ConfigExternal() VisionConfigExternal
	// External configuration backend settings
	SetConfigExternal(VisionConfigExternal) ConfigVision
	// Devices used for inference
	Devices() []VisionInferenceDevice
	// Devices used for inference
	SetDevices([]VisionInferenceDevice) ConfigVision
	// The configuration of network listeners
	Listeners() Listeners
	// The configuration of network listeners
	SetListeners(Listeners) ConfigVision
	// The level of logging according to event importance
	Loglevel() *VisionLoglevel
	// The level of logging according to event importance
	SetLoglevel(VisionLoglevel) ConfigVision
	// Server runtime stats
	Stats() ConfigVisionStats
	// Server runtime stats
	SetStats(ConfigVisionStats) ConfigVision
}

// Server runtime stats
type ConfigVisionStats interface {
	// Indicates which modules are enabled in the inference service
	AvailableModules() VisionContextSearchModule
	// Indicates which modules are enabled in the inference service
	SetAvailableModules(VisionContextSearchModule) ConfigVisionStats
	// Build version
	// Example: 235
	Build() *int
	// Build version
	// Example: 235
	SetBuild(int) ConfigVisionStats
	// Devices list available for running vision.
	Devices() []VisionDeviceInfo
	// Devices list available for running vision.
	SetDevices([]VisionDeviceInfo) ConfigVisionStats
	// Server's current timestamp
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.639337825e+12
	Now() *UtcMs
	// Server's current timestamp
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.639337825e+12
	SetNow(UtcMs) ConfigVisionStats
	// API schema revision implemented in this version of the server
	// Example: 5e5e91d8
	SchemaVersion() *string
	// API schema revision implemented in this version of the server
	// Example: 5e5e91d8
	SetSchemaVersion(string) ConfigVisionStats
	// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
	// Format: server_version (server_version)
	// Example: 21.12
	ServerVersion() *ServerVersion
	// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
	// Format: server_version (server_version)
	// Example: 21.12
	SetServerVersion(ServerVersion) ConfigVisionStats
	// Timestamp when this instance was started
	// Format: utc (Unix timestamp in seconds)
	// Example: 1.639337825e+09
	StartedAt() *Utc
	// Timestamp when this instance was started
	// Format: utc (Unix timestamp in seconds)
	// Example: 1.639337825e+09
	SetStartedAt(Utc) ConfigVisionStats
}

type CounterRecordsList interface {
	// Estimated total number of records for the query (regardless of the cursors).
	// Example: 5
	EstimatedCount() *int
	// Estimated total number of records for the query (regardless of the cursors).
	// Example: 5
	SetEstimatedCount(int) CounterRecordsList
	// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fZ3Q9MA==
	Next() *string
	// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fZ3Q9MA==
	SetNext(string) CounterRecordsList
	// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
	Prev() *string
	// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
	SetPrev(string) CounterRecordsList
	// The list of Counter records fetched according to the query parameters.
	Records() []VisionCounterRecord
	// The list of Counter records fetched according to the query parameters.
	SetRecords([]VisionCounterRecord) CounterRecordsList
	// An object with a list of different timings measured during this API call.
	Timing() any
	// An object with a list of different timings measured during this API call.
	SetTiming(any) CounterRecordsList
	// Collection returns the collection items
	Collection() []VisionCounterRecord
}

type Episode interface {
	// The reason for closing the episode.
	CloseReason() *EpisodeCloseReason
	// The reason for closing the episode.
	SetCloseReason(EpisodeCloseReason) Episode
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	ClosedAt() *UtcMs
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetClosedAt(UtcMs) Episode
	// Detections associated with this episode
	Detections() any
	// Detections associated with this episode
	SetDetections(any) Episode
	// The time when the episode appeared in the service relative to the server time.
	EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps
	// The time when the episode appeared in the service relative to the server time.
	SetEpisodeAppearanceTimestamps(EpisodeAppearanceTimestamps) Episode
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	EpisodeID() SnowflakeID
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	SetEpisodeID(SnowflakeID) Episode
	// Generic stream episode/Face is detected/Vehicle is detected/Human is detected/Episode matches context search text query/QR-code is detected/Custom episode type.
	// Use this field to define your own episode types when integrating custom analytics.
	// If episode type is not specified, episode will be saved with `generic` type.
	EpisodeType() *string
	// Generic stream episode/Face is detected/Vehicle is detected/Human is detected/Episode matches context search text query/QR-code is detected/Custom episode type.
	// Use this field to define your own episode types when integrating custom analytics.
	// If episode type is not specified, episode will be saved with `generic` type.
	SetEpisodeType(string) Episode
	// The fingerprint of the detected face
	Fingerprint() VisionFaceFingerprint
	// The fingerprint of the detected face
	SetFingerprint(VisionFaceFingerprint) Episode
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	FramePreview() *Base64
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	SetFramePreview(Base64) Episode
	// Indicates if no license plate is detected on this vehicle
	LicensePlateMissing() *bool
	// Indicates if no license plate is detected on this vehicle
	SetLicensePlateMissing(bool) Episode
	// Recognized vehicle's license plate number
	LicensePlateText() *string
	// Recognized vehicle's license plate number
	SetLicensePlateText(string) Episode
	// Maximum matching score between the text query and episode.
	// Examples: 0.2345
	MatchScore() *float64
	// Maximum matching score between the text query and episode.
	// Examples: 0.2345
	SetMatchScore(float64) Episode
	// List of matched persons with similarity metric.
	// Videoanalytics identification service enriches episode's data and fills this field
	// with the list of persons that are similar to the face detected in this episode.
	MatchedPersons() []VisionPersonMatch
	// List of matched persons with similarity metric.
	// Videoanalytics identification service enriches episode's data and fills this field
	// with the list of persons that are similar to the face detected in this episode.
	SetMatchedPersons([]VisionPersonMatch) Episode
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	SetMedia(MediaName) Episode
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	OpenedAt() UtcMs
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetOpenedAt(UtcMs) Episode
	// Raw data extracted from QR-code/Custom episode payload. Use this field to provide additional information about the episode.
	Payload() any
	// Raw data extracted from QR-code/Custom episode payload. Use this field to provide additional information about the episode.
	SetPayload(any) Episode
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// /Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Preview contains an image of person's face and has a resolution about 200 x 200 pixels with maximum size about 10 kilobytes.
	// /Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Preview contains an image of vehicle's license plate and has a resolution about 160 x 64 pixels with maximum size about 10 kilobytes.
	Preview() *Base64
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// /Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Preview contains an image of person's face and has a resolution about 200 x 200 pixels with maximum size about 10 kilobytes.
	// /Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Preview contains an image of vehicle's license plate and has a resolution about 160 x 64 pixels with maximum size about 10 kilobytes.
	SetPreview(Base64) Episode
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	PreviewTimestamp() *UtcMs
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetPreviewTimestamp(UtcMs) Episode
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	StartedAt() *UtcMs
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetStartedAt(UtcMs) Episode
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	UpdatedAt() UtcMs
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	SetUpdatedAt(UtcMs) Episode
	// Emergency type of the vehicle.
	VehicleEmergencySubtype() *VisionVehicleEmergencySubtype
	// Emergency type of the vehicle.
	SetVehicleEmergencySubtype(VisionVehicleEmergencySubtype) Episode
	// Shows from which side the vehicle was detected.
	VehicleFacingSide() *VisionVehicleFacingSide
	// Shows from which side the vehicle was detected.
	SetVehicleFacingSide(VisionVehicleFacingSide) Episode
	// The purpose of the vehicle, e.g. emergency or regular.
	VehiclePurpose() *VisionVehiclePurpose
	// The purpose of the vehicle, e.g. emergency or regular.
	SetVehiclePurpose(VisionVehiclePurpose) Episode
}

type EpisodeAppearanceTimestamps interface {
	// The time when this episode was created in inference service.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	InferenceTimestamp() *UtcMs
	// The time when this episode was created in inference service.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	SetInferenceTimestamp(UtcMs) EpisodeAppearanceTimestamps
}

// # Definition
// Episode is a record about continious part of one video stream.
// It is used in video analytics, television systems, etc. for describing one continious and logically
// consolidated part of video stream.
// For example, episode can describe one TV show or a part of video when the car with specific license plate
// passed the camera view.
// Different systems in our ecosystem can emit and consume episodes of different `episode_type`.
// # Alternatives
// What episodes are not:
// * they cannot combine multiple streams. If you have multicamera view on the scene, you will have to create many episodes and join then in another system
// * they cannot be multipart. Only one continious uninterrupted episode. However, it is ok for them to overlap.
// # Updates
// Episodes are supposed to be streamable and updatable.
// If you consume episodes, you must be ready to see old `episode_id`
// with new updated data. You MUST overwrite previous data.
// If you emit episodes and you change any fields, you MUST accumulate previous data of episode and send full copy of
// updated episode.
// # Borders
// Episode have two mandatory fields: `opened_at` and `updated_at`, they are default borders of the episode:
// beginning and the end.
// Sometimes you need to look at another fields: `started_at` and `closed_at`.
// `started_at` appears when episode emitter decides that beginning of the episode should be different from `opened_at`,
// for example if video analytics has analysed previous frames and decided that this object appeared earlier.
// `closed_at` can appear if episode source have decided that episode will not continue anymore, for example
// car have run out of camera view. However, `updated_at` can be still changed, if any other system will add
// more data there, for example detected licence plates of some other auxiliary information.
// Required: episode_id, media, opened_at, updated_at
type EpisodeBase interface {
	// The reason for closing the episode.
	CloseReason() *EpisodeCloseReason
	// The reason for closing the episode.
	SetCloseReason(EpisodeCloseReason) EpisodeBase
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	ClosedAt() *UtcMs
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetClosedAt(UtcMs) EpisodeBase
	// The time when the episode appeared in the service relative to the server time.
	EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps
	// The time when the episode appeared in the service relative to the server time.
	SetEpisodeAppearanceTimestamps(EpisodeAppearanceTimestamps) EpisodeBase
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	EpisodeID() SnowflakeID
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	SetEpisodeID(SnowflakeID) EpisodeBase
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	FramePreview() *Base64
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	SetFramePreview(Base64) EpisodeBase
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	SetMedia(MediaName) EpisodeBase
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	OpenedAt() UtcMs
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetOpenedAt(UtcMs) EpisodeBase
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	Preview() *Base64
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	SetPreview(Base64) EpisodeBase
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	PreviewTimestamp() *UtcMs
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetPreviewTimestamp(UtcMs) EpisodeBase
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	StartedAt() *UtcMs
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetStartedAt(UtcMs) EpisodeBase
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	UpdatedAt() UtcMs
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	SetUpdatedAt(UtcMs) EpisodeBase
}

type EpisodeCustom interface {
	// The reason for closing the episode.
	CloseReason() *EpisodeCloseReason
	// The reason for closing the episode.
	SetCloseReason(EpisodeCloseReason) EpisodeCustom
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	ClosedAt() *UtcMs
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetClosedAt(UtcMs) EpisodeCustom
	// The time when the episode appeared in the service relative to the server time.
	EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps
	// The time when the episode appeared in the service relative to the server time.
	SetEpisodeAppearanceTimestamps(EpisodeAppearanceTimestamps) EpisodeCustom
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	EpisodeID() SnowflakeID
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	SetEpisodeID(SnowflakeID) EpisodeCustom
	// Custom episode type.
	// Use this field to define your own episode types when integrating custom analytics.
	// If episode type is not specified, episode will be saved with `generic` type.
	EpisodeType() *string
	// Custom episode type.
	// Use this field to define your own episode types when integrating custom analytics.
	// If episode type is not specified, episode will be saved with `generic` type.
	SetEpisodeType(string) EpisodeCustom
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	FramePreview() *Base64
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	SetFramePreview(Base64) EpisodeCustom
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	SetMedia(MediaName) EpisodeCustom
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	OpenedAt() UtcMs
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetOpenedAt(UtcMs) EpisodeCustom
	// Custom episode payload. Use this field to provide additional information about the episode.
	Payload() any
	// Custom episode payload. Use this field to provide additional information about the episode.
	SetPayload(any) EpisodeCustom
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	Preview() *Base64
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	SetPreview(Base64) EpisodeCustom
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	PreviewTimestamp() *UtcMs
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetPreviewTimestamp(UtcMs) EpisodeCustom
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	StartedAt() *UtcMs
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetStartedAt(UtcMs) EpisodeCustom
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	UpdatedAt() UtcMs
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	SetUpdatedAt(UtcMs) EpisodeCustom
}

type EpisodeGeneric interface {
	// The reason for closing the episode.
	CloseReason() *EpisodeCloseReason
	// The reason for closing the episode.
	SetCloseReason(EpisodeCloseReason) EpisodeGeneric
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	ClosedAt() *UtcMs
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetClosedAt(UtcMs) EpisodeGeneric
	// The time when the episode appeared in the service relative to the server time.
	EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps
	// The time when the episode appeared in the service relative to the server time.
	SetEpisodeAppearanceTimestamps(EpisodeAppearanceTimestamps) EpisodeGeneric
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	EpisodeID() SnowflakeID
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	SetEpisodeID(SnowflakeID) EpisodeGeneric
	// Generic stream episode
	EpisodeType() *string
	// Generic stream episode
	SetEpisodeType(string) EpisodeGeneric
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	FramePreview() *Base64
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	SetFramePreview(Base64) EpisodeGeneric
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	SetMedia(MediaName) EpisodeGeneric
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	OpenedAt() UtcMs
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetOpenedAt(UtcMs) EpisodeGeneric
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	Preview() *Base64
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	SetPreview(Base64) EpisodeGeneric
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	PreviewTimestamp() *UtcMs
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetPreviewTimestamp(UtcMs) EpisodeGeneric
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	StartedAt() *UtcMs
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetStartedAt(UtcMs) EpisodeGeneric
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	UpdatedAt() UtcMs
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	SetUpdatedAt(UtcMs) EpisodeGeneric
}

type EpisodesList interface {
	// The list of Episodes fetched according to the query parameters.
	Episodes() []Episode
	// The list of Episodes fetched according to the query parameters.
	SetEpisodes([]Episode) EpisodesList
	// Estimated total number of records for the query (regardless of the cursors).
	// Example: 5
	EstimatedCount() *int
	// Estimated total number of records for the query (regardless of the cursors).
	// Example: 5
	SetEstimatedCount(int) EpisodesList
	// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fZ3Q9MA==
	Next() *string
	// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fZ3Q9MA==
	SetNext(string) EpisodesList
	// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
	Prev() *string
	// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
	SetPrev(string) EpisodesList
	// An object with a list of different timings measured during this API call.
	Timing() any
	// An object with a list of different timings measured during this API call.
	SetTiming(any) EpisodesList
	// Collection returns the collection items
	Collection() []Episode
}

// Required: port
type ListenConfig interface {
	// Network address that will be used for listening.
	// Example: 10.0.35.1
	Address() *string
	// Network address that will be used for listening.
	// Example: 10.0.35.1
	SetAddress(string) ListenConfig
	// Port that will be used for listening.
	// Format: network_port (network_port)
	// Example: 80
	Port() NetworkPort
	// Port that will be used for listening.
	// Format: network_port (network_port)
	// Example: 80
	SetPort(NetworkPort) ListenConfig
}

type ListenHTTPConfig interface {
	// Network address that will be used for listening.
	// Example: 10.0.35.1
	Address() *string
	// Network address that will be used for listening.
	// Example: 10.0.35.1
	SetAddress(string) ListenHTTPConfig
	// If false, listener do not serve api calls.
	API() *bool
	// If false, listener do not serve api calls.
	SetAPI(bool) ListenHTTPConfig
	// Port that will be used for listening.
	// Format: network_port (network_port)
	// Example: 80
	Port() NetworkPort
	// Port that will be used for listening.
	// Format: network_port (network_port)
	// Example: 80
	SetPort(NetworkPort) ListenHTTPConfig
}

type ListenHTTPConfigParams interface {
	// If false, listener do not serve api calls.
	API() *bool
	// If false, listener do not serve api calls.
	SetAPI(bool) ListenHTTPConfigParams
}

type ListenHTTPSConfig interface {
	// Network address that will be used for listening.
	// Example: 10.0.35.1
	Address() *string
	// Network address that will be used for listening.
	// Example: 10.0.35.1
	SetAddress(string) ListenHTTPSConfig
	// If false, listener do not serve api calls.
	API() *bool
	// If false, listener do not serve api calls.
	SetAPI(bool) ListenHTTPSConfig
	// Port that will be used for listening.
	// Format: network_port (network_port)
	// Example: 80
	Port() NetworkPort
	// Port that will be used for listening.
	// Format: network_port (network_port)
	// Example: 80
	SetPort(NetworkPort) ListenHTTPSConfig
	// List of SSL protocol versions that will be used for listening.
	// Example: [tlsv1.1 tlsv1.2]
	SslProtocols() []TlsVersion
	// List of SSL protocol versions that will be used for listening.
	// Example: [tlsv1.1 tlsv1.2]
	SetSslProtocols([]TlsVersion) ListenHTTPSConfig
}

type ListenSslConfig interface {
	// List of SSL protocol versions that will be used for listening.
	// Example: [tlsv1.1 tlsv1.2]
	SslProtocols() []TlsVersion
	// List of SSL protocol versions that will be used for listening.
	// Example: [tlsv1.1 tlsv1.2]
	SetSslProtocols([]TlsVersion) ListenSslConfig
}

type Listeners interface {
	// List of HTTP ports or `host:port` pairs that will be used for listening.
	// Examples: [map[api:false, port:80]]
	HTTP() []ListenHTTPConfig
	// List of HTTP ports or `host:port` pairs that will be used for listening.
	// Examples: [map[api:false, port:80]]
	SetHTTP([]ListenHTTPConfig) Listeners
	// List of HTTPS ports or `host:port` pairs that will be used for listening.
	// Examples: [map[port:443]]
	HTTPS() []ListenHTTPSConfig
	// List of HTTPS ports or `host:port` pairs that will be used for listening.
	// Examples: [map[port:443]]
	SetHTTPS([]ListenHTTPSConfig) Listeners
}

type OpenmetricsLabels interface {
	// Unique server ID generated on a first start or license change.
	// Should not changing until running on the same hardware.
	// Format: uuid (uuid)
	ServerID() *UUID
	// Unique server ID generated on a first start or license change.
	// Should not changing until running on the same hardware.
	// Format: uuid (uuid)
	SetServerID(UUID) OpenmetricsLabels
}

type StreamConfig interface {
	// Globally unique stream name.
	// Note that the name could not be changed after the stream is created.
	// Format: media_name (media_name)
	// Examples: Decklink-Stream, Dektec-Stream, hockey1, mylive/bunny, test_stream
	Name() MediaName
	// Globally unique stream name.
	// Note that the name could not be changed after the stream is created.
	// Format: media_name (media_name)
	// Examples: Decklink-Stream, Dektec-Stream, hockey1, mylive/bunny, test_stream
	SetName(MediaName) StreamConfig
	// Stream's metrics and other statistical information.
	Stats() StreamStats
	// Stream's metrics and other statistical information.
	SetStats(StreamStats) StreamConfig
	// Video analytics parameters.
	Vision() VisionSpec
	// Video analytics parameters.
	SetVision(VisionSpec) StreamConfig
}

type StreamConfigAdditional interface {
	// Stream's metrics and other statistical information.
	Stats() StreamStats
	// Stream's metrics and other statistical information.
	SetStats(StreamStats) StreamConfigAdditional
}

type StreamConfigBase interface {
}

type StreamConfigDeprecated interface {
}

type StreamConfigInput interface {
}

type StreamConfigMedia interface {
}

type StreamConfigOnpremises interface {
	// Video analytics parameters.
	Vision() VisionSpec
	// Video analytics parameters.
	SetVision(VisionSpec) StreamConfigOnpremises
}

type StreamConfigSingleMedia interface {
}

// Required: name
type StreamConfigSpecific interface {
	// Globally unique stream name.
	// Note that the name could not be changed after the stream is created.
	// Format: media_name (media_name)
	// Examples: Decklink-Stream, Dektec-Stream, hockey1, mylive/bunny, test_stream
	Name() MediaName
	// Globally unique stream name.
	// Note that the name could not be changed after the stream is created.
	// Format: media_name (media_name)
	// Examples: Decklink-Stream, Dektec-Stream, hockey1, mylive/bunny, test_stream
	SetName(MediaName) StreamConfigSpecific
}

type StreamStats interface {
	// Indicates the status of the stream.
	Status() *StreamStatus
	// Indicates the status of the stream.
	SetStatus(StreamStatus) StreamStats
}

type StreamsList interface {
	// Estimated total number of records for the query (regardless of the cursors).
	// Example: 5
	EstimatedCount() *int
	// Estimated total number of records for the query (regardless of the cursors).
	// Example: 5
	SetEstimatedCount(int) StreamsList
	// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fZ3Q9MA==
	Next() *string
	// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fZ3Q9MA==
	SetNext(string) StreamsList
	// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
	Prev() *string
	// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
	// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
	// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
	SetPrev(string) StreamsList
	// Unique server ID generated on a first start or license change.
	// Should not changing until running on the same hardware.
	// Format: uuid (uuid)
	ServerID() *UUID
	// Unique server ID generated on a first start or license change.
	// Should not changing until running on the same hardware.
	// Format: uuid (uuid)
	SetServerID(UUID) StreamsList
	// List of fetched streams according to the query parameters.
	Streams() []StreamConfig
	// List of fetched streams according to the query parameters.
	SetStreams([]StreamConfig) StreamsList
	// An object with a list of different timings measured during this API call.
	Timing() any
	// An object with a list of different timings measured during this API call.
	SetTiming(any) StreamsList
	// Collection returns the collection items
	Collection() []StreamConfig
}

type VisionAlerts interface {
	// The time when an episode could not be created due to low detection quality (on blurry or noisy frames).
	// It may be caused by uncertainty when the picture is not clear enough.
	// Try adjusting the shutter speed parameters on your camera.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	LowQualityAt() *UtcMs
	// The time when an episode could not be created due to low detection quality (on blurry or noisy frames).
	// It may be caused by uncertainty when the picture is not clear enough.
	// Try adjusting the shutter speed parameters on your camera.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	SetLowQualityAt(UtcMs) VisionAlerts
	// The time when an episode could not be created due to insufficient detections.
	// The issue occurs when the selected detector is unable to find the target object enough times.
	// It is possible that the target object appears shortly or is obscured by something.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	NotEnoughDetectionsAt() *UtcMs
	// The time when an episode could not be created due to insufficient detections.
	// The issue occurs when the selected detector is unable to find the target object enough times.
	// It is possible that the target object appears shortly or is obscured by something.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	SetNotEnoughDetectionsAt(UtcMs) VisionAlerts
	// The time when an episode could not be created due to the small size of detections relative to the detector internal settings.
	// The camera placement may need to be adjusted closer to the target objects.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	SmallSizeAt() *UtcMs
	// The time when an episode could not be created due to the small size of detections relative to the detector internal settings.
	// The camera placement may need to be adjusted closer to the target objects.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	SetSmallSizeAt(UtcMs) VisionAlerts
}

type VisionAppearance interface {
	// Position of the objects at the frame
	Box() VisionBox
	// Position of the objects at the frame
	SetBox(VisionBox) VisionAppearance
}

type VisionAvailableModules interface {
	// Indicates which modules are enabled in the inference service
	AvailableModules() VisionContextSearchModule
	// Indicates which modules are enabled in the inference service
	SetAvailableModules(VisionContextSearchModule) VisionAvailableModules
}

// Rectangle
// Required: top, left, bottom, right
type VisionBox interface {
	// Bottom border of the bounding box. Fraction of full frame height
	Bottom() float64
	// Bottom border of the bounding box. Fraction of full frame height
	SetBottom(float64) VisionBox
	// Left border of the bounding box. Fraction of full frame width
	Left() float64
	// Left border of the bounding box. Fraction of full frame width
	SetLeft(float64) VisionBox
	// Right border of the bounding box. Fraction of full frame width
	Right() float64
	// Right border of the bounding box. Fraction of full frame width
	SetRight(float64) VisionBox
	// Top border of the bounding box. Fraction of full frame height
	Top() float64
	// Top border of the bounding box. Fraction of full frame height
	SetTop(float64) VisionBox
}

// Required: url
type VisionConfigExternal interface {
	// Stream configuration backend (Central) URL
	// Format: url (url)
	// Example: http://central.example.com/
	URL() URL
	// Stream configuration backend (Central) URL
	// Format: url (url)
	// Example: http://central.example.com/
	SetURL(URL) VisionConfigExternal
}

type VisionContextSearchModule interface {
}

type VisionCounterRecord interface {
	// Type of the counter
	CounterType() *string
	// Type of the counter
	SetCounterType(string) VisionCounterRecord
	// Duration of the record
	// Format: milliseconds (milliseconds)
	// Examples: 60000
	Duration() Milliseconds
	// Duration of the record
	// Format: milliseconds (milliseconds)
	// Examples: 60000
	SetDuration(Milliseconds) VisionCounterRecord
	// Statistics for a number of humans appeared in the region
	Humans() VisionCounterRegionStats
	// Statistics for a number of humans appeared in the region
	SetHumans(VisionCounterRegionStats) VisionCounterRecord
	// Stream name on which this record was created.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this record was created.
	// Format: media_name (media_name)
	SetMedia(MediaName) VisionCounterRecord
	// The time when this record was created.
	// Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.6370949e+12
	OpenedAt() UtcMs
	// The time when this record was created.
	// Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.6370949e+12
	SetOpenedAt(UtcMs) VisionCounterRecord
	// Identifier of the area in which counter operates.
	// Empty or missing field means that the entire frame is being counted
	RegionID() *string
	// Identifier of the area in which counter operates.
	// Empty or missing field means that the entire frame is being counted
	SetRegionID(string) VisionCounterRecord
	// Statistics for a number of vehicles appeared in the region
	Vehicles() VisionCounterRegionStats
	// Statistics for a number of vehicles appeared in the region
	SetVehicles(VisionCounterRegionStats) VisionCounterRecord
}

// Required: media, opened_at, duration
type VisionCounterRecordBase interface {
	// Duration of the record
	// Format: milliseconds (milliseconds)
	// Examples: 60000
	Duration() Milliseconds
	// Duration of the record
	// Format: milliseconds (milliseconds)
	// Examples: 60000
	SetDuration(Milliseconds) VisionCounterRecordBase
	// Stream name on which this record was created.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this record was created.
	// Format: media_name (media_name)
	SetMedia(MediaName) VisionCounterRecordBase
	// The time when this record was created.
	// Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.6370949e+12
	OpenedAt() UtcMs
	// The time when this record was created.
	// Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.6370949e+12
	SetOpenedAt(UtcMs) VisionCounterRecordBase
}

type VisionCounterRecordRegion interface {
	// Type of the counter
	CounterType() *string
	// Type of the counter
	SetCounterType(string) VisionCounterRecordRegion
	// Duration of the record
	// Format: milliseconds (milliseconds)
	// Examples: 60000
	Duration() Milliseconds
	// Duration of the record
	// Format: milliseconds (milliseconds)
	// Examples: 60000
	SetDuration(Milliseconds) VisionCounterRecordRegion
	// Statistics for a number of humans appeared in the region
	Humans() VisionCounterRegionStats
	// Statistics for a number of humans appeared in the region
	SetHumans(VisionCounterRegionStats) VisionCounterRecordRegion
	// Stream name on which this record was created.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this record was created.
	// Format: media_name (media_name)
	SetMedia(MediaName) VisionCounterRecordRegion
	// The time when this record was created.
	// Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.6370949e+12
	OpenedAt() UtcMs
	// The time when this record was created.
	// Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.6370949e+12
	SetOpenedAt(UtcMs) VisionCounterRecordRegion
	// Identifier of the area in which counter operates.
	// Empty or missing field means that the entire frame is being counted
	RegionID() *string
	// Identifier of the area in which counter operates.
	// Empty or missing field means that the entire frame is being counted
	SetRegionID(string) VisionCounterRecordRegion
	// Statistics for a number of vehicles appeared in the region
	Vehicles() VisionCounterRegionStats
	// Statistics for a number of vehicles appeared in the region
	SetVehicles(VisionCounterRegionStats) VisionCounterRecordRegion
}

// Statistics calculated within some timeframe, a minute for instance.
type VisionCounterRegionStats interface {
	// Number of new objects detected
	Entries() *int
	// Number of new objects detected
	SetEntries(int) VisionCounterRegionStats
	// Average number of objects appeared at the same time
	OccupancyAverage() *int
	// Average number of objects appeared at the same time
	SetOccupancyAverage(int) VisionCounterRegionStats
	// Max number of objects appeared at the same time
	OccupancyMax() *int
	// Max number of objects appeared at the same time
	SetOccupancyMax(int) VisionCounterRegionStats
	// Min number of objects appeared at the same time
	OccupancyMin() *int
	// Min number of objects appeared at the same time
	SetOccupancyMin(int) VisionCounterRegionStats
}

type VisionDetectedFace interface {
	// Appearance attributes of the detected object
	Appearance() VisionAppearance
	// Appearance attributes of the detected object
	SetAppearance(VisionAppearance) VisionDetectedFace
	// Confidence level of object detection
	Confidence() *float64
	// Confidence level of object detection
	SetConfidence(float64) VisionDetectedFace
	// Timestamp when the object was detected
	// Format: utc_ms (Unix timestamp in milliseconds)
	DetectedAt() UtcMs
	// Timestamp when the object was detected
	// Format: utc_ms (Unix timestamp in milliseconds)
	SetDetectedAt(UtcMs) VisionDetectedFace
	// The fingerprint of the detected face
	Fingerprint() VisionFaceFingerprint
	// The fingerprint of the detected face
	SetFingerprint(VisionFaceFingerprint) VisionDetectedFace
	// Class of the detected object
	ObjectClass() VisionObjectClass
	// Class of the detected object
	SetObjectClass(VisionObjectClass) VisionDetectedFace
	// Preview of the detected object
	Thumbnail() VisionImageAttributes
	// Preview of the detected object
	SetThumbnail(VisionImageAttributes) VisionDetectedFace
	// Quality of the thumbnail
	ThumbnailQuality() *float64
	// Quality of the thumbnail
	SetThumbnailQuality(float64) VisionDetectedFace
}

type VisionDetectedLicensePlate interface {
	// Appearance attributes of the detected object
	Appearance() VisionAppearance
	// Appearance attributes of the detected object
	SetAppearance(VisionAppearance) VisionDetectedLicensePlate
	// Confidence level of object detection
	Confidence() *float64
	// Confidence level of object detection
	SetConfidence(float64) VisionDetectedLicensePlate
	// Timestamp when the object was detected
	// Format: utc_ms (Unix timestamp in milliseconds)
	DetectedAt() UtcMs
	// Timestamp when the object was detected
	// Format: utc_ms (Unix timestamp in milliseconds)
	SetDetectedAt(UtcMs) VisionDetectedLicensePlate
	// Shows from which side the vehicle was detected.
	FacingSide() *VisionVehicleFacingSide
	// Shows from which side the vehicle was detected.
	SetFacingSide(VisionVehicleFacingSide) VisionDetectedLicensePlate
	// Class of the detected object
	ObjectClass() VisionObjectClass
	// Class of the detected object
	SetObjectClass(VisionObjectClass) VisionDetectedLicensePlate
	// Recognized vehicle's license plate number
	PlateText() *string
	// Recognized vehicle's license plate number
	SetPlateText(string) VisionDetectedLicensePlate
	// Preview of the detected object
	Thumbnail() VisionImageAttributes
	// Preview of the detected object
	SetThumbnail(VisionImageAttributes) VisionDetectedLicensePlate
	// Quality of the thumbnail
	ThumbnailQuality() *float64
	// Quality of the thumbnail
	SetThumbnailQuality(float64) VisionDetectedLicensePlate
}

// Required: detected_at, object_class
type VisionDetectedObjectBase interface {
	// Appearance attributes of the detected object
	Appearance() VisionAppearance
	// Appearance attributes of the detected object
	SetAppearance(VisionAppearance) VisionDetectedObjectBase
	// Confidence level of object detection
	Confidence() *float64
	// Confidence level of object detection
	SetConfidence(float64) VisionDetectedObjectBase
	// Timestamp when the object was detected
	// Format: utc_ms (Unix timestamp in milliseconds)
	DetectedAt() UtcMs
	// Timestamp when the object was detected
	// Format: utc_ms (Unix timestamp in milliseconds)
	SetDetectedAt(UtcMs) VisionDetectedObjectBase
	// Class of the detected object
	ObjectClass() VisionObjectClass
	// Class of the detected object
	SetObjectClass(VisionObjectClass) VisionDetectedObjectBase
	// Preview of the detected object
	Thumbnail() VisionImageAttributes
	// Preview of the detected object
	SetThumbnail(VisionImageAttributes) VisionDetectedObjectBase
	// Quality of the thumbnail
	ThumbnailQuality() *float64
	// Quality of the thumbnail
	SetThumbnailQuality(float64) VisionDetectedObjectBase
}

type VisionDetectedVehicle interface {
	// Appearance attributes of the detected object
	Appearance() VisionAppearance
	// Appearance attributes of the detected object
	SetAppearance(VisionAppearance) VisionDetectedVehicle
	// Confidence level of object detection
	Confidence() *float64
	// Confidence level of object detection
	SetConfidence(float64) VisionDetectedVehicle
	// Timestamp when the object was detected
	// Format: utc_ms (Unix timestamp in milliseconds)
	DetectedAt() UtcMs
	// Timestamp when the object was detected
	// Format: utc_ms (Unix timestamp in milliseconds)
	SetDetectedAt(UtcMs) VisionDetectedVehicle
	// Indicates if no license plate is detected on this vehicle
	LicensePlateMissing() *bool
	// Indicates if no license plate is detected on this vehicle
	SetLicensePlateMissing(bool) VisionDetectedVehicle
	// Class of the detected object
	ObjectClass() VisionObjectClass
	// Class of the detected object
	SetObjectClass(VisionObjectClass) VisionDetectedVehicle
	// The purpose of the vehicle, e.g. emergency or regular.
	Purpose() *VisionVehiclePurpose
	// The purpose of the vehicle, e.g. emergency or regular.
	SetPurpose(VisionVehiclePurpose) VisionDetectedVehicle
	// Preview of the detected object
	Thumbnail() VisionImageAttributes
	// Preview of the detected object
	SetThumbnail(VisionImageAttributes) VisionDetectedVehicle
	// Quality of the thumbnail
	ThumbnailQuality() *float64
	// Quality of the thumbnail
	SetThumbnailQuality(float64) VisionDetectedVehicle
}

// Required: detector_type, region_id
type VisionDetectorConfig interface {
	DetectorType() VisionDetectorConfigDetectorType
	SetDetectorType(VisionDetectorConfigDetectorType) VisionDetectorConfig
	RegionCoordinates() VisionDetectorConfigRegionCoordinates
	SetRegionCoordinates(VisionDetectorConfigRegionCoordinates) VisionDetectorConfig
	// Identifier of the detection area.
	// It is used to distinguish episodes from various regions of interest within the frame.
	// For instance, it can be used with a single camera facing two entrances to count visitors independently at each entrance.
	RegionID() string
	// Identifier of the detection area.
	// It is used to distinguish episodes from various regions of interest within the frame.
	// For instance, it can be used with a single camera facing two entrances to count visitors independently at each entrance.
	SetRegionID(string) VisionDetectorConfig
	// Runtime information about the vision process.
	Stats() VisionDetectorStats
	// Runtime information about the vision process.
	SetStats(VisionDetectorStats) VisionDetectorConfig
}

type VisionDetectorConfigDetectorType interface {
}

type VisionDetectorConfigRegionCoordinates interface {
}

type VisionDetectorStats interface {
	// Identifies analytics issues related to frames in a stream that impact episode creation
	Alerts() VisionAlerts
	// Identifies analytics issues related to frames in a stream that impact episode creation
	SetAlerts(VisionAlerts) VisionDetectorStats
	// The time when there was the last detection. Constant updates mean that analytics can detect objects on frames.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	LastDetectionAt() *UtcMs
	// The time when there was the last detection. Constant updates mean that analytics can detect objects on frames.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	SetLastDetectionAt(UtcMs) VisionDetectorStats
}

type VisionDeviceInfo interface {
	// Identifier of the hardware device used for videoanalytics inference (if applicable)
	// Example: 0
	DeviceID() *int
	// Identifier of the hardware device used for videoanalytics inference (if applicable)
	// Example: 0
	SetDeviceID(int) VisionDeviceInfo
	// Vendor-defined title of the device
	// Examples: AMD Ryzen 7 3700X, NVIDIA GeForce RTX 2070
	DeviceTitle() *string
	// Vendor-defined title of the device
	// Examples: AMD Ryzen 7 3700X, NVIDIA GeForce RTX 2070
	SetDeviceTitle(string) VisionDeviceInfo
	// Hardware device type to be used for a vision process.
	Hw() VisionHardwareType
	// Hardware device type to be used for a vision process.
	SetHw(VisionHardwareType) VisionDeviceInfo
	// Runtime statistics for a vision process.
	Stats() VisionDeviceStats
	// Runtime statistics for a vision process.
	SetStats(VisionDeviceStats) VisionDeviceInfo
}

type VisionDeviceStats interface {
	// RAM size in bytes (gauge)
	// Example: 3.4359738368e+10
	RamTotalBytes() *int
	// RAM size in bytes (gauge)
	// Example: 3.4359738368e+10
	SetRamTotalBytes(int) VisionDeviceStats
	// Used RAM size in bytes (gauge)
	// Example: 2.2548578304e+10
	RamUsedBytes() *int
	// Used RAM size in bytes (gauge)
	// Example: 2.2548578304e+10
	SetRamUsedBytes(int) VisionDeviceStats
	// Utilization percent of the computing device (gauge)
	// Example: 87
	UtilizationPercent() *int
	// Utilization percent of the computing device (gauge)
	// Example: 87
	SetUtilizationPercent(int) VisionDeviceStats
}

type VisionEpisodeContextSearch interface {
	// The reason for closing the episode.
	CloseReason() *EpisodeCloseReason
	// The reason for closing the episode.
	SetCloseReason(EpisodeCloseReason) VisionEpisodeContextSearch
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	ClosedAt() *UtcMs
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetClosedAt(UtcMs) VisionEpisodeContextSearch
	// The time when the episode appeared in the service relative to the server time.
	EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps
	// The time when the episode appeared in the service relative to the server time.
	SetEpisodeAppearanceTimestamps(EpisodeAppearanceTimestamps) VisionEpisodeContextSearch
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	EpisodeID() SnowflakeID
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	SetEpisodeID(SnowflakeID) VisionEpisodeContextSearch
	// Episode matches context search text query
	EpisodeType() *string
	// Episode matches context search text query
	SetEpisodeType(string) VisionEpisodeContextSearch
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	FramePreview() *Base64
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	SetFramePreview(Base64) VisionEpisodeContextSearch
	// Maximum matching score between the text query and episode.
	// Examples: 0.2345
	MatchScore() *float64
	// Maximum matching score between the text query and episode.
	// Examples: 0.2345
	SetMatchScore(float64) VisionEpisodeContextSearch
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	SetMedia(MediaName) VisionEpisodeContextSearch
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	OpenedAt() UtcMs
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetOpenedAt(UtcMs) VisionEpisodeContextSearch
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	Preview() *Base64
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	SetPreview(Base64) VisionEpisodeContextSearch
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	PreviewTimestamp() *UtcMs
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetPreviewTimestamp(UtcMs) VisionEpisodeContextSearch
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	StartedAt() *UtcMs
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetStartedAt(UtcMs) VisionEpisodeContextSearch
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	UpdatedAt() UtcMs
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	SetUpdatedAt(UtcMs) VisionEpisodeContextSearch
}

type VisionEpisodeFace interface {
	// The reason for closing the episode.
	CloseReason() *EpisodeCloseReason
	// The reason for closing the episode.
	SetCloseReason(EpisodeCloseReason) VisionEpisodeFace
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	ClosedAt() *UtcMs
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetClosedAt(UtcMs) VisionEpisodeFace
	// Detections associated with this episode
	Detections() []VisionDetectedFace
	// Detections associated with this episode
	SetDetections([]VisionDetectedFace) VisionEpisodeFace
	// The time when the episode appeared in the service relative to the server time.
	EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps
	// The time when the episode appeared in the service relative to the server time.
	SetEpisodeAppearanceTimestamps(EpisodeAppearanceTimestamps) VisionEpisodeFace
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	EpisodeID() SnowflakeID
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	SetEpisodeID(SnowflakeID) VisionEpisodeFace
	// Face is detected
	EpisodeType() *string
	// Face is detected
	SetEpisodeType(string) VisionEpisodeFace
	// The fingerprint of the detected face
	Fingerprint() VisionFaceFingerprint
	// The fingerprint of the detected face
	SetFingerprint(VisionFaceFingerprint) VisionEpisodeFace
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	FramePreview() *Base64
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	SetFramePreview(Base64) VisionEpisodeFace
	// List of matched persons with similarity metric.
	// Videoanalytics identification service enriches episode's data and fills this field
	// with the list of persons that are similar to the face detected in this episode.
	MatchedPersons() []VisionPersonMatch
	// List of matched persons with similarity metric.
	// Videoanalytics identification service enriches episode's data and fills this field
	// with the list of persons that are similar to the face detected in this episode.
	SetMatchedPersons([]VisionPersonMatch) VisionEpisodeFace
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	SetMedia(MediaName) VisionEpisodeFace
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	OpenedAt() UtcMs
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetOpenedAt(UtcMs) VisionEpisodeFace
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Preview contains an image of person's face and has a resolution about 200 x 200 pixels with maximum size about 10 kilobytes.
	// Format: base64 (base64)
	Preview() Base64
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Preview contains an image of person's face and has a resolution about 200 x 200 pixels with maximum size about 10 kilobytes.
	// Format: base64 (base64)
	SetPreview(Base64) VisionEpisodeFace
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	PreviewTimestamp() *UtcMs
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetPreviewTimestamp(UtcMs) VisionEpisodeFace
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	StartedAt() *UtcMs
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetStartedAt(UtcMs) VisionEpisodeFace
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	UpdatedAt() UtcMs
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	SetUpdatedAt(UtcMs) VisionEpisodeFace
}

type VisionEpisodeHuman interface {
	// The reason for closing the episode.
	CloseReason() *EpisodeCloseReason
	// The reason for closing the episode.
	SetCloseReason(EpisodeCloseReason) VisionEpisodeHuman
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	ClosedAt() *UtcMs
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetClosedAt(UtcMs) VisionEpisodeHuman
	// Detections associated with this episode
	Detections() []VisionDetectedObjectBase
	// Detections associated with this episode
	SetDetections([]VisionDetectedObjectBase) VisionEpisodeHuman
	// The time when the episode appeared in the service relative to the server time.
	EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps
	// The time when the episode appeared in the service relative to the server time.
	SetEpisodeAppearanceTimestamps(EpisodeAppearanceTimestamps) VisionEpisodeHuman
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	EpisodeID() SnowflakeID
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	SetEpisodeID(SnowflakeID) VisionEpisodeHuman
	// Human is detected
	EpisodeType() *string
	// Human is detected
	SetEpisodeType(string) VisionEpisodeHuman
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	FramePreview() *Base64
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	SetFramePreview(Base64) VisionEpisodeHuman
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	SetMedia(MediaName) VisionEpisodeHuman
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	OpenedAt() UtcMs
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetOpenedAt(UtcMs) VisionEpisodeHuman
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	Preview() *Base64
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	SetPreview(Base64) VisionEpisodeHuman
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	PreviewTimestamp() *UtcMs
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetPreviewTimestamp(UtcMs) VisionEpisodeHuman
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	StartedAt() *UtcMs
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetStartedAt(UtcMs) VisionEpisodeHuman
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	UpdatedAt() UtcMs
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	SetUpdatedAt(UtcMs) VisionEpisodeHuman
}

type VisionEpisodeQrCode interface {
	// The reason for closing the episode.
	CloseReason() *EpisodeCloseReason
	// The reason for closing the episode.
	SetCloseReason(EpisodeCloseReason) VisionEpisodeQrCode
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	ClosedAt() *UtcMs
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetClosedAt(UtcMs) VisionEpisodeQrCode
	// The time when the episode appeared in the service relative to the server time.
	EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps
	// The time when the episode appeared in the service relative to the server time.
	SetEpisodeAppearanceTimestamps(EpisodeAppearanceTimestamps) VisionEpisodeQrCode
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	EpisodeID() SnowflakeID
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	SetEpisodeID(SnowflakeID) VisionEpisodeQrCode
	// QR-code is detected
	EpisodeType() *string
	// QR-code is detected
	SetEpisodeType(string) VisionEpisodeQrCode
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	FramePreview() *Base64
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	SetFramePreview(Base64) VisionEpisodeQrCode
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	SetMedia(MediaName) VisionEpisodeQrCode
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	OpenedAt() UtcMs
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetOpenedAt(UtcMs) VisionEpisodeQrCode
	// Raw data extracted from QR-code
	// Example: WIFI:T:WPA;S:MyOfficeWiFi;P:Mypassword;H:;
	Payload() *string
	// Raw data extracted from QR-code
	// Example: WIFI:T:WPA;S:MyOfficeWiFi;P:Mypassword;H:;
	SetPayload(string) VisionEpisodeQrCode
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	Preview() *Base64
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Format: base64 (base64)
	SetPreview(Base64) VisionEpisodeQrCode
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	PreviewTimestamp() *UtcMs
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetPreviewTimestamp(UtcMs) VisionEpisodeQrCode
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	StartedAt() *UtcMs
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetStartedAt(UtcMs) VisionEpisodeQrCode
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	UpdatedAt() UtcMs
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	SetUpdatedAt(UtcMs) VisionEpisodeQrCode
}

type VisionEpisodeVehicle interface {
	// The reason for closing the episode.
	CloseReason() *EpisodeCloseReason
	// The reason for closing the episode.
	SetCloseReason(EpisodeCloseReason) VisionEpisodeVehicle
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	ClosedAt() *UtcMs
	// Episode emitter can decide that episode considered closed and will not grow further.
	// `closed_at` MUST NOT change, it must be emitted only once.
	// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
	// of the episode.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetClosedAt(UtcMs) VisionEpisodeVehicle
	// Detections associated with this episode
	Detections() []any
	// Detections associated with this episode
	SetDetections([]any) VisionEpisodeVehicle
	// The time when the episode appeared in the service relative to the server time.
	EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps
	// The time when the episode appeared in the service relative to the server time.
	SetEpisodeAppearanceTimestamps(EpisodeAppearanceTimestamps) VisionEpisodeVehicle
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	EpisodeID() SnowflakeID
	// Unique identifier of the episode. Must be created by the system that first creates this episode.
	// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
	// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
	// handle very long integers.
	// Format: snowflake_id (snowflake_id)
	// Examples: 1.722279170848854e+18
	SetEpisodeID(SnowflakeID) VisionEpisodeVehicle
	// Vehicle is detected
	EpisodeType() *string
	// Vehicle is detected
	SetEpisodeType(string) VisionEpisodeVehicle
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	FramePreview() *Base64
	// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
	// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
	// Format: base64 (base64)
	SetFramePreview(Base64) VisionEpisodeVehicle
	// Indicates if no license plate is detected on this vehicle
	LicensePlateMissing() *bool
	// Indicates if no license plate is detected on this vehicle
	SetLicensePlateMissing(bool) VisionEpisodeVehicle
	// Recognized vehicle's license plate number
	LicensePlateText() *string
	// Recognized vehicle's license plate number
	SetLicensePlateText(string) VisionEpisodeVehicle
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	Media() MediaName
	// Stream name on which this episode exists.
	// Format: media_name (media_name)
	SetMedia(MediaName) VisionEpisodeVehicle
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	OpenedAt() UtcMs
	// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
	// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
	// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
	// sort as by `opened_at`
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetOpenedAt(UtcMs) VisionEpisodeVehicle
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Preview contains an image of vehicle's license plate and has a resolution about 160 x 64 pixels with maximum size about 10 kilobytes.
	// Format: base64 (base64)
	Preview() Base64
	// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
	// Preview contains an image of vehicle's license plate and has a resolution about 160 x 64 pixels with maximum size about 10 kilobytes.
	// Format: base64 (base64)
	SetPreview(Base64) VisionEpisodeVehicle
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	PreviewTimestamp() *UtcMs
	// The time when the preview of this episode is available.
	// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
	// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
	// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
	// for details.
	// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetPreviewTimestamp(UtcMs) VisionEpisodeVehicle
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	StartedAt() *UtcMs
	// This field can be used as indication of the fact that some system have checked and ensured that
	// this episode has really started at some time, that may differ from `opened_at`.
	// For example video analytics will use this field for the time when this episode was confirmed as confident.
	// May be not relevant for television systems.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637094994e+12
	SetStartedAt(UtcMs) VisionEpisodeVehicle
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	UpdatedAt() UtcMs
	// The time of last change of the episode.
	// System that processes episodes and can send them to other systems, MUST update this field
	// on any changes in this episode.
	// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
	// this `updated_at` can be used as a sort key for fetching fresh updates.
	// Consumer of the episodes can use `updated_at` in the following scenario:
	// * fetch all exisiting episodes from the source
	// * take biggest `updated_at` from this dataset, it will be T
	// * ask source for all episodes with `updated_at > T`
	// This algorithm can be used for fetching update stream from the source.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Examples: 1.637098611e+12
	SetUpdatedAt(UtcMs) VisionEpisodeVehicle
	// Emergency type of the vehicle.
	VehicleEmergencySubtype() *VisionVehicleEmergencySubtype
	// Emergency type of the vehicle.
	SetVehicleEmergencySubtype(VisionVehicleEmergencySubtype) VisionEpisodeVehicle
	// Shows from which side the vehicle was detected.
	VehicleFacingSide() *VisionVehicleFacingSide
	// Shows from which side the vehicle was detected.
	SetVehicleFacingSide(VisionVehicleFacingSide) VisionEpisodeVehicle
	// The purpose of the vehicle, e.g. emergency or regular.
	VehiclePurpose() *VisionVehiclePurpose
	// The purpose of the vehicle, e.g. emergency or regular.
	SetVehiclePurpose(VisionVehiclePurpose) VisionEpisodeVehicle
}

type VisionFaceAttributes interface {
	// The fingerprint of the detected face
	Fingerprint() VisionFaceFingerprint
	// The fingerprint of the detected face
	SetFingerprint(VisionFaceFingerprint) VisionFaceAttributes
}

// Digital fingerprint of the face
// Required: data, version
type VisionFaceFingerprint interface {
	// Base64 encoded representation of the fingerprint
	// Format: base64 (base64)
	Data() Base64
	// Base64 encoded representation of the fingerprint
	// Format: base64 (base64)
	SetData(Base64) VisionFaceFingerprint
	// Version identifier of the fingerprint's data. The version is assigned automatically.
	// Fingerprints of different versions cannot be compared to each other.
	// Examples: aabbccdd, c6ba4246
	Version() string
	// Version identifier of the fingerprint's data. The version is assigned automatically.
	// Fingerprints of different versions cannot be compared to each other.
	// Examples: aabbccdd, c6ba4246
	SetVersion(string) VisionFaceFingerprint
}

// Required: data
type VisionImageAttributes interface {
	// Base64-encoded image data
	// Format: base64 (base64)
	Data() Base64
	// Base64-encoded image data
	// Format: base64 (base64)
	SetData(Base64) VisionImageAttributes
	// MIME type of the image
	MimeType() *VisionImageMimetype
	// MIME type of the image
	SetMimeType(VisionImageMimetype) VisionImageAttributes
	// Checksum of this image
	// Format: hexbinary (hexbinary)
	Sha256() *Hexbinary
	// Checksum of this image
	// Format: hexbinary (hexbinary)
	SetSha256(Hexbinary) VisionImageAttributes
}

// Required: hw
type VisionInferenceDevice interface {
	// Identifier of the hardware device used for videoanalytics inference (if applicable)
	// Example: 0
	DeviceID() *int
	// Identifier of the hardware device used for videoanalytics inference (if applicable)
	// Example: 0
	SetDeviceID(int) VisionInferenceDevice
	// Hardware device type to be used for a vision process.
	Hw() VisionHardwareType
	// Hardware device type to be used for a vision process.
	SetHw(VisionHardwareType) VisionInferenceDevice
}

// Attributes of the detected vehicle
type VisionLicensePlateAttributes interface {
	// Shows from which side the vehicle was detected.
	FacingSide() *VisionVehicleFacingSide
	// Shows from which side the vehicle was detected.
	SetFacingSide(VisionVehicleFacingSide) VisionLicensePlateAttributes
	// Recognized vehicle's license plate number
	PlateText() *string
	// Recognized vehicle's license plate number
	SetPlateText(string) VisionLicensePlateAttributes
}

type VisionMetrics interface {
	// The number of decoded frames
	DecodedFramesCount() *int
	// The number of decoded frames
	SetDecodedFramesCount(int) VisionMetrics
	// The number of decoding errors
	DecoderErrorsCount() *int
	// The number of decoding errors
	SetDecoderErrorsCount(int) VisionMetrics
	// How many times decoder was restarted
	DecoderRestartsCount() *int
	// How many times decoder was restarted
	SetDecoderRestartsCount(int) VisionMetrics
	// Total time spent on decoding
	// Format: milliseconds (milliseconds)
	DecodingTime() *Milliseconds
	// Total time spent on decoding
	// Format: milliseconds (milliseconds)
	SetDecodingTime(Milliseconds) VisionMetrics
	// Total time spent on detection
	// Format: milliseconds (milliseconds)
	DetectionTime() *Milliseconds
	// Total time spent on detection
	// Format: milliseconds (milliseconds)
	SetDetectionTime(Milliseconds) VisionMetrics
	// Cumulative detection size **after** filtering
	DetectionsAcceptedArea() *float64
	// Cumulative detection size **after** filtering
	SetDetectionsAcceptedArea(float64) VisionMetrics
	// Cumulative detection confidence **after** filtering
	DetectionsAcceptedConfidence() *float64
	// Cumulative detection confidence **after** filtering
	SetDetectionsAcceptedConfidence(float64) VisionMetrics
	// The number of detected objects **after** filtering
	DetectionsAcceptedCount() *int
	// The number of detected objects **after** filtering
	SetDetectionsAcceptedCount(int) VisionMetrics
	// Cumulative detection size (in fraction of frame area) **before** filtering
	DetectionsArea() *float64
	// Cumulative detection size (in fraction of frame area) **before** filtering
	SetDetectionsArea(float64) VisionMetrics
	// Total number of detections rejected due to **size** inacceptable for fingerprinting
	DetectionsAreaRejectedCount() *int
	// Total number of detections rejected due to **size** inacceptable for fingerprinting
	SetDetectionsAreaRejectedCount(int) VisionMetrics
	// Cumulative detection confidences **before** filtering
	DetectionsConfidence() *float64
	// Cumulative detection confidences **before** filtering
	SetDetectionsConfidence(float64) VisionMetrics
	// Total number of detections rejected due to inacceptable **confidence**
	DetectionsConfidenceRejectedCount() *int
	// Total number of detections rejected due to inacceptable **confidence**
	SetDetectionsConfidenceRejectedCount(int) VisionMetrics
	// Total number of detected objects.
	// Consists of 4 buckets: rejected by confidence, size, orientation and accepted detections.
	// Each bucket is represented by number of detections in that bucket
	// For each rejection reason there is a cumulative _quality_ metric for all detections
	// and cumulative _quality_ metric for accepted detections
	// For example:
	// `detections_confidence` is a cumulative confidence of _all_ detections
	// `detections_accepted_confidence` is a cumulative confidence of _accepted_ detections
	// `detections_area` is a cumulative size of _all_ detections
	// `detections_accepted_area` is a cumulative size of _accepted_ detections
	DetectionsCount() *int
	// Total number of detected objects.
	// Consists of 4 buckets: rejected by confidence, size, orientation and accepted detections.
	// Each bucket is represented by number of detections in that bucket
	// For each rejection reason there is a cumulative _quality_ metric for all detections
	// and cumulative _quality_ metric for accepted detections
	// For example:
	// `detections_confidence` is a cumulative confidence of _all_ detections
	// `detections_accepted_confidence` is a cumulative confidence of _accepted_ detections
	// `detections_area` is a cumulative size of _all_ detections
	// `detections_accepted_area` is a cumulative size of _accepted_ detections
	SetDetectionsCount(int) VisionMetrics
	// Total number of detections rejected due to **orientation** inacceptable for fingerprinting
	DetectionsOrientationRejectedCount() *int
	// Total number of detections rejected due to **orientation** inacceptable for fingerprinting
	SetDetectionsOrientationRejectedCount(int) VisionMetrics
	// Configure the objects that should be detected.
	Detector() *VisionDetector
	// Configure the objects that should be detected.
	SetDetector(VisionDetector) VisionMetrics
	// Identifier of the hardware device used for videoanalytics inference (if applicable)
	DeviceID() *int
	// Identifier of the hardware device used for videoanalytics inference (if applicable)
	SetDeviceID(int) VisionMetrics
	// Time spent on copying the input data (batch of frames) to the inference device
	// Format: milliseconds (milliseconds)
	DeviceTransferTime() *Milliseconds
	// Time spent on copying the input data (batch of frames) to the inference device
	// Format: milliseconds (milliseconds)
	SetDeviceTransferTime(Milliseconds) VisionMetrics
	// How many bytes of the input data (batch of frames) was copied to the inference device
	// Format: bytes (bytes)
	DeviceTransferredBytes() *Bytes
	// How many bytes of the input data (batch of frames) was copied to the inference device
	// Format: bytes (bytes)
	SetDeviceTransferredBytes(Bytes) VisionMetrics
	// Total minimum distance between detected object and objects in existing episodes
	EpisodeCreationDistance() *float64
	// Total minimum distance between detected object and objects in existing episodes
	SetEpisodeCreationDistance(float64) VisionMetrics
	// Total episode creation latency.
	// The latency is calculated by comparing the time of the first detection with the timestamp of the frame from which that detection came.
	// Format: milliseconds (milliseconds)
	EpisodeCreationLatency() *Milliseconds
	// Total episode creation latency.
	// The latency is calculated by comparing the time of the first detection with the timestamp of the frame from which that detection came.
	// Format: milliseconds (milliseconds)
	SetEpisodeCreationLatency(Milliseconds) VisionMetrics
	// Total distance between detected object and object in the existing episode that is updated
	EpisodeUpdateDistance() *float64
	// Total distance between detected object and object in the existing episode that is updated
	SetEpisodeUpdateDistance(float64) VisionMetrics
	// The number of _created_ episodes
	EpisodesCreatedCount() *int
	// The number of _created_ episodes
	SetEpisodesCreatedCount(int) VisionMetrics
	// Total number of detections assigned to all episodes
	EpisodesDetectionsCount() *int
	// Total number of detections assigned to all episodes
	SetEpisodesDetectionsCount(int) VisionMetrics
	// Total duration of episodes
	// Format: milliseconds (milliseconds)
	EpisodesDuration() *Milliseconds
	// Total duration of episodes
	// Format: milliseconds (milliseconds)
	SetEpisodesDuration(Milliseconds) VisionMetrics
	// Total time spent on making a decision to make a new episode or extend existing one
	// Format: milliseconds (milliseconds)
	EpisodesFormingTime() *Milliseconds
	// Total time spent on making a decision to make a new episode or extend existing one
	// Format: milliseconds (milliseconds)
	SetEpisodesFormingTime(Milliseconds) VisionMetrics
	// Time spent on encoding episode previews into JPEG
	// Format: milliseconds (milliseconds)
	EpisodesPreviewEncodingTime() *Milliseconds
	// Time spent on encoding episode previews into JPEG
	// Format: milliseconds (milliseconds)
	SetEpisodesPreviewEncodingTime(Milliseconds) VisionMetrics
	// The number of _updates_ of existing episodes
	EpisodesUpdatedCount() *int
	// The number of _updates_ of existing episodes
	SetEpisodesUpdatedCount(int) VisionMetrics
	// Time spent on serialization of processing results (both detection and fingerprinting) to pass them into the next stage (forming the episode)
	// Format: milliseconds (milliseconds)
	FingerprintSerializationTime() *Milliseconds
	// Time spent on serialization of processing results (both detection and fingerprinting) to pass them into the next stage (forming the episode)
	// Format: milliseconds (milliseconds)
	SetFingerprintSerializationTime(Milliseconds) VisionMetrics
	// Total time spent on fingerprinting
	// Format: milliseconds (milliseconds)
	FingerprintingTime() *Milliseconds
	// Total time spent on fingerprinting
	// Format: milliseconds (milliseconds)
	SetFingerprintingTime(Milliseconds) VisionMetrics
	// Cumulative fingerprints confidence **after** filtering by confidence threshold
	FingerprintsAcceptedConfidence() *float64
	// Cumulative fingerprints confidence **after** filtering by confidence threshold
	SetFingerprintsAcceptedConfidence(float64) VisionMetrics
	// The number of fingerprinted objects
	FingerprintsAcceptedCount() *int
	// The number of fingerprinted objects
	SetFingerprintsAcceptedCount(int) VisionMetrics
	// Cumulative fingerprints confidence **before** filtering by confidence threshold
	FingerprintsConfidence() *float64
	// Cumulative fingerprints confidence **before** filtering by confidence threshold
	SetFingerprintsConfidence(float64) VisionMetrics
	// Total number of fingerprinted objects
	// Consists of 2 buckets: rejected by confidence and accepted fingerprints.
	// Each bucket is represented by number of fingerprints in that bucket
	// For each rejection reason there is a cumulative _quality_ metric for all fingerprints
	// and cumulative _quality_ metric for accepted fingerprints
	// For example:
	// `fingerprints_confidence` is a cumulative confidence of _all_ fingerprints
	// `fingerprints_accepted_confidence` is a cumulative confidence of _accepted_ fingerprints
	FingerprintsCount() *int
	// Total number of fingerprinted objects
	// Consists of 2 buckets: rejected by confidence and accepted fingerprints.
	// Each bucket is represented by number of fingerprints in that bucket
	// For each rejection reason there is a cumulative _quality_ metric for all fingerprints
	// and cumulative _quality_ metric for accepted fingerprints
	// For example:
	// `fingerprints_confidence` is a cumulative confidence of _all_ fingerprints
	// `fingerprints_accepted_confidence` is a cumulative confidence of _accepted_ fingerprints
	SetFingerprintsCount(int) VisionMetrics
	// Total time spent on frame preprocessing to make a batch. It includes frame resizing and chroma channels planarization, if needed
	// Format: milliseconds (milliseconds)
	FramePreprocessingTime() *Milliseconds
	// Total time spent on frame preprocessing to make a batch. It includes frame resizing and chroma channels planarization, if needed
	// Format: milliseconds (milliseconds)
	SetFramePreprocessingTime(Milliseconds) VisionMetrics
	// Type of the hardware device used for videoanalytics inference
	Hardware() *VisionHardwareType
	// Type of the hardware device used for videoanalytics inference
	SetHardware(VisionHardwareType) VisionMetrics
	// Time spent on copying the processing results (both detection and fingerprinting) to the host for further postprocessing
	// Format: milliseconds (milliseconds)
	HostTransferTime() *Milliseconds
	// Time spent on copying the processing results (both detection and fingerprinting) to the host for further postprocessing
	// Format: milliseconds (milliseconds)
	SetHostTransferTime(Milliseconds) VisionMetrics
	// How many bytes of the processing results (both detection and fingerprinting) was copied to the host for further postprocessing
	// Format: bytes (bytes)
	HostTransferredBytes() *Bytes
	// How many bytes of the processing results (both detection and fingerprinting) was copied to the host for further postprocessing
	// Format: bytes (bytes)
	SetHostTransferredBytes(Bytes) VisionMetrics
	// The number of frames that was sent by the input.
	InputFramesCount() *int
	// The number of frames that was sent by the input.
	SetInputFramesCount(int) VisionMetrics
	// Unique stream name.
	// Format: media_name (media_name)
	// Example: cam-1
	Media() *MediaName
	// Unique stream name.
	// Format: media_name (media_name)
	// Example: cam-1
	SetMedia(MediaName) VisionMetrics
	// The number of frames that were processed by videoanalytics.
	// This number may be less than `input_frames` because some input frames can be skipped depending on the hardware capabilities.
	ProcessedFramesCount() *int
	// The number of frames that were processed by videoanalytics.
	// This number may be less than `input_frames` because some input frames can be skipped depending on the hardware capabilities.
	SetProcessedFramesCount(int) VisionMetrics
	// Total number of processing errors
	ProcessingErrorsCount() *int
	// Total number of processing errors
	SetProcessingErrorsCount(int) VisionMetrics
	// Total time spent on processing (includes detection and fingerprinting stages)
	// Format: milliseconds (milliseconds)
	ProcessingTime() *Milliseconds
	// Total time spent on processing (includes detection and fingerprinting stages)
	// Format: milliseconds (milliseconds)
	SetProcessingTime(Milliseconds) VisionMetrics
	// Total delay before a received input frame being started to process.
	// This delay is counted only for frames sent to videoanalytics.
	// Format: milliseconds (milliseconds)
	ProcessingWaitTime() *Milliseconds
	// Total delay before a received input frame being started to process.
	// This delay is counted only for frames sent to videoanalytics.
	// Format: milliseconds (milliseconds)
	SetProcessingWaitTime(Milliseconds) VisionMetrics
	// The number of rejected episodes.
	// Episode has being rejected if it contains unsufficient number of detections or total confidence of them.
	RejectedEpisodesCount() *int
	// The number of rejected episodes.
	// Episode has being rejected if it contains unsufficient number of detections or total confidence of them.
	SetRejectedEpisodesCount(int) VisionMetrics
	// Total number of detections assigned to rejected episodes
	RejectedEpisodesDetectionsCount() *int
	// Total number of detections assigned to rejected episodes
	SetRejectedEpisodesDetectionsCount(int) VisionMetrics
	// Total duration of rejected episodes
	// Format: milliseconds (milliseconds)
	RejectedEpisodesDuration() *Milliseconds
	// Total duration of rejected episodes
	// Format: milliseconds (milliseconds)
	SetRejectedEpisodesDuration(Milliseconds) VisionMetrics
	// Hashed name of the media
	// Format: uuid (uuid)
	// Example: 61942420-1b2e-4614-8871-a4c6345da31f
	SourceID() *UUID
	// Hashed name of the media
	// Format: uuid (uuid)
	// Example: 61942420-1b2e-4614-8871-a4c6345da31f
	SetSourceID(UUID) VisionMetrics
}

type VisionMetricsEpisode interface {
	// Total minimum distance between detected object and objects in existing episodes
	EpisodeCreationDistance() *float64
	// Total minimum distance between detected object and objects in existing episodes
	SetEpisodeCreationDistance(float64) VisionMetricsEpisode
	// Total episode creation latency.
	// The latency is calculated by comparing the time of the first detection with the timestamp of the frame from which that detection came.
	// Format: milliseconds (milliseconds)
	EpisodeCreationLatency() *Milliseconds
	// Total episode creation latency.
	// The latency is calculated by comparing the time of the first detection with the timestamp of the frame from which that detection came.
	// Format: milliseconds (milliseconds)
	SetEpisodeCreationLatency(Milliseconds) VisionMetricsEpisode
	// Total distance between detected object and object in the existing episode that is updated
	EpisodeUpdateDistance() *float64
	// Total distance between detected object and object in the existing episode that is updated
	SetEpisodeUpdateDistance(float64) VisionMetricsEpisode
	// The number of _created_ episodes
	EpisodesCreatedCount() *int
	// The number of _created_ episodes
	SetEpisodesCreatedCount(int) VisionMetricsEpisode
	// Total number of detections assigned to all episodes
	EpisodesDetectionsCount() *int
	// Total number of detections assigned to all episodes
	SetEpisodesDetectionsCount(int) VisionMetricsEpisode
	// Total duration of episodes
	// Format: milliseconds (milliseconds)
	EpisodesDuration() *Milliseconds
	// Total duration of episodes
	// Format: milliseconds (milliseconds)
	SetEpisodesDuration(Milliseconds) VisionMetricsEpisode
	// Total time spent on making a decision to make a new episode or extend existing one
	// Format: milliseconds (milliseconds)
	EpisodesFormingTime() *Milliseconds
	// Total time spent on making a decision to make a new episode or extend existing one
	// Format: milliseconds (milliseconds)
	SetEpisodesFormingTime(Milliseconds) VisionMetricsEpisode
	// Time spent on encoding episode previews into JPEG
	// Format: milliseconds (milliseconds)
	EpisodesPreviewEncodingTime() *Milliseconds
	// Time spent on encoding episode previews into JPEG
	// Format: milliseconds (milliseconds)
	SetEpisodesPreviewEncodingTime(Milliseconds) VisionMetricsEpisode
	// The number of _updates_ of existing episodes
	EpisodesUpdatedCount() *int
	// The number of _updates_ of existing episodes
	SetEpisodesUpdatedCount(int) VisionMetricsEpisode
	// The number of rejected episodes.
	// Episode has being rejected if it contains unsufficient number of detections or total confidence of them.
	RejectedEpisodesCount() *int
	// The number of rejected episodes.
	// Episode has being rejected if it contains unsufficient number of detections or total confidence of them.
	SetRejectedEpisodesCount(int) VisionMetricsEpisode
	// Total number of detections assigned to rejected episodes
	RejectedEpisodesDetectionsCount() *int
	// Total number of detections assigned to rejected episodes
	SetRejectedEpisodesDetectionsCount(int) VisionMetricsEpisode
	// Total duration of rejected episodes
	// Format: milliseconds (milliseconds)
	RejectedEpisodesDuration() *Milliseconds
	// Total duration of rejected episodes
	// Format: milliseconds (milliseconds)
	SetRejectedEpisodesDuration(Milliseconds) VisionMetricsEpisode
}

type VisionMetricsGeneric interface {
	// The number of decoded frames
	DecodedFramesCount() *int
	// The number of decoded frames
	SetDecodedFramesCount(int) VisionMetricsGeneric
	// The number of decoding errors
	DecoderErrorsCount() *int
	// The number of decoding errors
	SetDecoderErrorsCount(int) VisionMetricsGeneric
	// How many times decoder was restarted
	DecoderRestartsCount() *int
	// How many times decoder was restarted
	SetDecoderRestartsCount(int) VisionMetricsGeneric
	// Total time spent on decoding
	// Format: milliseconds (milliseconds)
	DecodingTime() *Milliseconds
	// Total time spent on decoding
	// Format: milliseconds (milliseconds)
	SetDecodingTime(Milliseconds) VisionMetricsGeneric
	// Total time spent on frame preprocessing to make a batch. It includes frame resizing and chroma channels planarization, if needed
	// Format: milliseconds (milliseconds)
	FramePreprocessingTime() *Milliseconds
	// Total time spent on frame preprocessing to make a batch. It includes frame resizing and chroma channels planarization, if needed
	// Format: milliseconds (milliseconds)
	SetFramePreprocessingTime(Milliseconds) VisionMetricsGeneric
	// The number of frames that was sent by the input.
	InputFramesCount() *int
	// The number of frames that was sent by the input.
	SetInputFramesCount(int) VisionMetricsGeneric
	// The number of frames that were processed by videoanalytics.
	// This number may be less than `input_frames` because some input frames can be skipped depending on the hardware capabilities.
	ProcessedFramesCount() *int
	// The number of frames that were processed by videoanalytics.
	// This number may be less than `input_frames` because some input frames can be skipped depending on the hardware capabilities.
	SetProcessedFramesCount(int) VisionMetricsGeneric
	// Total number of processing errors
	ProcessingErrorsCount() *int
	// Total number of processing errors
	SetProcessingErrorsCount(int) VisionMetricsGeneric
	// Total time spent on processing (includes detection and fingerprinting stages)
	// Format: milliseconds (milliseconds)
	ProcessingTime() *Milliseconds
	// Total time spent on processing (includes detection and fingerprinting stages)
	// Format: milliseconds (milliseconds)
	SetProcessingTime(Milliseconds) VisionMetricsGeneric
	// Total delay before a received input frame being started to process.
	// This delay is counted only for frames sent to videoanalytics.
	// Format: milliseconds (milliseconds)
	ProcessingWaitTime() *Milliseconds
	// Total delay before a received input frame being started to process.
	// This delay is counted only for frames sent to videoanalytics.
	// Format: milliseconds (milliseconds)
	SetProcessingWaitTime(Milliseconds) VisionMetricsGeneric
}

type VisionMetricsInference interface {
	// Total time spent on detection
	// Format: milliseconds (milliseconds)
	DetectionTime() *Milliseconds
	// Total time spent on detection
	// Format: milliseconds (milliseconds)
	SetDetectionTime(Milliseconds) VisionMetricsInference
	// Cumulative detection size **after** filtering
	DetectionsAcceptedArea() *float64
	// Cumulative detection size **after** filtering
	SetDetectionsAcceptedArea(float64) VisionMetricsInference
	// Cumulative detection confidence **after** filtering
	DetectionsAcceptedConfidence() *float64
	// Cumulative detection confidence **after** filtering
	SetDetectionsAcceptedConfidence(float64) VisionMetricsInference
	// The number of detected objects **after** filtering
	DetectionsAcceptedCount() *int
	// The number of detected objects **after** filtering
	SetDetectionsAcceptedCount(int) VisionMetricsInference
	// Cumulative detection size (in fraction of frame area) **before** filtering
	DetectionsArea() *float64
	// Cumulative detection size (in fraction of frame area) **before** filtering
	SetDetectionsArea(float64) VisionMetricsInference
	// Total number of detections rejected due to **size** inacceptable for fingerprinting
	DetectionsAreaRejectedCount() *int
	// Total number of detections rejected due to **size** inacceptable for fingerprinting
	SetDetectionsAreaRejectedCount(int) VisionMetricsInference
	// Cumulative detection confidences **before** filtering
	DetectionsConfidence() *float64
	// Cumulative detection confidences **before** filtering
	SetDetectionsConfidence(float64) VisionMetricsInference
	// Total number of detections rejected due to inacceptable **confidence**
	DetectionsConfidenceRejectedCount() *int
	// Total number of detections rejected due to inacceptable **confidence**
	SetDetectionsConfidenceRejectedCount(int) VisionMetricsInference
	// Total number of detected objects.
	// Consists of 4 buckets: rejected by confidence, size, orientation and accepted detections.
	// Each bucket is represented by number of detections in that bucket
	// For each rejection reason there is a cumulative _quality_ metric for all detections
	// and cumulative _quality_ metric for accepted detections
	// For example:
	// `detections_confidence` is a cumulative confidence of _all_ detections
	// `detections_accepted_confidence` is a cumulative confidence of _accepted_ detections
	// `detections_area` is a cumulative size of _all_ detections
	// `detections_accepted_area` is a cumulative size of _accepted_ detections
	DetectionsCount() *int
	// Total number of detected objects.
	// Consists of 4 buckets: rejected by confidence, size, orientation and accepted detections.
	// Each bucket is represented by number of detections in that bucket
	// For each rejection reason there is a cumulative _quality_ metric for all detections
	// and cumulative _quality_ metric for accepted detections
	// For example:
	// `detections_confidence` is a cumulative confidence of _all_ detections
	// `detections_accepted_confidence` is a cumulative confidence of _accepted_ detections
	// `detections_area` is a cumulative size of _all_ detections
	// `detections_accepted_area` is a cumulative size of _accepted_ detections
	SetDetectionsCount(int) VisionMetricsInference
	// Total number of detections rejected due to **orientation** inacceptable for fingerprinting
	DetectionsOrientationRejectedCount() *int
	// Total number of detections rejected due to **orientation** inacceptable for fingerprinting
	SetDetectionsOrientationRejectedCount(int) VisionMetricsInference
	// Time spent on copying the input data (batch of frames) to the inference device
	// Format: milliseconds (milliseconds)
	DeviceTransferTime() *Milliseconds
	// Time spent on copying the input data (batch of frames) to the inference device
	// Format: milliseconds (milliseconds)
	SetDeviceTransferTime(Milliseconds) VisionMetricsInference
	// How many bytes of the input data (batch of frames) was copied to the inference device
	// Format: bytes (bytes)
	DeviceTransferredBytes() *Bytes
	// How many bytes of the input data (batch of frames) was copied to the inference device
	// Format: bytes (bytes)
	SetDeviceTransferredBytes(Bytes) VisionMetricsInference
	// Time spent on serialization of processing results (both detection and fingerprinting) to pass them into the next stage (forming the episode)
	// Format: milliseconds (milliseconds)
	FingerprintSerializationTime() *Milliseconds
	// Time spent on serialization of processing results (both detection and fingerprinting) to pass them into the next stage (forming the episode)
	// Format: milliseconds (milliseconds)
	SetFingerprintSerializationTime(Milliseconds) VisionMetricsInference
	// Total time spent on fingerprinting
	// Format: milliseconds (milliseconds)
	FingerprintingTime() *Milliseconds
	// Total time spent on fingerprinting
	// Format: milliseconds (milliseconds)
	SetFingerprintingTime(Milliseconds) VisionMetricsInference
	// Cumulative fingerprints confidence **after** filtering by confidence threshold
	FingerprintsAcceptedConfidence() *float64
	// Cumulative fingerprints confidence **after** filtering by confidence threshold
	SetFingerprintsAcceptedConfidence(float64) VisionMetricsInference
	// The number of fingerprinted objects
	FingerprintsAcceptedCount() *int
	// The number of fingerprinted objects
	SetFingerprintsAcceptedCount(int) VisionMetricsInference
	// Cumulative fingerprints confidence **before** filtering by confidence threshold
	FingerprintsConfidence() *float64
	// Cumulative fingerprints confidence **before** filtering by confidence threshold
	SetFingerprintsConfidence(float64) VisionMetricsInference
	// Total number of fingerprinted objects
	// Consists of 2 buckets: rejected by confidence and accepted fingerprints.
	// Each bucket is represented by number of fingerprints in that bucket
	// For each rejection reason there is a cumulative _quality_ metric for all fingerprints
	// and cumulative _quality_ metric for accepted fingerprints
	// For example:
	// `fingerprints_confidence` is a cumulative confidence of _all_ fingerprints
	// `fingerprints_accepted_confidence` is a cumulative confidence of _accepted_ fingerprints
	FingerprintsCount() *int
	// Total number of fingerprinted objects
	// Consists of 2 buckets: rejected by confidence and accepted fingerprints.
	// Each bucket is represented by number of fingerprints in that bucket
	// For each rejection reason there is a cumulative _quality_ metric for all fingerprints
	// and cumulative _quality_ metric for accepted fingerprints
	// For example:
	// `fingerprints_confidence` is a cumulative confidence of _all_ fingerprints
	// `fingerprints_accepted_confidence` is a cumulative confidence of _accepted_ fingerprints
	SetFingerprintsCount(int) VisionMetricsInference
	// Time spent on copying the processing results (both detection and fingerprinting) to the host for further postprocessing
	// Format: milliseconds (milliseconds)
	HostTransferTime() *Milliseconds
	// Time spent on copying the processing results (both detection and fingerprinting) to the host for further postprocessing
	// Format: milliseconds (milliseconds)
	SetHostTransferTime(Milliseconds) VisionMetricsInference
	// How many bytes of the processing results (both detection and fingerprinting) was copied to the host for further postprocessing
	// Format: bytes (bytes)
	HostTransferredBytes() *Bytes
	// How many bytes of the processing results (both detection and fingerprinting) was copied to the host for further postprocessing
	// Format: bytes (bytes)
	SetHostTransferredBytes(Bytes) VisionMetricsInference
}

// Person
// Required: person_id, updated_at, originator
type VisionPerson interface {
	// When this person was marked as deleted
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637095014573e+12
	DeletedAt() *UtcMs
	// When this person was marked as deleted
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637095014573e+12
	SetDeletedAt(UtcMs) VisionPerson
	// Identifier of the person in the external system.
	// Use it when supplying the recognition results further into the external system
	// (e.g. for access level check) if the person identifiers in the external system
	// are different from the ones in Flussonic Identification database.
	// This field may contain `null` when video analytics detects a new person
	// which explicitly has no association in the external system (i.e. if `originator=identification_service`).
	// Examples: dedcc8e8
	ExternalID() *string
	// Identifier of the person in the external system.
	// Use it when supplying the recognition results further into the external system
	// (e.g. for access level check) if the person identifiers in the external system
	// are different from the ones in Flussonic Identification database.
	// This field may contain `null` when video analytics detects a new person
	// which explicitly has no association in the external system (i.e. if `originator=identification_service`).
	// Examples: dedcc8e8
	SetExternalID(string) VisionPerson
	// Digital fingerprints of the person.
	// Videoanalytics makes digital fingerprint of the person
	// using uploaded photos or videostreams being processed
	Fingerprints() []VisionFaceFingerprint
	// Digital fingerprints of the person.
	// Videoanalytics makes digital fingerprint of the person
	// using uploaded photos or videostreams being processed
	SetFingerprints([]VisionFaceFingerprint) VisionPerson
	// Indicates the way this person was created:
	// manually via an api or automatically in the identification service.
	Originator() VisionPersonOriginator
	// Indicates the way this person was created:
	// manually via an api or automatically in the identification service.
	SetOriginator(VisionPersonOriginator) VisionPerson
	// Identifier of the person
	// Format: snowflake_id (snowflake_id)
	// Examples: 7.036001172460667e+18
	PersonID() SnowflakeID
	// Identifier of the person
	// Format: snowflake_id (snowflake_id)
	// Examples: 7.036001172460667e+18
	SetPersonID(SnowflakeID) VisionPerson
	// When this person was last updated
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637034282845e+12
	UpdatedAt() UtcMs
	// When this person was last updated
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637034282845e+12
	SetUpdatedAt(UtcMs) VisionPerson
}

// Person matching information
// Required: person, match_score
type VisionPersonMatch interface {
	// Score of the match with person. 1.0 means absolute match
	MatchScore() float64
	// Score of the match with person. 1.0 means absolute match
	SetMatchScore(float64) VisionPersonMatch
	// Matched person
	Person() VisionPerson
	// Matched person
	SetPerson(VisionPerson) VisionPersonMatch
}

// 2D point
// Required: x, y
type VisionPoint interface {
	// X coordinate. Fraction of full frame width
	// Examples: 0.54, 0.78
	X() float64
	// X coordinate. Fraction of full frame width
	// Examples: 0.54, 0.78
	SetX(float64) VisionPoint
	// Y coordinate. Fraction of full frame height
	// Examples: 0.12, 0.38
	Y() float64
	// Y coordinate. Fraction of full frame height
	// Examples: 0.12, 0.38
	SetY(float64) VisionPoint
}

type VisionProcessResult interface {
	// List of detected episodes
	Episodes() []Episode
	// List of detected episodes
	SetEpisodes([]Episode) VisionProcessResult
}

type VisionServerDevices interface {
	// Devices list available for running vision.
	Devices() []VisionDeviceInfo
	// Devices list available for running vision.
	SetDevices([]VisionDeviceInfo) VisionServerDevices
}

type VisionServerInfo interface {
	// Build version
	// Example: 235
	Build() *int
	// Build version
	// Example: 235
	SetBuild(int) VisionServerInfo
	// Server's current timestamp
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.639337825e+12
	Now() *UtcMs
	// Server's current timestamp
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.639337825e+12
	SetNow(UtcMs) VisionServerInfo
	// API schema revision implemented in this version of the server
	// Example: 5e5e91d8
	SchemaVersion() *string
	// API schema revision implemented in this version of the server
	// Example: 5e5e91d8
	SetSchemaVersion(string) VisionServerInfo
	// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
	// Format: server_version (server_version)
	// Example: 21.12
	ServerVersion() *ServerVersion
	// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
	// Format: server_version (server_version)
	// Example: 21.12
	SetServerVersion(ServerVersion) VisionServerInfo
	// Timestamp when this instance was started
	// Format: utc (Unix timestamp in seconds)
	// Example: 1.639337825e+09
	StartedAt() *Utc
	// Timestamp when this instance was started
	// Format: utc (Unix timestamp in seconds)
	// Example: 1.639337825e+09
	SetStartedAt(Utc) VisionServerInfo
}

type VisionSpec interface {
	// The algorithm used for video analytics.
	// Example: faces
	Alg() *VisionSpecAlg
	// The algorithm used for video analytics.
	// Example: faces
	SetAlg(VisionSpecAlg) VisionSpec
	// This parameter allows you to select specific polygonal area(s) for detection.
	// By default, it is empty, and the recognition system searches over the entire camera field of view.
	// Each area is specified as a sequence of comma-separated coordinates of vertices of the polygon: `x0,y0,x1,y1,x2,y2,...`.
	// The vertices are specified in a counter-clockwise direction. Multiple areas are separated by `:`.
	Areas() *string
	// This parameter allows you to select specific polygonal area(s) for detection.
	// By default, it is empty, and the recognition system searches over the entire camera field of view.
	// Each area is specified as a sequence of comma-separated coordinates of vertices of the polygon: `x0,y0,x1,y1,x2,y2,...`.
	// The vertices are specified in a counter-clockwise direction. Multiple areas are separated by `:`.
	SetAreas(string) VisionSpec
	// Configuration of videoanalytics modules.
	// This configuration supersedes `alg` and `areas` parameters.
	// If this field is specified, values of `alg` and `areas` fields are being ignored.
	Detectors() []VisionDetectorConfig
	// Configuration of videoanalytics modules.
	// This configuration supersedes `alg` and `areas` parameters.
	// If this field is specified, values of `alg` and `areas` fields are being ignored.
	SetDetectors([]VisionDetectorConfig) VisionSpec
	// Deprecated field.
	// Runtime information about the vision process.
	Stats() VisionStats
	// Deprecated field.
	// Runtime information about the vision process.
	SetStats(VisionStats) VisionSpec
}

type VisionStats interface {
	// The time when there was the last detection. Constant updates mean that analytics can detect objects on frames.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	LastDetectionAt() *UtcMs
	// The time when there was the last detection. Constant updates mean that analytics can detect objects on frames.
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.637094994e+12
	SetLastDetectionAt(UtcMs) VisionStats
}

type VisionVehicleAttributes interface {
	// Indicates if no license plate is detected on this vehicle
	LicensePlateMissing() *bool
	// Indicates if no license plate is detected on this vehicle
	SetLicensePlateMissing(bool) VisionVehicleAttributes
	// The purpose of the vehicle, e.g. emergency or regular.
	Purpose() *VisionVehiclePurpose
	// The purpose of the vehicle, e.g. emergency or regular.
	SetPurpose(VisionVehiclePurpose) VisionVehicleAttributes
}

type VisionWorkerStats interface {
	// Build version
	// Example: 235
	Build() *int
	// Build version
	// Example: 235
	SetBuild(int) VisionWorkerStats
	// Devices list available for running vision.
	Devices() []VisionDeviceInfo
	// Devices list available for running vision.
	SetDevices([]VisionDeviceInfo) VisionWorkerStats
	// Server's current timestamp
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.639337825e+12
	Now() *UtcMs
	// Server's current timestamp
	// Format: utc_ms (Unix timestamp in milliseconds)
	// Example: 1.639337825e+12
	SetNow(UtcMs) VisionWorkerStats
	// API schema revision implemented in this version of the server
	// Example: 5e5e91d8
	SchemaVersion() *string
	// API schema revision implemented in this version of the server
	// Example: 5e5e91d8
	SetSchemaVersion(string) VisionWorkerStats
	// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
	// Format: server_version (server_version)
	// Example: 21.12
	ServerVersion() *ServerVersion
	// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
	// Format: server_version (server_version)
	// Example: 21.12
	SetServerVersion(ServerVersion) VisionWorkerStats
	// Timestamp when this instance was started
	// Format: utc (Unix timestamp in seconds)
	// Example: 1.639337825e+09
	StartedAt() *Utc
	// Timestamp when this instance was started
	// Format: utc (Unix timestamp in seconds)
	// Example: 1.639337825e+09
	SetStartedAt(Utc) VisionWorkerStats
}

type CollectionResponseImpl struct {
	EstimatedCountValue *int    `json:"estimated_count,omitempty" validate:"omitempty"`
	NextValue           *string `json:"next,omitempty" validate:"omitempty"`
	PrevValue           *string `json:"prev,omitempty" validate:"omitempty"`
	TimingValue         any     `json:"timing,omitempty" validate:"omitempty"`
}

type ConfigVisionImpl struct {
	APIKeyValue         *string                      `json:"api_key,omitempty" validate:"omitempty"`
	ConfigExternalValue *VisionConfigExternalImpl    `json:"config_external,omitempty" validate:"omitempty"`
	ListenersValue      *ListenersImpl               `json:"listeners,omitempty" validate:"omitempty"`
	LoglevelValue       *VisionLoglevel              `json:"loglevel,omitempty" validate:"omitempty"`
	StatsValue          *ConfigVisionStatsImpl       `json:"stats,omitempty" validate:"omitempty"`
	DevicesValue        []*VisionInferenceDeviceImpl `json:"devices,omitempty" validate:"omitempty"`
}

// Server runtime stats
type ConfigVisionStatsImpl struct {
	AvailableModulesValue *VisionContextSearchModuleImpl `json:"available_modules,omitempty" validate:"omitempty"`
	BuildValue            *int                           `json:"build,omitempty" validate:"omitempty"`
	NowValue              *UtcMs                         `json:"now,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	SchemaVersionValue    *string                        `json:"schema_version,omitempty" validate:"omitempty"`
	ServerVersionValue    *ServerVersion                 `json:"server_version,omitempty" validate:"omitempty"`
	StartedAtValue        *Utc                           `json:"started_at,omitempty" validate:"omitempty,min=1e+09,max=1e+10"`
	DevicesValue          []*VisionDeviceInfoImpl        `json:"devices,omitempty" validate:"omitempty"`
}

type CounterRecordsListImpl struct {
	TimingValue         any                        `json:"timing,omitempty" validate:"omitempty"`
	EstimatedCountValue *int                       `json:"estimated_count,omitempty" validate:"omitempty"`
	NextValue           *string                    `json:"next,omitempty" validate:"omitempty"`
	PrevValue           *string                    `json:"prev,omitempty" validate:"omitempty"`
	RecordsValue        []*VisionCounterRecordImpl `json:"records,omitempty" validate:"omitempty"`
}

type EpisodeImpl struct {
	DetectionsValue                  any                              `json:"detections,omitempty" validate:"omitempty"`
	PayloadValue                     any                              `json:"payload,omitempty" validate:"omitempty"`
	MatchScoreValue                  *float64                         `json:"match_score,omitempty" validate:"omitempty"`
	PreviewValue                     *Base64                          `json:"preview,omitempty" validate:"omitempty,base64"`
	VehiclePurposeValue              *VisionVehiclePurpose            `json:"vehicle_purpose,omitempty" validate:"omitempty"`
	EpisodeTypeValue                 *string                          `json:"episode_type,omitempty" validate:"omitempty"`
	FingerprintValue                 *VisionFaceFingerprintImpl       `json:"fingerprint,omitempty" validate:"omitempty"`
	FramePreviewValue                *Base64                          `json:"frame_preview,omitempty" validate:"omitempty,base64"`
	LicensePlateMissingValue         *bool                            `json:"license_plate_missing,omitempty" validate:"omitempty"`
	LicensePlateTextValue            *string                          `json:"license_plate_text,omitempty" validate:"omitempty"`
	CloseReasonValue                 *EpisodeCloseReason              `json:"close_reason,omitempty" validate:"omitempty"`
	VehicleFacingSideValue           *VisionVehicleFacingSide         `json:"vehicle_facing_side,omitempty" validate:"omitempty"`
	VehicleEmergencySubtypeValue     *VisionVehicleEmergencySubtype   `json:"vehicle_emergency_subtype,omitempty" validate:"omitempty"`
	StartedAtValue                   *UtcMs                           `json:"started_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	ClosedAtValue                    *UtcMs                           `json:"closed_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeAppearanceTimestampsValue *EpisodeAppearanceTimestampsImpl `json:"episode_appearance_timestamps,omitempty" validate:"omitempty"`
	PreviewTimestampValue            *UtcMs                           `json:"preview_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	MediaValue                       MediaName                        `json:"media" validate:"required"`
	MatchedPersonsValue              []*VisionPersonMatchImpl         `json:"matched_persons,omitempty" validate:"omitempty"`
	OpenedAtValue                    UtcMs                            `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
	UpdatedAtValue                   UtcMs                            `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
	EpisodeIDValue                   SnowflakeID                      `json:"episode_id" validate:"required"`
}

type EpisodeAppearanceTimestampsImpl struct {
	InferenceTimestampValue *UtcMs `json:"inference_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
}

// # Definition
// Episode is a record about continious part of one video stream.
// It is used in video analytics, television systems, etc. for describing one continious and logically
// consolidated part of video stream.
// For example, episode can describe one TV show or a part of video when the car with specific license plate
// passed the camera view.
// Different systems in our ecosystem can emit and consume episodes of different `episode_type`.
// # Alternatives
// What episodes are not:
// * they cannot combine multiple streams. If you have multicamera view on the scene, you will have to create many episodes and join then in another system
// * they cannot be multipart. Only one continious uninterrupted episode. However, it is ok for them to overlap.
// # Updates
// Episodes are supposed to be streamable and updatable.
// If you consume episodes, you must be ready to see old `episode_id`
// with new updated data. You MUST overwrite previous data.
// If you emit episodes and you change any fields, you MUST accumulate previous data of episode and send full copy of
// updated episode.
// # Borders
// Episode have two mandatory fields: `opened_at` and `updated_at`, they are default borders of the episode:
// beginning and the end.
// Sometimes you need to look at another fields: `started_at` and `closed_at`.
// `started_at` appears when episode emitter decides that beginning of the episode should be different from `opened_at`,
// for example if video analytics has analysed previous frames and decided that this object appeared earlier.
// `closed_at` can appear if episode source have decided that episode will not continue anymore, for example
// car have run out of camera view. However, `updated_at` can be still changed, if any other system will add
// more data there, for example detected licence plates of some other auxiliary information.
// Required: episode_id, media, opened_at, updated_at
type EpisodeBaseImpl struct {
	CloseReasonValue                 *EpisodeCloseReason              `json:"close_reason,omitempty" validate:"omitempty"`
	ClosedAtValue                    *UtcMs                           `json:"closed_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeAppearanceTimestampsValue *EpisodeAppearanceTimestampsImpl `json:"episode_appearance_timestamps,omitempty" validate:"omitempty"`
	FramePreviewValue                *Base64                          `json:"frame_preview,omitempty" validate:"omitempty,base64"`
	PreviewValue                     *Base64                          `json:"preview,omitempty" validate:"omitempty,base64"`
	PreviewTimestampValue            *UtcMs                           `json:"preview_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	StartedAtValue                   *UtcMs                           `json:"started_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	MediaValue                       MediaName                        `json:"media" validate:"required"`
	EpisodeIDValue                   SnowflakeID                      `json:"episode_id" validate:"required"`
	OpenedAtValue                    UtcMs                            `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
	UpdatedAtValue                   UtcMs                            `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
}

type EpisodeCustomImpl struct {
	PayloadValue                     any                              `json:"payload,omitempty" validate:"omitempty"`
	PreviewValue                     *Base64                          `json:"preview,omitempty" validate:"omitempty,base64"`
	ClosedAtValue                    *UtcMs                           `json:"closed_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeAppearanceTimestampsValue *EpisodeAppearanceTimestampsImpl `json:"episode_appearance_timestamps,omitempty" validate:"omitempty"`
	StartedAtValue                   *UtcMs                           `json:"started_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeTypeValue                 *string                          `json:"episode_type,omitempty" validate:"omitempty,min=1,max=20"`
	FramePreviewValue                *Base64                          `json:"frame_preview,omitempty" validate:"omitempty,base64"`
	CloseReasonValue                 *EpisodeCloseReason              `json:"close_reason,omitempty" validate:"omitempty"`
	PreviewTimestampValue            *UtcMs                           `json:"preview_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	MediaValue                       MediaName                        `json:"media" validate:"required"`
	OpenedAtValue                    UtcMs                            `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
	EpisodeIDValue                   SnowflakeID                      `json:"episode_id" validate:"required"`
	UpdatedAtValue                   UtcMs                            `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
}

type EpisodeGenericImpl struct {
	CloseReasonValue                 *EpisodeCloseReason              `json:"close_reason,omitempty" validate:"omitempty"`
	ClosedAtValue                    *UtcMs                           `json:"closed_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeAppearanceTimestampsValue *EpisodeAppearanceTimestampsImpl `json:"episode_appearance_timestamps,omitempty" validate:"omitempty"`
	EpisodeTypeValue                 *string                          `json:"episode_type,omitempty" validate:"omitempty"`
	FramePreviewValue                *Base64                          `json:"frame_preview,omitempty" validate:"omitempty,base64"`
	PreviewValue                     *Base64                          `json:"preview,omitempty" validate:"omitempty,base64"`
	PreviewTimestampValue            *UtcMs                           `json:"preview_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	StartedAtValue                   *UtcMs                           `json:"started_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	MediaValue                       MediaName                        `json:"media" validate:"required"`
	EpisodeIDValue                   SnowflakeID                      `json:"episode_id" validate:"required"`
	OpenedAtValue                    UtcMs                            `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
	UpdatedAtValue                   UtcMs                            `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
}

type EpisodesListImpl struct {
	TimingValue         any            `json:"timing,omitempty" validate:"omitempty"`
	EstimatedCountValue *int           `json:"estimated_count,omitempty" validate:"omitempty"`
	NextValue           *string        `json:"next,omitempty" validate:"omitempty"`
	PrevValue           *string        `json:"prev,omitempty" validate:"omitempty"`
	EpisodesValue       []*EpisodeImpl `json:"episodes,omitempty" validate:"omitempty"`
}

// Required: port
type ListenConfigImpl struct {
	AddressValue *string     `json:"address,omitempty" validate:"omitempty"`
	PortValue    NetworkPort `json:"port" validate:"required"`
}

type ListenHTTPConfigImpl struct {
	AddressValue *string     `json:"address,omitempty" validate:"omitempty"`
	APIValue     *bool       `json:"api,omitempty" validate:"omitempty"`
	PortValue    NetworkPort `json:"port" validate:"required"`
}

type ListenHTTPConfigParamsImpl struct {
	APIValue *bool `json:"api,omitempty" validate:"omitempty"`
}

type ListenHTTPSConfigImpl struct {
	AddressValue      *string      `json:"address,omitempty" validate:"omitempty"`
	APIValue          *bool        `json:"api,omitempty" validate:"omitempty"`
	SslProtocolsValue []TlsVersion `json:"ssl_protocols,omitempty" validate:"omitempty"`
	PortValue         NetworkPort  `json:"port" validate:"required"`
}

type ListenSslConfigImpl struct {
	SslProtocolsValue []TlsVersion `json:"ssl_protocols,omitempty" validate:"omitempty"`
}

type ListenersImpl struct {
	HTTPValue  []*ListenHTTPConfigImpl  `json:"http,omitempty" validate:"omitempty"`
	HTTPSValue []*ListenHTTPSConfigImpl `json:"https,omitempty" validate:"omitempty"`
}

type OpenmetricsLabelsImpl struct {
	ServerIDValue *UUID `json:"server_id,omitempty" validate:"omitempty" openmetrics_label:"server_id"`
}

type StreamConfigImpl struct {
	StatsValue  *StreamStatsImpl `json:"stats,omitempty" validate:"omitempty"`
	VisionValue *VisionSpecImpl  `json:"vision,omitempty" validate:"omitempty"`
	NameValue   MediaName        `json:"name" validate:"required" openmetrics_label:"name"`
}

type StreamConfigAdditionalImpl struct {
	StatsValue *StreamStatsImpl `json:"stats,omitempty" validate:"omitempty"`
}

type StreamConfigBaseImpl struct {
}

type StreamConfigDeprecatedImpl struct {
}

type StreamConfigInputImpl struct {
}

type StreamConfigMediaImpl struct {
}

type StreamConfigOnpremisesImpl struct {
	VisionValue *VisionSpecImpl `json:"vision,omitempty" validate:"omitempty"`
}

type StreamConfigSingleMediaImpl struct {
}

// Required: name
type StreamConfigSpecificImpl struct {
	NameValue MediaName `json:"name" validate:"required" openmetrics_label:"name"`
}

type StreamStatsImpl struct {
	StatusValue *StreamStatus `json:"status,omitempty" validate:"omitempty"`
}

type StreamsListImpl struct {
	TimingValue         any                 `json:"timing,omitempty" validate:"omitempty"`
	EstimatedCountValue *int                `json:"estimated_count,omitempty" validate:"omitempty"`
	NextValue           *string             `json:"next,omitempty" validate:"omitempty"`
	PrevValue           *string             `json:"prev,omitempty" validate:"omitempty"`
	ServerIDValue       *UUID               `json:"server_id,omitempty" validate:"omitempty" openmetrics_label:"server_id"`
	StreamsValue        []*StreamConfigImpl `json:"streams,omitempty" validate:"omitempty"`
}

type VisionAlertsImpl struct {
	LowQualityAtValue          *UtcMs `json:"low_quality_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	NotEnoughDetectionsAtValue *UtcMs `json:"not_enough_detections_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	SmallSizeAtValue           *UtcMs `json:"small_size_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
}

type VisionAppearanceImpl struct {
	BoxValue *VisionBoxImpl `json:"box,omitempty" validate:"omitempty"`
}

type VisionAvailableModulesImpl struct {
	AvailableModulesValue *VisionContextSearchModuleImpl `json:"available_modules,omitempty" validate:"omitempty"`
}

// Rectangle
// Required: top, left, bottom, right
type VisionBoxImpl struct {
	BottomValue float64 `json:"bottom" validate:"required,min=0,max=1"`
	LeftValue   float64 `json:"left" validate:"required,min=0,max=1"`
	RightValue  float64 `json:"right" validate:"required,min=0,max=1"`
	TopValue    float64 `json:"top" validate:"required,min=0,max=1"`
}

// Required: url
type VisionConfigExternalImpl struct {
	URLValue URL `json:"url" validate:"required"`
}

type VisionContextSearchModuleImpl struct {
}

type VisionCounterRecordImpl struct {
	CounterTypeValue *string                       `json:"counter_type,omitempty" validate:"omitempty"`
	HumansValue      *VisionCounterRegionStatsImpl `json:"humans,omitempty" validate:"omitempty"`
	RegionIDValue    *string                       `json:"region_id,omitempty" validate:"omitempty"`
	VehiclesValue    *VisionCounterRegionStatsImpl `json:"vehicles,omitempty" validate:"omitempty"`
	MediaValue       MediaName                     `json:"media" validate:"required"`
	DurationValue    Milliseconds                  `json:"duration" validate:"required"`
	OpenedAtValue    UtcMs                         `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
}

// Required: media, opened_at, duration
type VisionCounterRecordBaseImpl struct {
	MediaValue    MediaName    `json:"media" validate:"required"`
	DurationValue Milliseconds `json:"duration" validate:"required"`
	OpenedAtValue UtcMs        `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
}

type VisionCounterRecordRegionImpl struct {
	CounterTypeValue *string                       `json:"counter_type,omitempty" validate:"omitempty"`
	HumansValue      *VisionCounterRegionStatsImpl `json:"humans,omitempty" validate:"omitempty"`
	RegionIDValue    *string                       `json:"region_id,omitempty" validate:"omitempty"`
	VehiclesValue    *VisionCounterRegionStatsImpl `json:"vehicles,omitempty" validate:"omitempty"`
	MediaValue       MediaName                     `json:"media" validate:"required"`
	DurationValue    Milliseconds                  `json:"duration" validate:"required"`
	OpenedAtValue    UtcMs                         `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
}

// Statistics calculated within some timeframe, a minute for instance.
type VisionCounterRegionStatsImpl struct {
	EntriesValue          *int `json:"entries,omitempty" validate:"omitempty"`
	OccupancyAverageValue *int `json:"occupancy_average,omitempty" validate:"omitempty"`
	OccupancyMaxValue     *int `json:"occupancy_max,omitempty" validate:"omitempty"`
	OccupancyMinValue     *int `json:"occupancy_min,omitempty" validate:"omitempty"`
}

type VisionDetectedFaceImpl struct {
	AppearanceValue       *VisionAppearanceImpl      `json:"appearance,omitempty" validate:"omitempty"`
	ConfidenceValue       *float64                   `json:"confidence,omitempty" validate:"omitempty"`
	FingerprintValue      *VisionFaceFingerprintImpl `json:"fingerprint,omitempty" validate:"omitempty"`
	ThumbnailValue        *VisionImageAttributesImpl `json:"thumbnail,omitempty" validate:"omitempty"`
	ThumbnailQualityValue *float64                   `json:"thumbnail_quality,omitempty" validate:"omitempty"`
	ObjectClassValue      VisionObjectClass          `json:"object_class" validate:"required"`
	DetectedAtValue       UtcMs                      `json:"detected_at" validate:"required,min=1e+12,max=1e+13"`
}

type VisionDetectedLicensePlateImpl struct {
	AppearanceValue       *VisionAppearanceImpl      `json:"appearance,omitempty" validate:"omitempty"`
	ConfidenceValue       *float64                   `json:"confidence,omitempty" validate:"omitempty"`
	FacingSideValue       *VisionVehicleFacingSide   `json:"facing_side,omitempty" validate:"omitempty"`
	PlateTextValue        *string                    `json:"plate_text,omitempty" validate:"omitempty"`
	ThumbnailValue        *VisionImageAttributesImpl `json:"thumbnail,omitempty" validate:"omitempty"`
	ThumbnailQualityValue *float64                   `json:"thumbnail_quality,omitempty" validate:"omitempty"`
	ObjectClassValue      VisionObjectClass          `json:"object_class" validate:"required"`
	DetectedAtValue       UtcMs                      `json:"detected_at" validate:"required,min=1e+12,max=1e+13"`
}

// Required: detected_at, object_class
type VisionDetectedObjectBaseImpl struct {
	AppearanceValue       *VisionAppearanceImpl      `json:"appearance,omitempty" validate:"omitempty"`
	ConfidenceValue       *float64                   `json:"confidence,omitempty" validate:"omitempty"`
	ThumbnailValue        *VisionImageAttributesImpl `json:"thumbnail,omitempty" validate:"omitempty"`
	ThumbnailQualityValue *float64                   `json:"thumbnail_quality,omitempty" validate:"omitempty"`
	ObjectClassValue      VisionObjectClass          `json:"object_class" validate:"required"`
	DetectedAtValue       UtcMs                      `json:"detected_at" validate:"required,min=1e+12,max=1e+13"`
}

type VisionDetectedVehicleImpl struct {
	AppearanceValue          *VisionAppearanceImpl      `json:"appearance,omitempty" validate:"omitempty"`
	ConfidenceValue          *float64                   `json:"confidence,omitempty" validate:"omitempty"`
	LicensePlateMissingValue *bool                      `json:"license_plate_missing,omitempty" validate:"omitempty"`
	PurposeValue             *VisionVehiclePurpose      `json:"purpose,omitempty" validate:"omitempty"`
	ThumbnailValue           *VisionImageAttributesImpl `json:"thumbnail,omitempty" validate:"omitempty"`
	ThumbnailQualityValue    *float64                   `json:"thumbnail_quality,omitempty" validate:"omitempty"`
	ObjectClassValue         VisionObjectClass          `json:"object_class" validate:"required"`
	DetectedAtValue          UtcMs                      `json:"detected_at" validate:"required,min=1e+12,max=1e+13"`
}

// Required: detector_type, region_id
type VisionDetectorConfigImpl struct {
	DetectorTypeValue      *VisionDetectorConfigDetectorTypeImpl      `json:"detector_type" validate:"required"`
	RegionCoordinatesValue *VisionDetectorConfigRegionCoordinatesImpl `json:"region_coordinates,omitempty" validate:"omitempty"`
	StatsValue             *VisionDetectorStatsImpl                   `json:"stats,omitempty" validate:"omitempty"`
	RegionIDValue          string                                     `json:"region_id" validate:"required"`
}

type VisionDetectorConfigDetectorTypeImpl struct {
}

type VisionDetectorConfigRegionCoordinatesImpl struct {
}

type VisionDetectorStatsImpl struct {
	AlertsValue          *VisionAlertsImpl `json:"alerts,omitempty" validate:"omitempty"`
	LastDetectionAtValue *UtcMs            `json:"last_detection_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
}

type VisionDeviceInfoImpl struct {
	DeviceIDValue    *int                   `json:"device_id,omitempty" validate:"omitempty"`
	DeviceTitleValue *string                `json:"device_title,omitempty" validate:"omitempty"`
	StatsValue       *VisionDeviceStatsImpl `json:"stats,omitempty" validate:"omitempty"`
	HwValue          VisionHardwareType     `json:"hw" validate:"required"`
}

type VisionDeviceStatsImpl struct {
	RamTotalBytesValue      *int `json:"ram_total_bytes,omitempty" validate:"omitempty"`
	RamUsedBytesValue       *int `json:"ram_used_bytes,omitempty" validate:"omitempty"`
	UtilizationPercentValue *int `json:"utilization_percent,omitempty" validate:"omitempty"`
}

type VisionEpisodeContextSearchImpl struct {
	PreviewValue                     *Base64                          `json:"preview,omitempty" validate:"omitempty,base64"`
	ClosedAtValue                    *UtcMs                           `json:"closed_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeAppearanceTimestampsValue *EpisodeAppearanceTimestampsImpl `json:"episode_appearance_timestamps,omitempty" validate:"omitempty"`
	EpisodeTypeValue                 *string                          `json:"episode_type,omitempty" validate:"omitempty"`
	FramePreviewValue                *Base64                          `json:"frame_preview,omitempty" validate:"omitempty,base64"`
	MatchScoreValue                  *float64                         `json:"match_score,omitempty" validate:"omitempty"`
	CloseReasonValue                 *EpisodeCloseReason              `json:"close_reason,omitempty" validate:"omitempty"`
	PreviewTimestampValue            *UtcMs                           `json:"preview_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	StartedAtValue                   *UtcMs                           `json:"started_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	MediaValue                       MediaName                        `json:"media" validate:"required"`
	EpisodeIDValue                   SnowflakeID                      `json:"episode_id" validate:"required"`
	OpenedAtValue                    UtcMs                            `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
	UpdatedAtValue                   UtcMs                            `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
}

type VisionEpisodeFaceImpl struct {
	FingerprintValue                 *VisionFaceFingerprintImpl       `json:"fingerprint,omitempty" validate:"omitempty"`
	PreviewTimestampValue            *UtcMs                           `json:"preview_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeAppearanceTimestampsValue *EpisodeAppearanceTimestampsImpl `json:"episode_appearance_timestamps,omitempty" validate:"omitempty"`
	EpisodeTypeValue                 *string                          `json:"episode_type,omitempty" validate:"omitempty"`
	ClosedAtValue                    *UtcMs                           `json:"closed_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	StartedAtValue                   *UtcMs                           `json:"started_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	CloseReasonValue                 *EpisodeCloseReason              `json:"close_reason,omitempty" validate:"omitempty"`
	FramePreviewValue                *Base64                          `json:"frame_preview,omitempty" validate:"omitempty,base64"`
	MediaValue                       MediaName                        `json:"media" validate:"required"`
	PreviewValue                     Base64                           `json:"preview" validate:"required,base64"`
	DetectionsValue                  []*VisionDetectedFaceImpl        `json:"detections,omitempty" validate:"omitempty"`
	MatchedPersonsValue              []*VisionPersonMatchImpl         `json:"matched_persons,omitempty" validate:"omitempty"`
	EpisodeIDValue                   SnowflakeID                      `json:"episode_id" validate:"required"`
	OpenedAtValue                    UtcMs                            `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
	UpdatedAtValue                   UtcMs                            `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
}

type VisionEpisodeHumanImpl struct {
	FramePreviewValue                *Base64                          `json:"frame_preview,omitempty" validate:"omitempty,base64"`
	ClosedAtValue                    *UtcMs                           `json:"closed_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeAppearanceTimestampsValue *EpisodeAppearanceTimestampsImpl `json:"episode_appearance_timestamps,omitempty" validate:"omitempty"`
	EpisodeTypeValue                 *string                          `json:"episode_type,omitempty" validate:"omitempty"`
	CloseReasonValue                 *EpisodeCloseReason              `json:"close_reason,omitempty" validate:"omitempty"`
	PreviewValue                     *Base64                          `json:"preview,omitempty" validate:"omitempty,base64"`
	PreviewTimestampValue            *UtcMs                           `json:"preview_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	StartedAtValue                   *UtcMs                           `json:"started_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	MediaValue                       MediaName                        `json:"media" validate:"required"`
	DetectionsValue                  []*VisionDetectedObjectBaseImpl  `json:"detections,omitempty" validate:"omitempty"`
	EpisodeIDValue                   SnowflakeID                      `json:"episode_id" validate:"required"`
	OpenedAtValue                    UtcMs                            `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
	UpdatedAtValue                   UtcMs                            `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
}

type VisionEpisodeQrCodeImpl struct {
	PreviewValue                     *Base64                          `json:"preview,omitempty" validate:"omitempty,base64"`
	ClosedAtValue                    *UtcMs                           `json:"closed_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeAppearanceTimestampsValue *EpisodeAppearanceTimestampsImpl `json:"episode_appearance_timestamps,omitempty" validate:"omitempty"`
	StartedAtValue                   *UtcMs                           `json:"started_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	EpisodeTypeValue                 *string                          `json:"episode_type,omitempty" validate:"omitempty"`
	FramePreviewValue                *Base64                          `json:"frame_preview,omitempty" validate:"omitempty,base64"`
	CloseReasonValue                 *EpisodeCloseReason              `json:"close_reason,omitempty" validate:"omitempty"`
	PreviewTimestampValue            *UtcMs                           `json:"preview_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	PayloadValue                     *string                          `json:"payload,omitempty" validate:"omitempty"`
	MediaValue                       MediaName                        `json:"media" validate:"required"`
	OpenedAtValue                    UtcMs                            `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
	EpisodeIDValue                   SnowflakeID                      `json:"episode_id" validate:"required"`
	UpdatedAtValue                   UtcMs                            `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
}

type VisionEpisodeVehicleImpl struct {
	PreviewTimestampValue            *UtcMs                           `json:"preview_timestamp,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	StartedAtValue                   *UtcMs                           `json:"started_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	VehiclePurposeValue              *VisionVehiclePurpose            `json:"vehicle_purpose,omitempty" validate:"omitempty"`
	EpisodeAppearanceTimestampsValue *EpisodeAppearanceTimestampsImpl `json:"episode_appearance_timestamps,omitempty" validate:"omitempty"`
	VehicleFacingSideValue           *VisionVehicleFacingSide         `json:"vehicle_facing_side,omitempty" validate:"omitempty"`
	EpisodeTypeValue                 *string                          `json:"episode_type,omitempty" validate:"omitempty"`
	FramePreviewValue                *Base64                          `json:"frame_preview,omitempty" validate:"omitempty,base64"`
	LicensePlateMissingValue         *bool                            `json:"license_plate_missing,omitempty" validate:"omitempty"`
	ClosedAtValue                    *UtcMs                           `json:"closed_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	VehicleEmergencySubtypeValue     *VisionVehicleEmergencySubtype   `json:"vehicle_emergency_subtype,omitempty" validate:"omitempty"`
	LicensePlateTextValue            *string                          `json:"license_plate_text,omitempty" validate:"omitempty"`
	CloseReasonValue                 *EpisodeCloseReason              `json:"close_reason,omitempty" validate:"omitempty"`
	PreviewValue                     Base64                           `json:"preview" validate:"required,base64"`
	MediaValue                       MediaName                        `json:"media" validate:"required"`
	DetectionsValue                  []any                            `json:"detections,omitempty" validate:"omitempty"`
	UpdatedAtValue                   UtcMs                            `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
	OpenedAtValue                    UtcMs                            `json:"opened_at" validate:"required,min=1e+12,max=1e+13"`
	EpisodeIDValue                   SnowflakeID                      `json:"episode_id" validate:"required"`
}

type VisionFaceAttributesImpl struct {
	FingerprintValue *VisionFaceFingerprintImpl `json:"fingerprint,omitempty" validate:"omitempty"`
}

// Digital fingerprint of the face
// Required: data, version
type VisionFaceFingerprintImpl struct {
	DataValue    Base64 `json:"data" validate:"required,base64"`
	VersionValue string `json:"version" validate:"required"`
}

// Required: data
type VisionImageAttributesImpl struct {
	MimeTypeValue *VisionImageMimetype `json:"mime_type,omitempty" validate:"omitempty"`
	Sha256Value   *Hexbinary           `json:"sha256,omitempty" validate:"omitempty,min=64,max=64"`
	DataValue     Base64               `json:"data" validate:"required,base64"`
}

// Required: hw
type VisionInferenceDeviceImpl struct {
	DeviceIDValue *int               `json:"device_id,omitempty" validate:"omitempty"`
	HwValue       VisionHardwareType `json:"hw" validate:"required"`
}

// Attributes of the detected vehicle
type VisionLicensePlateAttributesImpl struct {
	FacingSideValue *VisionVehicleFacingSide `json:"facing_side,omitempty" validate:"omitempty"`
	PlateTextValue  *string                  `json:"plate_text,omitempty" validate:"omitempty"`
}

type VisionMetricsImpl struct {
	DecodedFramesCountValue                 *int                `json:"decoded_frames_count,omitempty" validate:"omitempty"`
	DecoderErrorsCountValue                 *int                `json:"decoder_errors_count,omitempty" validate:"omitempty"`
	DecoderRestartsCountValue               *int                `json:"decoder_restarts_count,omitempty" validate:"omitempty"`
	DecodingTimeValue                       *Milliseconds       `json:"decoding_time,omitempty" validate:"omitempty"`
	DetectionTimeValue                      *Milliseconds       `json:"detection_time,omitempty" validate:"omitempty"`
	DetectionsAcceptedAreaValue             *float64            `json:"detections_accepted_area,omitempty" validate:"omitempty,min=0"`
	DetectionsAcceptedConfidenceValue       *float64            `json:"detections_accepted_confidence,omitempty" validate:"omitempty,min=0"`
	DetectionsAcceptedCountValue            *int                `json:"detections_accepted_count,omitempty" validate:"omitempty"`
	DetectionsAreaValue                     *float64            `json:"detections_area,omitempty" validate:"omitempty,min=0"`
	DetectionsAreaRejectedCountValue        *int                `json:"detections_area_rejected_count,omitempty" validate:"omitempty,min=0"`
	DetectionsConfidenceValue               *float64            `json:"detections_confidence,omitempty" validate:"omitempty,min=0"`
	DetectionsConfidenceRejectedCountValue  *int                `json:"detections_confidence_rejected_count,omitempty" validate:"omitempty,min=0"`
	DetectionsCountValue                    *int                `json:"detections_count,omitempty" validate:"omitempty"`
	DetectionsOrientationRejectedCountValue *int                `json:"detections_orientation_rejected_count,omitempty" validate:"omitempty,min=0"`
	DetectorValue                           *VisionDetector     `json:"detector,omitempty" validate:"omitempty"`
	DeviceIDValue                           *int                `json:"device_id,omitempty" validate:"omitempty"`
	DeviceTransferTimeValue                 *Milliseconds       `json:"device_transfer_time,omitempty" validate:"omitempty"`
	DeviceTransferredBytesValue             *Bytes              `json:"device_transferred_bytes,omitempty" validate:"omitempty"`
	EpisodeCreationDistanceValue            *float64            `json:"episode_creation_distance,omitempty" validate:"omitempty,min=0"`
	EpisodeCreationLatencyValue             *Milliseconds       `json:"episode_creation_latency,omitempty" validate:"omitempty"`
	EpisodeUpdateDistanceValue              *float64            `json:"episode_update_distance,omitempty" validate:"omitempty,min=0"`
	EpisodesCreatedCountValue               *int                `json:"episodes_created_count,omitempty" validate:"omitempty"`
	EpisodesDetectionsCountValue            *int                `json:"episodes_detections_count,omitempty" validate:"omitempty"`
	EpisodesDurationValue                   *Milliseconds       `json:"episodes_duration,omitempty" validate:"omitempty"`
	EpisodesFormingTimeValue                *Milliseconds       `json:"episodes_forming_time,omitempty" validate:"omitempty"`
	EpisodesPreviewEncodingTimeValue        *Milliseconds       `json:"episodes_preview_encoding_time,omitempty" validate:"omitempty"`
	EpisodesUpdatedCountValue               *int                `json:"episodes_updated_count,omitempty" validate:"omitempty"`
	FingerprintSerializationTimeValue       *Milliseconds       `json:"fingerprint_serialization_time,omitempty" validate:"omitempty"`
	FingerprintingTimeValue                 *Milliseconds       `json:"fingerprinting_time,omitempty" validate:"omitempty"`
	FingerprintsAcceptedConfidenceValue     *float64            `json:"fingerprints_accepted_confidence,omitempty" validate:"omitempty,min=0"`
	FingerprintsAcceptedCountValue          *int                `json:"fingerprints_accepted_count,omitempty" validate:"omitempty"`
	FingerprintsConfidenceValue             *float64            `json:"fingerprints_confidence,omitempty" validate:"omitempty,min=0"`
	FingerprintsCountValue                  *int                `json:"fingerprints_count,omitempty" validate:"omitempty"`
	FramePreprocessingTimeValue             *Milliseconds       `json:"frame_preprocessing_time,omitempty" validate:"omitempty"`
	HardwareValue                           *VisionHardwareType `json:"hardware,omitempty" validate:"omitempty"`
	HostTransferTimeValue                   *Milliseconds       `json:"host_transfer_time,omitempty" validate:"omitempty"`
	HostTransferredBytesValue               *Bytes              `json:"host_transferred_bytes,omitempty" validate:"omitempty"`
	InputFramesCountValue                   *int                `json:"input_frames_count,omitempty" validate:"omitempty"`
	MediaValue                              *MediaName          `json:"media,omitempty" validate:"omitempty"`
	ProcessedFramesCountValue               *int                `json:"processed_frames_count,omitempty" validate:"omitempty"`
	ProcessingErrorsCountValue              *int                `json:"processing_errors_count,omitempty" validate:"omitempty"`
	ProcessingTimeValue                     *Milliseconds       `json:"processing_time,omitempty" validate:"omitempty"`
	ProcessingWaitTimeValue                 *Milliseconds       `json:"processing_wait_time,omitempty" validate:"omitempty"`
	RejectedEpisodesCountValue              *int                `json:"rejected_episodes_count,omitempty" validate:"omitempty"`
	RejectedEpisodesDetectionsCountValue    *int                `json:"rejected_episodes_detections_count,omitempty" validate:"omitempty"`
	RejectedEpisodesDurationValue           *Milliseconds       `json:"rejected_episodes_duration,omitempty" validate:"omitempty"`
	SourceIDValue                           *UUID               `json:"source_id,omitempty" validate:"omitempty"`
}

type VisionMetricsEpisodeImpl struct {
	EpisodeCreationDistanceValue         *float64      `json:"episode_creation_distance,omitempty" validate:"omitempty,min=0"`
	EpisodeCreationLatencyValue          *Milliseconds `json:"episode_creation_latency,omitempty" validate:"omitempty"`
	EpisodeUpdateDistanceValue           *float64      `json:"episode_update_distance,omitempty" validate:"omitempty,min=0"`
	EpisodesCreatedCountValue            *int          `json:"episodes_created_count,omitempty" validate:"omitempty"`
	EpisodesDetectionsCountValue         *int          `json:"episodes_detections_count,omitempty" validate:"omitempty"`
	EpisodesDurationValue                *Milliseconds `json:"episodes_duration,omitempty" validate:"omitempty"`
	EpisodesFormingTimeValue             *Milliseconds `json:"episodes_forming_time,omitempty" validate:"omitempty"`
	EpisodesPreviewEncodingTimeValue     *Milliseconds `json:"episodes_preview_encoding_time,omitempty" validate:"omitempty"`
	EpisodesUpdatedCountValue            *int          `json:"episodes_updated_count,omitempty" validate:"omitempty"`
	RejectedEpisodesCountValue           *int          `json:"rejected_episodes_count,omitempty" validate:"omitempty"`
	RejectedEpisodesDetectionsCountValue *int          `json:"rejected_episodes_detections_count,omitempty" validate:"omitempty"`
	RejectedEpisodesDurationValue        *Milliseconds `json:"rejected_episodes_duration,omitempty" validate:"omitempty"`
}

type VisionMetricsGenericImpl struct {
	DecodedFramesCountValue     *int          `json:"decoded_frames_count,omitempty" validate:"omitempty"`
	DecoderErrorsCountValue     *int          `json:"decoder_errors_count,omitempty" validate:"omitempty"`
	DecoderRestartsCountValue   *int          `json:"decoder_restarts_count,omitempty" validate:"omitempty"`
	DecodingTimeValue           *Milliseconds `json:"decoding_time,omitempty" validate:"omitempty"`
	FramePreprocessingTimeValue *Milliseconds `json:"frame_preprocessing_time,omitempty" validate:"omitempty"`
	InputFramesCountValue       *int          `json:"input_frames_count,omitempty" validate:"omitempty"`
	ProcessedFramesCountValue   *int          `json:"processed_frames_count,omitempty" validate:"omitempty"`
	ProcessingErrorsCountValue  *int          `json:"processing_errors_count,omitempty" validate:"omitempty"`
	ProcessingTimeValue         *Milliseconds `json:"processing_time,omitempty" validate:"omitempty"`
	ProcessingWaitTimeValue     *Milliseconds `json:"processing_wait_time,omitempty" validate:"omitempty"`
}

type VisionMetricsInferenceImpl struct {
	DetectionTimeValue                      *Milliseconds `json:"detection_time,omitempty" validate:"omitempty"`
	DetectionsAcceptedAreaValue             *float64      `json:"detections_accepted_area,omitempty" validate:"omitempty,min=0"`
	DetectionsAcceptedConfidenceValue       *float64      `json:"detections_accepted_confidence,omitempty" validate:"omitempty,min=0"`
	DetectionsAcceptedCountValue            *int          `json:"detections_accepted_count,omitempty" validate:"omitempty"`
	DetectionsAreaValue                     *float64      `json:"detections_area,omitempty" validate:"omitempty,min=0"`
	DetectionsAreaRejectedCountValue        *int          `json:"detections_area_rejected_count,omitempty" validate:"omitempty,min=0"`
	DetectionsConfidenceValue               *float64      `json:"detections_confidence,omitempty" validate:"omitempty,min=0"`
	DetectionsConfidenceRejectedCountValue  *int          `json:"detections_confidence_rejected_count,omitempty" validate:"omitempty,min=0"`
	DetectionsCountValue                    *int          `json:"detections_count,omitempty" validate:"omitempty"`
	DetectionsOrientationRejectedCountValue *int          `json:"detections_orientation_rejected_count,omitempty" validate:"omitempty,min=0"`
	DeviceTransferTimeValue                 *Milliseconds `json:"device_transfer_time,omitempty" validate:"omitempty"`
	DeviceTransferredBytesValue             *Bytes        `json:"device_transferred_bytes,omitempty" validate:"omitempty"`
	FingerprintSerializationTimeValue       *Milliseconds `json:"fingerprint_serialization_time,omitempty" validate:"omitempty"`
	FingerprintingTimeValue                 *Milliseconds `json:"fingerprinting_time,omitempty" validate:"omitempty"`
	FingerprintsAcceptedConfidenceValue     *float64      `json:"fingerprints_accepted_confidence,omitempty" validate:"omitempty,min=0"`
	FingerprintsAcceptedCountValue          *int          `json:"fingerprints_accepted_count,omitempty" validate:"omitempty"`
	FingerprintsConfidenceValue             *float64      `json:"fingerprints_confidence,omitempty" validate:"omitempty,min=0"`
	FingerprintsCountValue                  *int          `json:"fingerprints_count,omitempty" validate:"omitempty"`
	HostTransferTimeValue                   *Milliseconds `json:"host_transfer_time,omitempty" validate:"omitempty"`
	HostTransferredBytesValue               *Bytes        `json:"host_transferred_bytes,omitempty" validate:"omitempty"`
}

// Person
// Required: person_id, updated_at, originator
type VisionPersonImpl struct {
	DeletedAtValue    *UtcMs                       `json:"deleted_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	ExternalIDValue   *string                      `json:"external_id,omitempty" validate:"omitempty"`
	OriginatorValue   VisionPersonOriginator       `json:"originator" validate:"required,oneof=api identification_service"`
	FingerprintsValue []*VisionFaceFingerprintImpl `json:"fingerprints,omitempty" validate:"omitempty"`
	PersonIDValue     SnowflakeID                  `json:"person_id" validate:"required"`
	UpdatedAtValue    UtcMs                        `json:"updated_at" validate:"required,min=1e+12,max=1e+13"`
}

// Person matching information
// Required: person, match_score
type VisionPersonMatchImpl struct {
	PersonValue     *VisionPersonImpl `json:"person" validate:"required"`
	MatchScoreValue float64           `json:"match_score" validate:"required"`
}

// 2D point
// Required: x, y
type VisionPointImpl struct {
	XValue float64 `json:"x" validate:"required,min=0,max=1"`
	YValue float64 `json:"y" validate:"required,min=0,max=1"`
}

type VisionProcessResultImpl struct {
	EpisodesValue []*EpisodeImpl `json:"episodes,omitempty" validate:"omitempty"`
}

type VisionServerDevicesImpl struct {
	DevicesValue []*VisionDeviceInfoImpl `json:"devices,omitempty" validate:"omitempty"`
}

type VisionServerInfoImpl struct {
	BuildValue         *int           `json:"build,omitempty" validate:"omitempty"`
	NowValue           *UtcMs         `json:"now,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	SchemaVersionValue *string        `json:"schema_version,omitempty" validate:"omitempty"`
	ServerVersionValue *ServerVersion `json:"server_version,omitempty" validate:"omitempty"`
	StartedAtValue     *Utc           `json:"started_at,omitempty" validate:"omitempty,min=1e+09,max=1e+10"`
}

type VisionSpecImpl struct {
	AlgValue       *VisionSpecAlg              `json:"alg,omitempty" validate:"omitempty,oneof=faces plates"`
	AreasValue     *string                     `json:"areas,omitempty" validate:"omitempty"`
	StatsValue     *VisionStatsImpl            `json:"stats,omitempty" validate:"omitempty"`
	DetectorsValue []*VisionDetectorConfigImpl `json:"detectors,omitempty" validate:"omitempty"`
}

type VisionStatsImpl struct {
	LastDetectionAtValue *UtcMs `json:"last_detection_at,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
}

type VisionVehicleAttributesImpl struct {
	LicensePlateMissingValue *bool                 `json:"license_plate_missing,omitempty" validate:"omitempty"`
	PurposeValue             *VisionVehiclePurpose `json:"purpose,omitempty" validate:"omitempty"`
}

type VisionWorkerStatsImpl struct {
	BuildValue         *int                    `json:"build,omitempty" validate:"omitempty"`
	NowValue           *UtcMs                  `json:"now,omitempty" validate:"omitempty,min=1e+12,max=1e+13"`
	SchemaVersionValue *string                 `json:"schema_version,omitempty" validate:"omitempty"`
	ServerVersionValue *ServerVersion          `json:"server_version,omitempty" validate:"omitempty"`
	StartedAtValue     *Utc                    `json:"started_at,omitempty" validate:"omitempty,min=1e+09,max=1e+10"`
	DevicesValue       []*VisionDeviceInfoImpl `json:"devices,omitempty" validate:"omitempty"`
}

// NewCollectionResponse creates a new CollectionResponse instance
func NewCollectionResponse() CollectionResponse {
	return &CollectionResponseImpl{}
}

// Estimated total number of records for the query (regardless of the cursors).
// Example: 5
func (s CollectionResponseImpl) EstimatedCount() *int {
	return s.EstimatedCountValue
}

// Estimated total number of records for the query (regardless of the cursors).
// Example: 5
func (s *CollectionResponseImpl) SetEstimatedCount(v int) CollectionResponse {
	if s == nil {
		return nil
	}
	s.EstimatedCountValue = &v
	return s
}

// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fZ3Q9MA==
func (s CollectionResponseImpl) Next() *string {
	return s.NextValue
}

// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fZ3Q9MA==
func (s *CollectionResponseImpl) SetNext(v string) CollectionResponse {
	if s == nil {
		return nil
	}
	s.NextValue = &v
	return s
}

// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
func (s CollectionResponseImpl) Prev() *string {
	return s.PrevValue
}

// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
func (s *CollectionResponseImpl) SetPrev(v string) CollectionResponse {
	if s == nil {
		return nil
	}
	s.PrevValue = &v
	return s
}

// An object with a list of different timings measured during this API call.
func (s CollectionResponseImpl) Timing() any {
	return s.TimingValue
}

// An object with a list of different timings measured during this API call.
func (s *CollectionResponseImpl) SetTiming(v any) CollectionResponse {
	if s == nil {
		return nil
	}
	s.TimingValue = v
	return s
}

// NewConfigVision creates a new ConfigVision instance
func NewConfigVision() ConfigVision {
	return &ConfigVisionImpl{}
}

// Key used for HTTP API authorization
// Example: secret
func (s ConfigVisionImpl) APIKey() *string {
	return s.APIKeyValue
}

// Key used for HTTP API authorization
// Example: secret
func (s *ConfigVisionImpl) SetAPIKey(v string) ConfigVision {
	if s == nil {
		return nil
	}
	s.APIKeyValue = &v
	return s
}

// External configuration backend settings
func (s ConfigVisionImpl) ConfigExternal() VisionConfigExternal {
	return s.ConfigExternalValue
}

// External configuration backend settings
func (s *ConfigVisionImpl) SetConfigExternal(v VisionConfigExternal) ConfigVision {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionConfigExternalImpl); ok {
		s.ConfigExternalValue = impl
	}
	return s
}

// Devices used for inference
func (s ConfigVisionImpl) Devices() []VisionInferenceDevice {
	if s.DevicesValue == nil {
		return nil
	}
	result := make([]VisionInferenceDevice, len(s.DevicesValue))
	for i, item := range s.DevicesValue {
		result[i] = item
	}
	return result
}

// Devices used for inference
func (s *ConfigVisionImpl) SetDevices(v []VisionInferenceDevice) ConfigVision {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionInferenceDeviceImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionInferenceDeviceImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.DevicesValue = impl
	}
	return s
}

// The configuration of network listeners
func (s ConfigVisionImpl) Listeners() Listeners {
	return s.ListenersValue
}

// The configuration of network listeners
func (s *ConfigVisionImpl) SetListeners(v Listeners) ConfigVision {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*ListenersImpl); ok {
		s.ListenersValue = impl
	}
	return s
}

// The level of logging according to event importance
func (s ConfigVisionImpl) Loglevel() *VisionLoglevel {
	return s.LoglevelValue
}

// The level of logging according to event importance
func (s *ConfigVisionImpl) SetLoglevel(v VisionLoglevel) ConfigVision {
	if s == nil {
		return nil
	}
	s.LoglevelValue = &v
	return s
}

// Server runtime stats
func (s ConfigVisionImpl) Stats() ConfigVisionStats {
	return s.StatsValue
}

// Server runtime stats
func (s *ConfigVisionImpl) SetStats(v ConfigVisionStats) ConfigVision {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*ConfigVisionStatsImpl); ok {
		s.StatsValue = impl
	}
	return s
}

// NewConfigVisionStats creates a new ConfigVisionStats instance
func NewConfigVisionStats() ConfigVisionStats {
	return &ConfigVisionStatsImpl{}
}

// Indicates which modules are enabled in the inference service
func (s ConfigVisionStatsImpl) AvailableModules() VisionContextSearchModule {
	return s.AvailableModulesValue
}

// Indicates which modules are enabled in the inference service
func (s *ConfigVisionStatsImpl) SetAvailableModules(v VisionContextSearchModule) ConfigVisionStats {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionContextSearchModuleImpl); ok {
		s.AvailableModulesValue = impl
	}
	return s
}

// Build version
// Example: 235
func (s ConfigVisionStatsImpl) Build() *int {
	return s.BuildValue
}

// Build version
// Example: 235
func (s *ConfigVisionStatsImpl) SetBuild(v int) ConfigVisionStats {
	if s == nil {
		return nil
	}
	s.BuildValue = &v
	return s
}

// Devices list available for running vision.
func (s ConfigVisionStatsImpl) Devices() []VisionDeviceInfo {
	if s.DevicesValue == nil {
		return nil
	}
	result := make([]VisionDeviceInfo, len(s.DevicesValue))
	for i, item := range s.DevicesValue {
		result[i] = item
	}
	return result
}

// Devices list available for running vision.
func (s *ConfigVisionStatsImpl) SetDevices(v []VisionDeviceInfo) ConfigVisionStats {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionDeviceInfoImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionDeviceInfoImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.DevicesValue = impl
	}
	return s
}

// Server's current timestamp
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.639337825e+12
func (s ConfigVisionStatsImpl) Now() *UtcMs {
	return s.NowValue
}

// Server's current timestamp
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.639337825e+12
func (s *ConfigVisionStatsImpl) SetNow(v UtcMs) ConfigVisionStats {
	if s == nil {
		return nil
	}
	s.NowValue = &v
	return s
}

// API schema revision implemented in this version of the server
// Example: 5e5e91d8
func (s ConfigVisionStatsImpl) SchemaVersion() *string {
	return s.SchemaVersionValue
}

// API schema revision implemented in this version of the server
// Example: 5e5e91d8
func (s *ConfigVisionStatsImpl) SetSchemaVersion(v string) ConfigVisionStats {
	if s == nil {
		return nil
	}
	s.SchemaVersionValue = &v
	return s
}

// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
// Format: server_version (server_version)
// Example: 21.12
func (s ConfigVisionStatsImpl) ServerVersion() *ServerVersion {
	return s.ServerVersionValue
}

// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
// Format: server_version (server_version)
// Example: 21.12
func (s *ConfigVisionStatsImpl) SetServerVersion(v ServerVersion) ConfigVisionStats {
	if s == nil {
		return nil
	}
	s.ServerVersionValue = &v
	return s
}

// Timestamp when this instance was started
// Format: utc (Unix timestamp in seconds)
// Example: 1.639337825e+09
func (s ConfigVisionStatsImpl) StartedAt() *Utc {
	return s.StartedAtValue
}

// Timestamp when this instance was started
// Format: utc (Unix timestamp in seconds)
// Example: 1.639337825e+09
func (s *ConfigVisionStatsImpl) SetStartedAt(v Utc) ConfigVisionStats {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// NewCounterRecordsList creates a new CounterRecordsList instance
func NewCounterRecordsList() CounterRecordsList {
	return &CounterRecordsListImpl{}
}

// Estimated total number of records for the query (regardless of the cursors).
// Example: 5
func (s CounterRecordsListImpl) EstimatedCount() *int {
	return s.EstimatedCountValue
}

// Estimated total number of records for the query (regardless of the cursors).
// Example: 5
func (s *CounterRecordsListImpl) SetEstimatedCount(v int) CounterRecordsList {
	if s == nil {
		return nil
	}
	s.EstimatedCountValue = &v
	return s
}

// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fZ3Q9MA==
func (s CounterRecordsListImpl) Next() *string {
	return s.NextValue
}

// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fZ3Q9MA==
func (s *CounterRecordsListImpl) SetNext(v string) CounterRecordsList {
	if s == nil {
		return nil
	}
	s.NextValue = &v
	return s
}

// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
func (s CounterRecordsListImpl) Prev() *string {
	return s.PrevValue
}

// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
func (s *CounterRecordsListImpl) SetPrev(v string) CounterRecordsList {
	if s == nil {
		return nil
	}
	s.PrevValue = &v
	return s
}

// The list of Counter records fetched according to the query parameters.
func (s CounterRecordsListImpl) Records() []VisionCounterRecord {
	if s.RecordsValue == nil {
		return nil
	}
	result := make([]VisionCounterRecord, len(s.RecordsValue))
	for i, item := range s.RecordsValue {
		result[i] = item
	}
	return result
}

// The list of Counter records fetched according to the query parameters.
func (s *CounterRecordsListImpl) SetRecords(v []VisionCounterRecord) CounterRecordsList {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionCounterRecordImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionCounterRecordImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.RecordsValue = impl
	}
	return s
}

// An object with a list of different timings measured during this API call.
func (s CounterRecordsListImpl) Timing() any {
	return s.TimingValue
}

// An object with a list of different timings measured during this API call.
func (s *CounterRecordsListImpl) SetTiming(v any) CounterRecordsList {
	if s == nil {
		return nil
	}
	s.TimingValue = v
	return s
}

// Collection returns the collection items from CounterRecordsList
func (s CounterRecordsListImpl) Collection() []VisionCounterRecord {
	return s.Records()
}

// NewEpisode creates a new Episode instance
func NewEpisode() Episode {
	return &EpisodeImpl{}
}

// The reason for closing the episode.
func (s EpisodeImpl) CloseReason() *EpisodeCloseReason {
	return s.CloseReasonValue
}

// The reason for closing the episode.
func (s *EpisodeImpl) SetCloseReason(v EpisodeCloseReason) Episode {
	if s == nil {
		return nil
	}
	s.CloseReasonValue = &v
	return s
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeImpl) ClosedAt() *UtcMs {
	return s.ClosedAtValue
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeImpl) SetClosedAt(v UtcMs) Episode {
	if s == nil {
		return nil
	}
	s.ClosedAtValue = &v
	return s
}

// Detections associated with this episode
func (s EpisodeImpl) Detections() any {
	return s.DetectionsValue
}

// Detections associated with this episode
func (s *EpisodeImpl) SetDetections(v any) Episode {
	if s == nil {
		return nil
	}
	s.DetectionsValue = v
	return s
}

// The time when the episode appeared in the service relative to the server time.
func (s EpisodeImpl) EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return s.EpisodeAppearanceTimestampsValue
}

// The time when the episode appeared in the service relative to the server time.
func (s *EpisodeImpl) SetEpisodeAppearanceTimestamps(v EpisodeAppearanceTimestamps) Episode {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*EpisodeAppearanceTimestampsImpl); ok {
		s.EpisodeAppearanceTimestampsValue = impl
	}
	return s
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s EpisodeImpl) EpisodeID() SnowflakeID {
	return s.EpisodeIDValue
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s *EpisodeImpl) SetEpisodeID(v SnowflakeID) Episode {
	if s == nil {
		return nil
	}
	s.EpisodeIDValue = v
	return s
}

// Generic stream episode/Face is detected/Vehicle is detected/Human is detected/Episode matches context search text query/QR-code is detected/Custom episode type.
// Use this field to define your own episode types when integrating custom analytics.
// If episode type is not specified, episode will be saved with `generic` type.
func (s EpisodeImpl) EpisodeType() *string {
	return s.EpisodeTypeValue
}

// Generic stream episode/Face is detected/Vehicle is detected/Human is detected/Episode matches context search text query/QR-code is detected/Custom episode type.
// Use this field to define your own episode types when integrating custom analytics.
// If episode type is not specified, episode will be saved with `generic` type.
func (s *EpisodeImpl) SetEpisodeType(v string) Episode {
	if s == nil {
		return nil
	}
	s.EpisodeTypeValue = &v
	return s
}

// The fingerprint of the detected face
func (s EpisodeImpl) Fingerprint() VisionFaceFingerprint {
	return s.FingerprintValue
}

// The fingerprint of the detected face
func (s *EpisodeImpl) SetFingerprint(v VisionFaceFingerprint) Episode {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionFaceFingerprintImpl); ok {
		s.FingerprintValue = impl
	}
	return s
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s EpisodeImpl) FramePreview() *Base64 {
	return s.FramePreviewValue
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s *EpisodeImpl) SetFramePreview(v Base64) Episode {
	if s == nil {
		return nil
	}
	s.FramePreviewValue = &v
	return s
}

// Indicates if no license plate is detected on this vehicle
func (s EpisodeImpl) LicensePlateMissing() *bool {
	return s.LicensePlateMissingValue
}

// Indicates if no license plate is detected on this vehicle
func (s *EpisodeImpl) SetLicensePlateMissing(v bool) Episode {
	if s == nil {
		return nil
	}
	s.LicensePlateMissingValue = &v
	return s
}

// Recognized vehicle's license plate number
func (s EpisodeImpl) LicensePlateText() *string {
	return s.LicensePlateTextValue
}

// Recognized vehicle's license plate number
func (s *EpisodeImpl) SetLicensePlateText(v string) Episode {
	if s == nil {
		return nil
	}
	s.LicensePlateTextValue = &v
	return s
}

// Maximum matching score between the text query and episode.
// Examples: 0.2345
func (s EpisodeImpl) MatchScore() *float64 {
	return s.MatchScoreValue
}

// Maximum matching score between the text query and episode.
// Examples: 0.2345
func (s *EpisodeImpl) SetMatchScore(v float64) Episode {
	if s == nil {
		return nil
	}
	s.MatchScoreValue = &v
	return s
}

// List of matched persons with similarity metric.
// Videoanalytics identification service enriches episode's data and fills this field
// with the list of persons that are similar to the face detected in this episode.
func (s EpisodeImpl) MatchedPersons() []VisionPersonMatch {
	if s.MatchedPersonsValue == nil {
		return nil
	}
	result := make([]VisionPersonMatch, len(s.MatchedPersonsValue))
	for i, item := range s.MatchedPersonsValue {
		result[i] = item
	}
	return result
}

// List of matched persons with similarity metric.
// Videoanalytics identification service enriches episode's data and fills this field
// with the list of persons that are similar to the face detected in this episode.
func (s *EpisodeImpl) SetMatchedPersons(v []VisionPersonMatch) Episode {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionPersonMatchImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionPersonMatchImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.MatchedPersonsValue = impl
	}
	return s
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s EpisodeImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s *EpisodeImpl) SetMedia(v MediaName) Episode {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeImpl) SetOpenedAt(v UtcMs) Episode {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Raw data extracted from QR-code/Custom episode payload. Use this field to provide additional information about the episode.
func (s EpisodeImpl) Payload() any {
	return s.PayloadValue
}

// Raw data extracted from QR-code/Custom episode payload. Use this field to provide additional information about the episode.
func (s *EpisodeImpl) SetPayload(v any) Episode {
	if s == nil {
		return nil
	}
	s.PayloadValue = v
	return s
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// /Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Preview contains an image of person's face and has a resolution about 200 x 200 pixels with maximum size about 10 kilobytes.
// /Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Preview contains an image of vehicle's license plate and has a resolution about 160 x 64 pixels with maximum size about 10 kilobytes.
func (s EpisodeImpl) Preview() *Base64 {
	return s.PreviewValue
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// /Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Preview contains an image of person's face and has a resolution about 200 x 200 pixels with maximum size about 10 kilobytes.
// /Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Preview contains an image of vehicle's license plate and has a resolution about 160 x 64 pixels with maximum size about 10 kilobytes.
func (s *EpisodeImpl) SetPreview(v Base64) Episode {
	if s == nil {
		return nil
	}
	s.PreviewValue = &v
	return s
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeImpl) PreviewTimestamp() *UtcMs {
	return s.PreviewTimestampValue
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeImpl) SetPreviewTimestamp(v UtcMs) Episode {
	if s == nil {
		return nil
	}
	s.PreviewTimestampValue = &v
	return s
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeImpl) StartedAt() *UtcMs {
	return s.StartedAtValue
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeImpl) SetStartedAt(v UtcMs) Episode {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s EpisodeImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s *EpisodeImpl) SetUpdatedAt(v UtcMs) Episode {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// Emergency type of the vehicle.
func (s EpisodeImpl) VehicleEmergencySubtype() *VisionVehicleEmergencySubtype {
	return s.VehicleEmergencySubtypeValue
}

// Emergency type of the vehicle.
func (s *EpisodeImpl) SetVehicleEmergencySubtype(v VisionVehicleEmergencySubtype) Episode {
	if s == nil {
		return nil
	}
	s.VehicleEmergencySubtypeValue = &v
	return s
}

// Shows from which side the vehicle was detected.
func (s EpisodeImpl) VehicleFacingSide() *VisionVehicleFacingSide {
	return s.VehicleFacingSideValue
}

// Shows from which side the vehicle was detected.
func (s *EpisodeImpl) SetVehicleFacingSide(v VisionVehicleFacingSide) Episode {
	if s == nil {
		return nil
	}
	s.VehicleFacingSideValue = &v
	return s
}

// The purpose of the vehicle, e.g. emergency or regular.
func (s EpisodeImpl) VehiclePurpose() *VisionVehiclePurpose {
	return s.VehiclePurposeValue
}

// The purpose of the vehicle, e.g. emergency or regular.
func (s *EpisodeImpl) SetVehiclePurpose(v VisionVehiclePurpose) Episode {
	if s == nil {
		return nil
	}
	s.VehiclePurposeValue = &v
	return s
}

// NewEpisodeAppearanceTimestamps creates a new EpisodeAppearanceTimestamps instance
func NewEpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return &EpisodeAppearanceTimestampsImpl{}
}

// The time when this episode was created in inference service.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s EpisodeAppearanceTimestampsImpl) InferenceTimestamp() *UtcMs {
	return s.InferenceTimestampValue
}

// The time when this episode was created in inference service.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s *EpisodeAppearanceTimestampsImpl) SetInferenceTimestamp(v UtcMs) EpisodeAppearanceTimestamps {
	if s == nil {
		return nil
	}
	s.InferenceTimestampValue = &v
	return s
}

// NewEpisodeBase creates a new EpisodeBase instance
func NewEpisodeBase() EpisodeBase {
	return &EpisodeBaseImpl{}
}

// The reason for closing the episode.
func (s EpisodeBaseImpl) CloseReason() *EpisodeCloseReason {
	return s.CloseReasonValue
}

// The reason for closing the episode.
func (s *EpisodeBaseImpl) SetCloseReason(v EpisodeCloseReason) EpisodeBase {
	if s == nil {
		return nil
	}
	s.CloseReasonValue = &v
	return s
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeBaseImpl) ClosedAt() *UtcMs {
	return s.ClosedAtValue
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeBaseImpl) SetClosedAt(v UtcMs) EpisodeBase {
	if s == nil {
		return nil
	}
	s.ClosedAtValue = &v
	return s
}

// The time when the episode appeared in the service relative to the server time.
func (s EpisodeBaseImpl) EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return s.EpisodeAppearanceTimestampsValue
}

// The time when the episode appeared in the service relative to the server time.
func (s *EpisodeBaseImpl) SetEpisodeAppearanceTimestamps(v EpisodeAppearanceTimestamps) EpisodeBase {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*EpisodeAppearanceTimestampsImpl); ok {
		s.EpisodeAppearanceTimestampsValue = impl
	}
	return s
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s EpisodeBaseImpl) EpisodeID() SnowflakeID {
	return s.EpisodeIDValue
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s *EpisodeBaseImpl) SetEpisodeID(v SnowflakeID) EpisodeBase {
	if s == nil {
		return nil
	}
	s.EpisodeIDValue = v
	return s
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s EpisodeBaseImpl) FramePreview() *Base64 {
	return s.FramePreviewValue
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s *EpisodeBaseImpl) SetFramePreview(v Base64) EpisodeBase {
	if s == nil {
		return nil
	}
	s.FramePreviewValue = &v
	return s
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s EpisodeBaseImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s *EpisodeBaseImpl) SetMedia(v MediaName) EpisodeBase {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeBaseImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeBaseImpl) SetOpenedAt(v UtcMs) EpisodeBase {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s EpisodeBaseImpl) Preview() *Base64 {
	return s.PreviewValue
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s *EpisodeBaseImpl) SetPreview(v Base64) EpisodeBase {
	if s == nil {
		return nil
	}
	s.PreviewValue = &v
	return s
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeBaseImpl) PreviewTimestamp() *UtcMs {
	return s.PreviewTimestampValue
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeBaseImpl) SetPreviewTimestamp(v UtcMs) EpisodeBase {
	if s == nil {
		return nil
	}
	s.PreviewTimestampValue = &v
	return s
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeBaseImpl) StartedAt() *UtcMs {
	return s.StartedAtValue
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeBaseImpl) SetStartedAt(v UtcMs) EpisodeBase {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s EpisodeBaseImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s *EpisodeBaseImpl) SetUpdatedAt(v UtcMs) EpisodeBase {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// NewEpisodeCustom creates a new EpisodeCustom instance
func NewEpisodeCustom() EpisodeCustom {
	return &EpisodeCustomImpl{}
}

// The reason for closing the episode.
func (s EpisodeCustomImpl) CloseReason() *EpisodeCloseReason {
	return s.CloseReasonValue
}

// The reason for closing the episode.
func (s *EpisodeCustomImpl) SetCloseReason(v EpisodeCloseReason) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.CloseReasonValue = &v
	return s
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeCustomImpl) ClosedAt() *UtcMs {
	return s.ClosedAtValue
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeCustomImpl) SetClosedAt(v UtcMs) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.ClosedAtValue = &v
	return s
}

// The time when the episode appeared in the service relative to the server time.
func (s EpisodeCustomImpl) EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return s.EpisodeAppearanceTimestampsValue
}

// The time when the episode appeared in the service relative to the server time.
func (s *EpisodeCustomImpl) SetEpisodeAppearanceTimestamps(v EpisodeAppearanceTimestamps) EpisodeCustom {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*EpisodeAppearanceTimestampsImpl); ok {
		s.EpisodeAppearanceTimestampsValue = impl
	}
	return s
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s EpisodeCustomImpl) EpisodeID() SnowflakeID {
	return s.EpisodeIDValue
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s *EpisodeCustomImpl) SetEpisodeID(v SnowflakeID) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.EpisodeIDValue = v
	return s
}

// Custom episode type.
// Use this field to define your own episode types when integrating custom analytics.
// If episode type is not specified, episode will be saved with `generic` type.
func (s EpisodeCustomImpl) EpisodeType() *string {
	return s.EpisodeTypeValue
}

// Custom episode type.
// Use this field to define your own episode types when integrating custom analytics.
// If episode type is not specified, episode will be saved with `generic` type.
func (s *EpisodeCustomImpl) SetEpisodeType(v string) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.EpisodeTypeValue = &v
	return s
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s EpisodeCustomImpl) FramePreview() *Base64 {
	return s.FramePreviewValue
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s *EpisodeCustomImpl) SetFramePreview(v Base64) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.FramePreviewValue = &v
	return s
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s EpisodeCustomImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s *EpisodeCustomImpl) SetMedia(v MediaName) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeCustomImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeCustomImpl) SetOpenedAt(v UtcMs) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Custom episode payload. Use this field to provide additional information about the episode.
func (s EpisodeCustomImpl) Payload() any {
	return s.PayloadValue
}

// Custom episode payload. Use this field to provide additional information about the episode.
func (s *EpisodeCustomImpl) SetPayload(v any) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.PayloadValue = v
	return s
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s EpisodeCustomImpl) Preview() *Base64 {
	return s.PreviewValue
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s *EpisodeCustomImpl) SetPreview(v Base64) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.PreviewValue = &v
	return s
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeCustomImpl) PreviewTimestamp() *UtcMs {
	return s.PreviewTimestampValue
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeCustomImpl) SetPreviewTimestamp(v UtcMs) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.PreviewTimestampValue = &v
	return s
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeCustomImpl) StartedAt() *UtcMs {
	return s.StartedAtValue
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeCustomImpl) SetStartedAt(v UtcMs) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s EpisodeCustomImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s *EpisodeCustomImpl) SetUpdatedAt(v UtcMs) EpisodeCustom {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// NewEpisodeGeneric creates a new EpisodeGeneric instance
func NewEpisodeGeneric() EpisodeGeneric {
	return &EpisodeGenericImpl{}
}

// The reason for closing the episode.
func (s EpisodeGenericImpl) CloseReason() *EpisodeCloseReason {
	return s.CloseReasonValue
}

// The reason for closing the episode.
func (s *EpisodeGenericImpl) SetCloseReason(v EpisodeCloseReason) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.CloseReasonValue = &v
	return s
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeGenericImpl) ClosedAt() *UtcMs {
	return s.ClosedAtValue
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeGenericImpl) SetClosedAt(v UtcMs) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.ClosedAtValue = &v
	return s
}

// The time when the episode appeared in the service relative to the server time.
func (s EpisodeGenericImpl) EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return s.EpisodeAppearanceTimestampsValue
}

// The time when the episode appeared in the service relative to the server time.
func (s *EpisodeGenericImpl) SetEpisodeAppearanceTimestamps(v EpisodeAppearanceTimestamps) EpisodeGeneric {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*EpisodeAppearanceTimestampsImpl); ok {
		s.EpisodeAppearanceTimestampsValue = impl
	}
	return s
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s EpisodeGenericImpl) EpisodeID() SnowflakeID {
	return s.EpisodeIDValue
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s *EpisodeGenericImpl) SetEpisodeID(v SnowflakeID) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.EpisodeIDValue = v
	return s
}

// Generic stream episode
func (s EpisodeGenericImpl) EpisodeType() *string {
	return s.EpisodeTypeValue
}

// Generic stream episode
func (s *EpisodeGenericImpl) SetEpisodeType(v string) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.EpisodeTypeValue = &v
	return s
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s EpisodeGenericImpl) FramePreview() *Base64 {
	return s.FramePreviewValue
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s *EpisodeGenericImpl) SetFramePreview(v Base64) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.FramePreviewValue = &v
	return s
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s EpisodeGenericImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s *EpisodeGenericImpl) SetMedia(v MediaName) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeGenericImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeGenericImpl) SetOpenedAt(v UtcMs) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s EpisodeGenericImpl) Preview() *Base64 {
	return s.PreviewValue
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s *EpisodeGenericImpl) SetPreview(v Base64) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.PreviewValue = &v
	return s
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeGenericImpl) PreviewTimestamp() *UtcMs {
	return s.PreviewTimestampValue
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeGenericImpl) SetPreviewTimestamp(v UtcMs) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.PreviewTimestampValue = &v
	return s
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s EpisodeGenericImpl) StartedAt() *UtcMs {
	return s.StartedAtValue
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *EpisodeGenericImpl) SetStartedAt(v UtcMs) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s EpisodeGenericImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s *EpisodeGenericImpl) SetUpdatedAt(v UtcMs) EpisodeGeneric {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// NewEpisodesList creates a new EpisodesList instance
func NewEpisodesList() EpisodesList {
	return &EpisodesListImpl{}
}

// The list of Episodes fetched according to the query parameters.
func (s EpisodesListImpl) Episodes() []Episode {
	if s.EpisodesValue == nil {
		return nil
	}
	result := make([]Episode, len(s.EpisodesValue))
	for i, item := range s.EpisodesValue {
		result[i] = item
	}
	return result
}

// The list of Episodes fetched according to the query parameters.
func (s *EpisodesListImpl) SetEpisodes(v []Episode) EpisodesList {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*EpisodeImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*EpisodeImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.EpisodesValue = impl
	}
	return s
}

// Estimated total number of records for the query (regardless of the cursors).
// Example: 5
func (s EpisodesListImpl) EstimatedCount() *int {
	return s.EstimatedCountValue
}

// Estimated total number of records for the query (regardless of the cursors).
// Example: 5
func (s *EpisodesListImpl) SetEstimatedCount(v int) EpisodesList {
	if s == nil {
		return nil
	}
	s.EstimatedCountValue = &v
	return s
}

// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fZ3Q9MA==
func (s EpisodesListImpl) Next() *string {
	return s.NextValue
}

// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fZ3Q9MA==
func (s *EpisodesListImpl) SetNext(v string) EpisodesList {
	if s == nil {
		return nil
	}
	s.NextValue = &v
	return s
}

// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
func (s EpisodesListImpl) Prev() *string {
	return s.PrevValue
}

// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
func (s *EpisodesListImpl) SetPrev(v string) EpisodesList {
	if s == nil {
		return nil
	}
	s.PrevValue = &v
	return s
}

// An object with a list of different timings measured during this API call.
func (s EpisodesListImpl) Timing() any {
	return s.TimingValue
}

// An object with a list of different timings measured during this API call.
func (s *EpisodesListImpl) SetTiming(v any) EpisodesList {
	if s == nil {
		return nil
	}
	s.TimingValue = v
	return s
}

// Collection returns the collection items from EpisodesList
func (s EpisodesListImpl) Collection() []Episode {
	return s.Episodes()
}

// NewListenConfig creates a new ListenConfig instance
func NewListenConfig() ListenConfig {
	return &ListenConfigImpl{}
}

// Network address that will be used for listening.
// Example: 10.0.35.1
func (s ListenConfigImpl) Address() *string {
	return s.AddressValue
}

// Network address that will be used for listening.
// Example: 10.0.35.1
func (s *ListenConfigImpl) SetAddress(v string) ListenConfig {
	if s == nil {
		return nil
	}
	s.AddressValue = &v
	return s
}

// Port that will be used for listening.
// Format: network_port (network_port)
// Example: 80
func (s ListenConfigImpl) Port() NetworkPort {
	return s.PortValue
}

// Port that will be used for listening.
// Format: network_port (network_port)
// Example: 80
func (s *ListenConfigImpl) SetPort(v NetworkPort) ListenConfig {
	if s == nil {
		return nil
	}
	s.PortValue = v
	return s
}

// NewListenHTTPConfig creates a new ListenHTTPConfig instance
func NewListenHTTPConfig() ListenHTTPConfig {
	return &ListenHTTPConfigImpl{}
}

// Network address that will be used for listening.
// Example: 10.0.35.1
func (s ListenHTTPConfigImpl) Address() *string {
	return s.AddressValue
}

// Network address that will be used for listening.
// Example: 10.0.35.1
func (s *ListenHTTPConfigImpl) SetAddress(v string) ListenHTTPConfig {
	if s == nil {
		return nil
	}
	s.AddressValue = &v
	return s
}

// If false, listener do not serve api calls.
func (s ListenHTTPConfigImpl) API() *bool {
	return s.APIValue
}

// If false, listener do not serve api calls.
func (s *ListenHTTPConfigImpl) SetAPI(v bool) ListenHTTPConfig {
	if s == nil {
		return nil
	}
	s.APIValue = &v
	return s
}

// Port that will be used for listening.
// Format: network_port (network_port)
// Example: 80
func (s ListenHTTPConfigImpl) Port() NetworkPort {
	return s.PortValue
}

// Port that will be used for listening.
// Format: network_port (network_port)
// Example: 80
func (s *ListenHTTPConfigImpl) SetPort(v NetworkPort) ListenHTTPConfig {
	if s == nil {
		return nil
	}
	s.PortValue = v
	return s
}

// NewListenHTTPConfigParams creates a new ListenHTTPConfigParams instance
func NewListenHTTPConfigParams() ListenHTTPConfigParams {
	return &ListenHTTPConfigParamsImpl{}
}

// If false, listener do not serve api calls.
func (s ListenHTTPConfigParamsImpl) API() *bool {
	return s.APIValue
}

// If false, listener do not serve api calls.
func (s *ListenHTTPConfigParamsImpl) SetAPI(v bool) ListenHTTPConfigParams {
	if s == nil {
		return nil
	}
	s.APIValue = &v
	return s
}

// NewListenHTTPSConfig creates a new ListenHTTPSConfig instance
func NewListenHTTPSConfig() ListenHTTPSConfig {
	return &ListenHTTPSConfigImpl{}
}

// Network address that will be used for listening.
// Example: 10.0.35.1
func (s ListenHTTPSConfigImpl) Address() *string {
	return s.AddressValue
}

// Network address that will be used for listening.
// Example: 10.0.35.1
func (s *ListenHTTPSConfigImpl) SetAddress(v string) ListenHTTPSConfig {
	if s == nil {
		return nil
	}
	s.AddressValue = &v
	return s
}

// If false, listener do not serve api calls.
func (s ListenHTTPSConfigImpl) API() *bool {
	return s.APIValue
}

// If false, listener do not serve api calls.
func (s *ListenHTTPSConfigImpl) SetAPI(v bool) ListenHTTPSConfig {
	if s == nil {
		return nil
	}
	s.APIValue = &v
	return s
}

// Port that will be used for listening.
// Format: network_port (network_port)
// Example: 80
func (s ListenHTTPSConfigImpl) Port() NetworkPort {
	return s.PortValue
}

// Port that will be used for listening.
// Format: network_port (network_port)
// Example: 80
func (s *ListenHTTPSConfigImpl) SetPort(v NetworkPort) ListenHTTPSConfig {
	if s == nil {
		return nil
	}
	s.PortValue = v
	return s
}

// List of SSL protocol versions that will be used for listening.
// Example: [tlsv1.1 tlsv1.2]
func (s ListenHTTPSConfigImpl) SslProtocols() []TlsVersion {
	return s.SslProtocolsValue
}

// List of SSL protocol versions that will be used for listening.
// Example: [tlsv1.1 tlsv1.2]
func (s *ListenHTTPSConfigImpl) SetSslProtocols(v []TlsVersion) ListenHTTPSConfig {
	if s == nil {
		return nil
	}
	s.SslProtocolsValue = v
	return s
}

// NewListenSslConfig creates a new ListenSslConfig instance
func NewListenSslConfig() ListenSslConfig {
	return &ListenSslConfigImpl{}
}

// List of SSL protocol versions that will be used for listening.
// Example: [tlsv1.1 tlsv1.2]
func (s ListenSslConfigImpl) SslProtocols() []TlsVersion {
	return s.SslProtocolsValue
}

// List of SSL protocol versions that will be used for listening.
// Example: [tlsv1.1 tlsv1.2]
func (s *ListenSslConfigImpl) SetSslProtocols(v []TlsVersion) ListenSslConfig {
	if s == nil {
		return nil
	}
	s.SslProtocolsValue = v
	return s
}

// NewListeners creates a new Listeners instance
func NewListeners() Listeners {
	return &ListenersImpl{}
}

// List of HTTP ports or `host:port` pairs that will be used for listening.
// Examples: [map[api:false, port:80]]
func (s ListenersImpl) HTTP() []ListenHTTPConfig {
	if s.HTTPValue == nil {
		return nil
	}
	result := make([]ListenHTTPConfig, len(s.HTTPValue))
	for i, item := range s.HTTPValue {
		result[i] = item
	}
	return result
}

// List of HTTP ports or `host:port` pairs that will be used for listening.
// Examples: [map[api:false, port:80]]
func (s *ListenersImpl) SetHTTP(v []ListenHTTPConfig) Listeners {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*ListenHTTPConfigImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*ListenHTTPConfigImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.HTTPValue = impl
	}
	return s
}

// List of HTTPS ports or `host:port` pairs that will be used for listening.
// Examples: [map[port:443]]
func (s ListenersImpl) HTTPS() []ListenHTTPSConfig {
	if s.HTTPSValue == nil {
		return nil
	}
	result := make([]ListenHTTPSConfig, len(s.HTTPSValue))
	for i, item := range s.HTTPSValue {
		result[i] = item
	}
	return result
}

// List of HTTPS ports or `host:port` pairs that will be used for listening.
// Examples: [map[port:443]]
func (s *ListenersImpl) SetHTTPS(v []ListenHTTPSConfig) Listeners {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*ListenHTTPSConfigImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*ListenHTTPSConfigImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.HTTPSValue = impl
	}
	return s
}

// NewOpenmetricsLabels creates a new OpenmetricsLabels instance
func NewOpenmetricsLabels() OpenmetricsLabels {
	return &OpenmetricsLabelsImpl{}
}

// Unique server ID generated on a first start or license change.
// Should not changing until running on the same hardware.
// Format: uuid (uuid)
func (s OpenmetricsLabelsImpl) ServerID() *UUID {
	return s.ServerIDValue
}

// Unique server ID generated on a first start or license change.
// Should not changing until running on the same hardware.
// Format: uuid (uuid)
func (s *OpenmetricsLabelsImpl) SetServerID(v UUID) OpenmetricsLabels {
	if s == nil {
		return nil
	}
	s.ServerIDValue = &v
	return s
}

// NewStreamConfig creates a new StreamConfig instance
func NewStreamConfig() StreamConfig {
	return &StreamConfigImpl{}
}

// Globally unique stream name.
// Note that the name could not be changed after the stream is created.
// Format: media_name (media_name)
// Examples: Decklink-Stream, Dektec-Stream, hockey1, mylive/bunny, test_stream
func (s StreamConfigImpl) Name() MediaName {
	return s.NameValue
}

// Globally unique stream name.
// Note that the name could not be changed after the stream is created.
// Format: media_name (media_name)
// Examples: Decklink-Stream, Dektec-Stream, hockey1, mylive/bunny, test_stream
func (s *StreamConfigImpl) SetName(v MediaName) StreamConfig {
	if s == nil {
		return nil
	}
	s.NameValue = v
	return s
}

// Stream's metrics and other statistical information.
func (s StreamConfigImpl) Stats() StreamStats {
	return s.StatsValue
}

// Stream's metrics and other statistical information.
func (s *StreamConfigImpl) SetStats(v StreamStats) StreamConfig {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*StreamStatsImpl); ok {
		s.StatsValue = impl
	}
	return s
}

// Video analytics parameters.
func (s StreamConfigImpl) Vision() VisionSpec {
	return s.VisionValue
}

// Video analytics parameters.
func (s *StreamConfigImpl) SetVision(v VisionSpec) StreamConfig {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionSpecImpl); ok {
		s.VisionValue = impl
	}
	return s
}

// NewStreamConfigAdditional creates a new StreamConfigAdditional instance
func NewStreamConfigAdditional() StreamConfigAdditional {
	return &StreamConfigAdditionalImpl{}
}

// Stream's metrics and other statistical information.
func (s StreamConfigAdditionalImpl) Stats() StreamStats {
	return s.StatsValue
}

// Stream's metrics and other statistical information.
func (s *StreamConfigAdditionalImpl) SetStats(v StreamStats) StreamConfigAdditional {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*StreamStatsImpl); ok {
		s.StatsValue = impl
	}
	return s
}

// NewStreamConfigBase creates a new StreamConfigBase instance
func NewStreamConfigBase() StreamConfigBase {
	return &StreamConfigBaseImpl{}
}

// NewStreamConfigDeprecated creates a new StreamConfigDeprecated instance
func NewStreamConfigDeprecated() StreamConfigDeprecated {
	return &StreamConfigDeprecatedImpl{}
}

// NewStreamConfigInput creates a new StreamConfigInput instance
func NewStreamConfigInput() StreamConfigInput {
	return &StreamConfigInputImpl{}
}

// NewStreamConfigMedia creates a new StreamConfigMedia instance
func NewStreamConfigMedia() StreamConfigMedia {
	return &StreamConfigMediaImpl{}
}

// NewStreamConfigOnpremises creates a new StreamConfigOnpremises instance
func NewStreamConfigOnpremises() StreamConfigOnpremises {
	return &StreamConfigOnpremisesImpl{}
}

// Video analytics parameters.
func (s StreamConfigOnpremisesImpl) Vision() VisionSpec {
	return s.VisionValue
}

// Video analytics parameters.
func (s *StreamConfigOnpremisesImpl) SetVision(v VisionSpec) StreamConfigOnpremises {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionSpecImpl); ok {
		s.VisionValue = impl
	}
	return s
}

// NewStreamConfigSingleMedia creates a new StreamConfigSingleMedia instance
func NewStreamConfigSingleMedia() StreamConfigSingleMedia {
	return &StreamConfigSingleMediaImpl{}
}

// NewStreamConfigSpecific creates a new StreamConfigSpecific instance
func NewStreamConfigSpecific() StreamConfigSpecific {
	return &StreamConfigSpecificImpl{}
}

// Globally unique stream name.
// Note that the name could not be changed after the stream is created.
// Format: media_name (media_name)
// Examples: Decklink-Stream, Dektec-Stream, hockey1, mylive/bunny, test_stream
func (s StreamConfigSpecificImpl) Name() MediaName {
	return s.NameValue
}

// Globally unique stream name.
// Note that the name could not be changed after the stream is created.
// Format: media_name (media_name)
// Examples: Decklink-Stream, Dektec-Stream, hockey1, mylive/bunny, test_stream
func (s *StreamConfigSpecificImpl) SetName(v MediaName) StreamConfigSpecific {
	if s == nil {
		return nil
	}
	s.NameValue = v
	return s
}

// NewStreamStats creates a new StreamStats instance
func NewStreamStats() StreamStats {
	return &StreamStatsImpl{}
}

// Indicates the status of the stream.
func (s StreamStatsImpl) Status() *StreamStatus {
	return s.StatusValue
}

// Indicates the status of the stream.
func (s *StreamStatsImpl) SetStatus(v StreamStatus) StreamStats {
	if s == nil {
		return nil
	}
	s.StatusValue = &v
	return s
}

// NewStreamsList creates a new StreamsList instance
func NewStreamsList() StreamsList {
	return &StreamsListImpl{}
}

// Estimated total number of records for the query (regardless of the cursors).
// Example: 5
func (s StreamsListImpl) EstimatedCount() *int {
	return s.EstimatedCountValue
}

// Estimated total number of records for the query (regardless of the cursors).
// Example: 5
func (s *StreamsListImpl) SetEstimatedCount(v int) StreamsList {
	if s == nil {
		return nil
	}
	s.EstimatedCountValue = &v
	return s
}

// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fZ3Q9MA==
func (s StreamsListImpl) Next() *string {
	return s.NextValue
}

// Next cursor: a properly encoded equivalent of offset allowing to read the next bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fZ3Q9MA==
func (s *StreamsListImpl) SetNext(v string) StreamsList {
	if s == nil {
		return nil
	}
	s.NextValue = &v
	return s
}

// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
func (s StreamsListImpl) Prev() *string {
	return s.PrevValue
}

// Previous cursor: a properly encoded equivalent of offset allowing to read the previous bunch of items.
// Learn more in [Flussonic API design principles](https://flussonic.com/doc/rest-api-guidelines/#api-http-collections-cursor).
// Example: JTI0cG9zaXRpb25fbHQ9MSYlMjRyZXZlcnNlZD10cnVl
func (s *StreamsListImpl) SetPrev(v string) StreamsList {
	if s == nil {
		return nil
	}
	s.PrevValue = &v
	return s
}

// Unique server ID generated on a first start or license change.
// Should not changing until running on the same hardware.
// Format: uuid (uuid)
func (s StreamsListImpl) ServerID() *UUID {
	return s.ServerIDValue
}

// Unique server ID generated on a first start or license change.
// Should not changing until running on the same hardware.
// Format: uuid (uuid)
func (s *StreamsListImpl) SetServerID(v UUID) StreamsList {
	if s == nil {
		return nil
	}
	s.ServerIDValue = &v
	return s
}

// List of fetched streams according to the query parameters.
func (s StreamsListImpl) Streams() []StreamConfig {
	if s.StreamsValue == nil {
		return nil
	}
	result := make([]StreamConfig, len(s.StreamsValue))
	for i, item := range s.StreamsValue {
		result[i] = item
	}
	return result
}

// List of fetched streams according to the query parameters.
func (s *StreamsListImpl) SetStreams(v []StreamConfig) StreamsList {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*StreamConfigImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*StreamConfigImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.StreamsValue = impl
	}
	return s
}

// An object with a list of different timings measured during this API call.
func (s StreamsListImpl) Timing() any {
	return s.TimingValue
}

// An object with a list of different timings measured during this API call.
func (s *StreamsListImpl) SetTiming(v any) StreamsList {
	if s == nil {
		return nil
	}
	s.TimingValue = v
	return s
}

// Collection returns the collection items from StreamsList
func (s StreamsListImpl) Collection() []StreamConfig {
	return s.Streams()
}

// NewVisionAlerts creates a new VisionAlerts instance
func NewVisionAlerts() VisionAlerts {
	return &VisionAlertsImpl{}
}

// The time when an episode could not be created due to low detection quality (on blurry or noisy frames).
// It may be caused by uncertainty when the picture is not clear enough.
// Try adjusting the shutter speed parameters on your camera.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s VisionAlertsImpl) LowQualityAt() *UtcMs {
	return s.LowQualityAtValue
}

// The time when an episode could not be created due to low detection quality (on blurry or noisy frames).
// It may be caused by uncertainty when the picture is not clear enough.
// Try adjusting the shutter speed parameters on your camera.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s *VisionAlertsImpl) SetLowQualityAt(v UtcMs) VisionAlerts {
	if s == nil {
		return nil
	}
	s.LowQualityAtValue = &v
	return s
}

// The time when an episode could not be created due to insufficient detections.
// The issue occurs when the selected detector is unable to find the target object enough times.
// It is possible that the target object appears shortly or is obscured by something.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s VisionAlertsImpl) NotEnoughDetectionsAt() *UtcMs {
	return s.NotEnoughDetectionsAtValue
}

// The time when an episode could not be created due to insufficient detections.
// The issue occurs when the selected detector is unable to find the target object enough times.
// It is possible that the target object appears shortly or is obscured by something.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s *VisionAlertsImpl) SetNotEnoughDetectionsAt(v UtcMs) VisionAlerts {
	if s == nil {
		return nil
	}
	s.NotEnoughDetectionsAtValue = &v
	return s
}

// The time when an episode could not be created due to the small size of detections relative to the detector internal settings.
// The camera placement may need to be adjusted closer to the target objects.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s VisionAlertsImpl) SmallSizeAt() *UtcMs {
	return s.SmallSizeAtValue
}

// The time when an episode could not be created due to the small size of detections relative to the detector internal settings.
// The camera placement may need to be adjusted closer to the target objects.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s *VisionAlertsImpl) SetSmallSizeAt(v UtcMs) VisionAlerts {
	if s == nil {
		return nil
	}
	s.SmallSizeAtValue = &v
	return s
}

// NewVisionAppearance creates a new VisionAppearance instance
func NewVisionAppearance() VisionAppearance {
	return &VisionAppearanceImpl{}
}

// Position of the objects at the frame
func (s VisionAppearanceImpl) Box() VisionBox {
	return s.BoxValue
}

// Position of the objects at the frame
func (s *VisionAppearanceImpl) SetBox(v VisionBox) VisionAppearance {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionBoxImpl); ok {
		s.BoxValue = impl
	}
	return s
}

// NewVisionAvailableModules creates a new VisionAvailableModules instance
func NewVisionAvailableModules() VisionAvailableModules {
	return &VisionAvailableModulesImpl{}
}

// Indicates which modules are enabled in the inference service
func (s VisionAvailableModulesImpl) AvailableModules() VisionContextSearchModule {
	return s.AvailableModulesValue
}

// Indicates which modules are enabled in the inference service
func (s *VisionAvailableModulesImpl) SetAvailableModules(v VisionContextSearchModule) VisionAvailableModules {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionContextSearchModuleImpl); ok {
		s.AvailableModulesValue = impl
	}
	return s
}

// NewVisionBox creates a new VisionBox instance
func NewVisionBox() VisionBox {
	return &VisionBoxImpl{}
}

// Bottom border of the bounding box. Fraction of full frame height
func (s VisionBoxImpl) Bottom() float64 {
	return s.BottomValue
}

// Bottom border of the bounding box. Fraction of full frame height
func (s *VisionBoxImpl) SetBottom(v float64) VisionBox {
	if s == nil {
		return nil
	}
	s.BottomValue = v
	return s
}

// Left border of the bounding box. Fraction of full frame width
func (s VisionBoxImpl) Left() float64 {
	return s.LeftValue
}

// Left border of the bounding box. Fraction of full frame width
func (s *VisionBoxImpl) SetLeft(v float64) VisionBox {
	if s == nil {
		return nil
	}
	s.LeftValue = v
	return s
}

// Right border of the bounding box. Fraction of full frame width
func (s VisionBoxImpl) Right() float64 {
	return s.RightValue
}

// Right border of the bounding box. Fraction of full frame width
func (s *VisionBoxImpl) SetRight(v float64) VisionBox {
	if s == nil {
		return nil
	}
	s.RightValue = v
	return s
}

// Top border of the bounding box. Fraction of full frame height
func (s VisionBoxImpl) Top() float64 {
	return s.TopValue
}

// Top border of the bounding box. Fraction of full frame height
func (s *VisionBoxImpl) SetTop(v float64) VisionBox {
	if s == nil {
		return nil
	}
	s.TopValue = v
	return s
}

// NewVisionConfigExternal creates a new VisionConfigExternal instance
func NewVisionConfigExternal() VisionConfigExternal {
	return &VisionConfigExternalImpl{}
}

// Stream configuration backend (Central) URL
// Format: url (url)
// Example: http://central.example.com/
func (s VisionConfigExternalImpl) URL() URL {
	return s.URLValue
}

// Stream configuration backend (Central) URL
// Format: url (url)
// Example: http://central.example.com/
func (s *VisionConfigExternalImpl) SetURL(v URL) VisionConfigExternal {
	if s == nil {
		return nil
	}
	s.URLValue = v
	return s
}

// NewVisionContextSearchModule creates a new VisionContextSearchModule instance
func NewVisionContextSearchModule() VisionContextSearchModule {
	return &VisionContextSearchModuleImpl{}
}

// NewVisionCounterRecord creates a new VisionCounterRecord instance
func NewVisionCounterRecord() VisionCounterRecord {
	return &VisionCounterRecordImpl{}
}

// Type of the counter
func (s VisionCounterRecordImpl) CounterType() *string {
	return s.CounterTypeValue
}

// Type of the counter
func (s *VisionCounterRecordImpl) SetCounterType(v string) VisionCounterRecord {
	if s == nil {
		return nil
	}
	s.CounterTypeValue = &v
	return s
}

// Duration of the record
// Format: milliseconds (milliseconds)
// Examples: 60000
func (s VisionCounterRecordImpl) Duration() Milliseconds {
	return s.DurationValue
}

// Duration of the record
// Format: milliseconds (milliseconds)
// Examples: 60000
func (s *VisionCounterRecordImpl) SetDuration(v Milliseconds) VisionCounterRecord {
	if s == nil {
		return nil
	}
	s.DurationValue = v
	return s
}

// Statistics for a number of humans appeared in the region
func (s VisionCounterRecordImpl) Humans() VisionCounterRegionStats {
	return s.HumansValue
}

// Statistics for a number of humans appeared in the region
func (s *VisionCounterRecordImpl) SetHumans(v VisionCounterRegionStats) VisionCounterRecord {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionCounterRegionStatsImpl); ok {
		s.HumansValue = impl
	}
	return s
}

// Stream name on which this record was created.
// Format: media_name (media_name)
func (s VisionCounterRecordImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this record was created.
// Format: media_name (media_name)
func (s *VisionCounterRecordImpl) SetMedia(v MediaName) VisionCounterRecord {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this record was created.
// Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.6370949e+12
func (s VisionCounterRecordImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this record was created.
// Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.6370949e+12
func (s *VisionCounterRecordImpl) SetOpenedAt(v UtcMs) VisionCounterRecord {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Identifier of the area in which counter operates.
// Empty or missing field means that the entire frame is being counted
func (s VisionCounterRecordImpl) RegionID() *string {
	return s.RegionIDValue
}

// Identifier of the area in which counter operates.
// Empty or missing field means that the entire frame is being counted
func (s *VisionCounterRecordImpl) SetRegionID(v string) VisionCounterRecord {
	if s == nil {
		return nil
	}
	s.RegionIDValue = &v
	return s
}

// Statistics for a number of vehicles appeared in the region
func (s VisionCounterRecordImpl) Vehicles() VisionCounterRegionStats {
	return s.VehiclesValue
}

// Statistics for a number of vehicles appeared in the region
func (s *VisionCounterRecordImpl) SetVehicles(v VisionCounterRegionStats) VisionCounterRecord {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionCounterRegionStatsImpl); ok {
		s.VehiclesValue = impl
	}
	return s
}

// NewVisionCounterRecordBase creates a new VisionCounterRecordBase instance
func NewVisionCounterRecordBase() VisionCounterRecordBase {
	return &VisionCounterRecordBaseImpl{}
}

// Duration of the record
// Format: milliseconds (milliseconds)
// Examples: 60000
func (s VisionCounterRecordBaseImpl) Duration() Milliseconds {
	return s.DurationValue
}

// Duration of the record
// Format: milliseconds (milliseconds)
// Examples: 60000
func (s *VisionCounterRecordBaseImpl) SetDuration(v Milliseconds) VisionCounterRecordBase {
	if s == nil {
		return nil
	}
	s.DurationValue = v
	return s
}

// Stream name on which this record was created.
// Format: media_name (media_name)
func (s VisionCounterRecordBaseImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this record was created.
// Format: media_name (media_name)
func (s *VisionCounterRecordBaseImpl) SetMedia(v MediaName) VisionCounterRecordBase {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this record was created.
// Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.6370949e+12
func (s VisionCounterRecordBaseImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this record was created.
// Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.6370949e+12
func (s *VisionCounterRecordBaseImpl) SetOpenedAt(v UtcMs) VisionCounterRecordBase {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// NewVisionCounterRecordRegion creates a new VisionCounterRecordRegion instance
func NewVisionCounterRecordRegion() VisionCounterRecordRegion {
	return &VisionCounterRecordRegionImpl{}
}

// Type of the counter
func (s VisionCounterRecordRegionImpl) CounterType() *string {
	return s.CounterTypeValue
}

// Type of the counter
func (s *VisionCounterRecordRegionImpl) SetCounterType(v string) VisionCounterRecordRegion {
	if s == nil {
		return nil
	}
	s.CounterTypeValue = &v
	return s
}

// Duration of the record
// Format: milliseconds (milliseconds)
// Examples: 60000
func (s VisionCounterRecordRegionImpl) Duration() Milliseconds {
	return s.DurationValue
}

// Duration of the record
// Format: milliseconds (milliseconds)
// Examples: 60000
func (s *VisionCounterRecordRegionImpl) SetDuration(v Milliseconds) VisionCounterRecordRegion {
	if s == nil {
		return nil
	}
	s.DurationValue = v
	return s
}

// Statistics for a number of humans appeared in the region
func (s VisionCounterRecordRegionImpl) Humans() VisionCounterRegionStats {
	return s.HumansValue
}

// Statistics for a number of humans appeared in the region
func (s *VisionCounterRecordRegionImpl) SetHumans(v VisionCounterRegionStats) VisionCounterRecordRegion {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionCounterRegionStatsImpl); ok {
		s.HumansValue = impl
	}
	return s
}

// Stream name on which this record was created.
// Format: media_name (media_name)
func (s VisionCounterRecordRegionImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this record was created.
// Format: media_name (media_name)
func (s *VisionCounterRecordRegionImpl) SetMedia(v MediaName) VisionCounterRecordRegion {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this record was created.
// Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.6370949e+12
func (s VisionCounterRecordRegionImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this record was created.
// Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.6370949e+12
func (s *VisionCounterRecordRegionImpl) SetOpenedAt(v UtcMs) VisionCounterRecordRegion {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Identifier of the area in which counter operates.
// Empty or missing field means that the entire frame is being counted
func (s VisionCounterRecordRegionImpl) RegionID() *string {
	return s.RegionIDValue
}

// Identifier of the area in which counter operates.
// Empty or missing field means that the entire frame is being counted
func (s *VisionCounterRecordRegionImpl) SetRegionID(v string) VisionCounterRecordRegion {
	if s == nil {
		return nil
	}
	s.RegionIDValue = &v
	return s
}

// Statistics for a number of vehicles appeared in the region
func (s VisionCounterRecordRegionImpl) Vehicles() VisionCounterRegionStats {
	return s.VehiclesValue
}

// Statistics for a number of vehicles appeared in the region
func (s *VisionCounterRecordRegionImpl) SetVehicles(v VisionCounterRegionStats) VisionCounterRecordRegion {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionCounterRegionStatsImpl); ok {
		s.VehiclesValue = impl
	}
	return s
}

// NewVisionCounterRegionStats creates a new VisionCounterRegionStats instance
func NewVisionCounterRegionStats() VisionCounterRegionStats {
	return &VisionCounterRegionStatsImpl{}
}

// Number of new objects detected
func (s VisionCounterRegionStatsImpl) Entries() *int {
	return s.EntriesValue
}

// Number of new objects detected
func (s *VisionCounterRegionStatsImpl) SetEntries(v int) VisionCounterRegionStats {
	if s == nil {
		return nil
	}
	s.EntriesValue = &v
	return s
}

// Average number of objects appeared at the same time
func (s VisionCounterRegionStatsImpl) OccupancyAverage() *int {
	return s.OccupancyAverageValue
}

// Average number of objects appeared at the same time
func (s *VisionCounterRegionStatsImpl) SetOccupancyAverage(v int) VisionCounterRegionStats {
	if s == nil {
		return nil
	}
	s.OccupancyAverageValue = &v
	return s
}

// Max number of objects appeared at the same time
func (s VisionCounterRegionStatsImpl) OccupancyMax() *int {
	return s.OccupancyMaxValue
}

// Max number of objects appeared at the same time
func (s *VisionCounterRegionStatsImpl) SetOccupancyMax(v int) VisionCounterRegionStats {
	if s == nil {
		return nil
	}
	s.OccupancyMaxValue = &v
	return s
}

// Min number of objects appeared at the same time
func (s VisionCounterRegionStatsImpl) OccupancyMin() *int {
	return s.OccupancyMinValue
}

// Min number of objects appeared at the same time
func (s *VisionCounterRegionStatsImpl) SetOccupancyMin(v int) VisionCounterRegionStats {
	if s == nil {
		return nil
	}
	s.OccupancyMinValue = &v
	return s
}

// NewVisionDetectedFace creates a new VisionDetectedFace instance
func NewVisionDetectedFace() VisionDetectedFace {
	return &VisionDetectedFaceImpl{}
}

// Appearance attributes of the detected object
func (s VisionDetectedFaceImpl) Appearance() VisionAppearance {
	return s.AppearanceValue
}

// Appearance attributes of the detected object
func (s *VisionDetectedFaceImpl) SetAppearance(v VisionAppearance) VisionDetectedFace {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionAppearanceImpl); ok {
		s.AppearanceValue = impl
	}
	return s
}

// Confidence level of object detection
func (s VisionDetectedFaceImpl) Confidence() *float64 {
	return s.ConfidenceValue
}

// Confidence level of object detection
func (s *VisionDetectedFaceImpl) SetConfidence(v float64) VisionDetectedFace {
	if s == nil {
		return nil
	}
	s.ConfidenceValue = &v
	return s
}

// Timestamp when the object was detected
// Format: utc_ms (Unix timestamp in milliseconds)
func (s VisionDetectedFaceImpl) DetectedAt() UtcMs {
	return s.DetectedAtValue
}

// Timestamp when the object was detected
// Format: utc_ms (Unix timestamp in milliseconds)
func (s *VisionDetectedFaceImpl) SetDetectedAt(v UtcMs) VisionDetectedFace {
	if s == nil {
		return nil
	}
	s.DetectedAtValue = v
	return s
}

// The fingerprint of the detected face
func (s VisionDetectedFaceImpl) Fingerprint() VisionFaceFingerprint {
	return s.FingerprintValue
}

// The fingerprint of the detected face
func (s *VisionDetectedFaceImpl) SetFingerprint(v VisionFaceFingerprint) VisionDetectedFace {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionFaceFingerprintImpl); ok {
		s.FingerprintValue = impl
	}
	return s
}

// Class of the detected object
func (s VisionDetectedFaceImpl) ObjectClass() VisionObjectClass {
	return s.ObjectClassValue
}

// Class of the detected object
func (s *VisionDetectedFaceImpl) SetObjectClass(v VisionObjectClass) VisionDetectedFace {
	if s == nil {
		return nil
	}
	s.ObjectClassValue = v
	return s
}

// Preview of the detected object
func (s VisionDetectedFaceImpl) Thumbnail() VisionImageAttributes {
	return s.ThumbnailValue
}

// Preview of the detected object
func (s *VisionDetectedFaceImpl) SetThumbnail(v VisionImageAttributes) VisionDetectedFace {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionImageAttributesImpl); ok {
		s.ThumbnailValue = impl
	}
	return s
}

// Quality of the thumbnail
func (s VisionDetectedFaceImpl) ThumbnailQuality() *float64 {
	return s.ThumbnailQualityValue
}

// Quality of the thumbnail
func (s *VisionDetectedFaceImpl) SetThumbnailQuality(v float64) VisionDetectedFace {
	if s == nil {
		return nil
	}
	s.ThumbnailQualityValue = &v
	return s
}

// NewVisionDetectedLicensePlate creates a new VisionDetectedLicensePlate instance
func NewVisionDetectedLicensePlate() VisionDetectedLicensePlate {
	return &VisionDetectedLicensePlateImpl{}
}

// Appearance attributes of the detected object
func (s VisionDetectedLicensePlateImpl) Appearance() VisionAppearance {
	return s.AppearanceValue
}

// Appearance attributes of the detected object
func (s *VisionDetectedLicensePlateImpl) SetAppearance(v VisionAppearance) VisionDetectedLicensePlate {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionAppearanceImpl); ok {
		s.AppearanceValue = impl
	}
	return s
}

// Confidence level of object detection
func (s VisionDetectedLicensePlateImpl) Confidence() *float64 {
	return s.ConfidenceValue
}

// Confidence level of object detection
func (s *VisionDetectedLicensePlateImpl) SetConfidence(v float64) VisionDetectedLicensePlate {
	if s == nil {
		return nil
	}
	s.ConfidenceValue = &v
	return s
}

// Timestamp when the object was detected
// Format: utc_ms (Unix timestamp in milliseconds)
func (s VisionDetectedLicensePlateImpl) DetectedAt() UtcMs {
	return s.DetectedAtValue
}

// Timestamp when the object was detected
// Format: utc_ms (Unix timestamp in milliseconds)
func (s *VisionDetectedLicensePlateImpl) SetDetectedAt(v UtcMs) VisionDetectedLicensePlate {
	if s == nil {
		return nil
	}
	s.DetectedAtValue = v
	return s
}

// Shows from which side the vehicle was detected.
func (s VisionDetectedLicensePlateImpl) FacingSide() *VisionVehicleFacingSide {
	return s.FacingSideValue
}

// Shows from which side the vehicle was detected.
func (s *VisionDetectedLicensePlateImpl) SetFacingSide(v VisionVehicleFacingSide) VisionDetectedLicensePlate {
	if s == nil {
		return nil
	}
	s.FacingSideValue = &v
	return s
}

// Class of the detected object
func (s VisionDetectedLicensePlateImpl) ObjectClass() VisionObjectClass {
	return s.ObjectClassValue
}

// Class of the detected object
func (s *VisionDetectedLicensePlateImpl) SetObjectClass(v VisionObjectClass) VisionDetectedLicensePlate {
	if s == nil {
		return nil
	}
	s.ObjectClassValue = v
	return s
}

// Recognized vehicle's license plate number
func (s VisionDetectedLicensePlateImpl) PlateText() *string {
	return s.PlateTextValue
}

// Recognized vehicle's license plate number
func (s *VisionDetectedLicensePlateImpl) SetPlateText(v string) VisionDetectedLicensePlate {
	if s == nil {
		return nil
	}
	s.PlateTextValue = &v
	return s
}

// Preview of the detected object
func (s VisionDetectedLicensePlateImpl) Thumbnail() VisionImageAttributes {
	return s.ThumbnailValue
}

// Preview of the detected object
func (s *VisionDetectedLicensePlateImpl) SetThumbnail(v VisionImageAttributes) VisionDetectedLicensePlate {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionImageAttributesImpl); ok {
		s.ThumbnailValue = impl
	}
	return s
}

// Quality of the thumbnail
func (s VisionDetectedLicensePlateImpl) ThumbnailQuality() *float64 {
	return s.ThumbnailQualityValue
}

// Quality of the thumbnail
func (s *VisionDetectedLicensePlateImpl) SetThumbnailQuality(v float64) VisionDetectedLicensePlate {
	if s == nil {
		return nil
	}
	s.ThumbnailQualityValue = &v
	return s
}

// NewVisionDetectedObjectBase creates a new VisionDetectedObjectBase instance
func NewVisionDetectedObjectBase() VisionDetectedObjectBase {
	return &VisionDetectedObjectBaseImpl{}
}

// Appearance attributes of the detected object
func (s VisionDetectedObjectBaseImpl) Appearance() VisionAppearance {
	return s.AppearanceValue
}

// Appearance attributes of the detected object
func (s *VisionDetectedObjectBaseImpl) SetAppearance(v VisionAppearance) VisionDetectedObjectBase {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionAppearanceImpl); ok {
		s.AppearanceValue = impl
	}
	return s
}

// Confidence level of object detection
func (s VisionDetectedObjectBaseImpl) Confidence() *float64 {
	return s.ConfidenceValue
}

// Confidence level of object detection
func (s *VisionDetectedObjectBaseImpl) SetConfidence(v float64) VisionDetectedObjectBase {
	if s == nil {
		return nil
	}
	s.ConfidenceValue = &v
	return s
}

// Timestamp when the object was detected
// Format: utc_ms (Unix timestamp in milliseconds)
func (s VisionDetectedObjectBaseImpl) DetectedAt() UtcMs {
	return s.DetectedAtValue
}

// Timestamp when the object was detected
// Format: utc_ms (Unix timestamp in milliseconds)
func (s *VisionDetectedObjectBaseImpl) SetDetectedAt(v UtcMs) VisionDetectedObjectBase {
	if s == nil {
		return nil
	}
	s.DetectedAtValue = v
	return s
}

// Class of the detected object
func (s VisionDetectedObjectBaseImpl) ObjectClass() VisionObjectClass {
	return s.ObjectClassValue
}

// Class of the detected object
func (s *VisionDetectedObjectBaseImpl) SetObjectClass(v VisionObjectClass) VisionDetectedObjectBase {
	if s == nil {
		return nil
	}
	s.ObjectClassValue = v
	return s
}

// Preview of the detected object
func (s VisionDetectedObjectBaseImpl) Thumbnail() VisionImageAttributes {
	return s.ThumbnailValue
}

// Preview of the detected object
func (s *VisionDetectedObjectBaseImpl) SetThumbnail(v VisionImageAttributes) VisionDetectedObjectBase {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionImageAttributesImpl); ok {
		s.ThumbnailValue = impl
	}
	return s
}

// Quality of the thumbnail
func (s VisionDetectedObjectBaseImpl) ThumbnailQuality() *float64 {
	return s.ThumbnailQualityValue
}

// Quality of the thumbnail
func (s *VisionDetectedObjectBaseImpl) SetThumbnailQuality(v float64) VisionDetectedObjectBase {
	if s == nil {
		return nil
	}
	s.ThumbnailQualityValue = &v
	return s
}

// NewVisionDetectedVehicle creates a new VisionDetectedVehicle instance
func NewVisionDetectedVehicle() VisionDetectedVehicle {
	return &VisionDetectedVehicleImpl{}
}

// Appearance attributes of the detected object
func (s VisionDetectedVehicleImpl) Appearance() VisionAppearance {
	return s.AppearanceValue
}

// Appearance attributes of the detected object
func (s *VisionDetectedVehicleImpl) SetAppearance(v VisionAppearance) VisionDetectedVehicle {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionAppearanceImpl); ok {
		s.AppearanceValue = impl
	}
	return s
}

// Confidence level of object detection
func (s VisionDetectedVehicleImpl) Confidence() *float64 {
	return s.ConfidenceValue
}

// Confidence level of object detection
func (s *VisionDetectedVehicleImpl) SetConfidence(v float64) VisionDetectedVehicle {
	if s == nil {
		return nil
	}
	s.ConfidenceValue = &v
	return s
}

// Timestamp when the object was detected
// Format: utc_ms (Unix timestamp in milliseconds)
func (s VisionDetectedVehicleImpl) DetectedAt() UtcMs {
	return s.DetectedAtValue
}

// Timestamp when the object was detected
// Format: utc_ms (Unix timestamp in milliseconds)
func (s *VisionDetectedVehicleImpl) SetDetectedAt(v UtcMs) VisionDetectedVehicle {
	if s == nil {
		return nil
	}
	s.DetectedAtValue = v
	return s
}

// Indicates if no license plate is detected on this vehicle
func (s VisionDetectedVehicleImpl) LicensePlateMissing() *bool {
	return s.LicensePlateMissingValue
}

// Indicates if no license plate is detected on this vehicle
func (s *VisionDetectedVehicleImpl) SetLicensePlateMissing(v bool) VisionDetectedVehicle {
	if s == nil {
		return nil
	}
	s.LicensePlateMissingValue = &v
	return s
}

// Class of the detected object
func (s VisionDetectedVehicleImpl) ObjectClass() VisionObjectClass {
	return s.ObjectClassValue
}

// Class of the detected object
func (s *VisionDetectedVehicleImpl) SetObjectClass(v VisionObjectClass) VisionDetectedVehicle {
	if s == nil {
		return nil
	}
	s.ObjectClassValue = v
	return s
}

// The purpose of the vehicle, e.g. emergency or regular.
func (s VisionDetectedVehicleImpl) Purpose() *VisionVehiclePurpose {
	return s.PurposeValue
}

// The purpose of the vehicle, e.g. emergency or regular.
func (s *VisionDetectedVehicleImpl) SetPurpose(v VisionVehiclePurpose) VisionDetectedVehicle {
	if s == nil {
		return nil
	}
	s.PurposeValue = &v
	return s
}

// Preview of the detected object
func (s VisionDetectedVehicleImpl) Thumbnail() VisionImageAttributes {
	return s.ThumbnailValue
}

// Preview of the detected object
func (s *VisionDetectedVehicleImpl) SetThumbnail(v VisionImageAttributes) VisionDetectedVehicle {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionImageAttributesImpl); ok {
		s.ThumbnailValue = impl
	}
	return s
}

// Quality of the thumbnail
func (s VisionDetectedVehicleImpl) ThumbnailQuality() *float64 {
	return s.ThumbnailQualityValue
}

// Quality of the thumbnail
func (s *VisionDetectedVehicleImpl) SetThumbnailQuality(v float64) VisionDetectedVehicle {
	if s == nil {
		return nil
	}
	s.ThumbnailQualityValue = &v
	return s
}

// NewVisionDetectorConfig creates a new VisionDetectorConfig instance
func NewVisionDetectorConfig() VisionDetectorConfig {
	return &VisionDetectorConfigImpl{}
}

func (s VisionDetectorConfigImpl) DetectorType() VisionDetectorConfigDetectorType {
	return s.DetectorTypeValue
}

func (s *VisionDetectorConfigImpl) SetDetectorType(v VisionDetectorConfigDetectorType) VisionDetectorConfig {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionDetectorConfigDetectorTypeImpl); ok {
		s.DetectorTypeValue = impl
	}
	return s
}

func (s VisionDetectorConfigImpl) RegionCoordinates() VisionDetectorConfigRegionCoordinates {
	return s.RegionCoordinatesValue
}

func (s *VisionDetectorConfigImpl) SetRegionCoordinates(v VisionDetectorConfigRegionCoordinates) VisionDetectorConfig {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionDetectorConfigRegionCoordinatesImpl); ok {
		s.RegionCoordinatesValue = impl
	}
	return s
}

// Identifier of the detection area.
// It is used to distinguish episodes from various regions of interest within the frame.
// For instance, it can be used with a single camera facing two entrances to count visitors independently at each entrance.
func (s VisionDetectorConfigImpl) RegionID() string {
	return s.RegionIDValue
}

// Identifier of the detection area.
// It is used to distinguish episodes from various regions of interest within the frame.
// For instance, it can be used with a single camera facing two entrances to count visitors independently at each entrance.
func (s *VisionDetectorConfigImpl) SetRegionID(v string) VisionDetectorConfig {
	if s == nil {
		return nil
	}
	s.RegionIDValue = v
	return s
}

// Runtime information about the vision process.
func (s VisionDetectorConfigImpl) Stats() VisionDetectorStats {
	return s.StatsValue
}

// Runtime information about the vision process.
func (s *VisionDetectorConfigImpl) SetStats(v VisionDetectorStats) VisionDetectorConfig {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionDetectorStatsImpl); ok {
		s.StatsValue = impl
	}
	return s
}

// NewVisionDetectorConfigDetectorType creates a new VisionDetectorConfigDetectorType instance
func NewVisionDetectorConfigDetectorType() VisionDetectorConfigDetectorType {
	return &VisionDetectorConfigDetectorTypeImpl{}
}

// NewVisionDetectorConfigRegionCoordinates creates a new VisionDetectorConfigRegionCoordinates instance
func NewVisionDetectorConfigRegionCoordinates() VisionDetectorConfigRegionCoordinates {
	return &VisionDetectorConfigRegionCoordinatesImpl{}
}

// NewVisionDetectorStats creates a new VisionDetectorStats instance
func NewVisionDetectorStats() VisionDetectorStats {
	return &VisionDetectorStatsImpl{}
}

// Identifies analytics issues related to frames in a stream that impact episode creation
func (s VisionDetectorStatsImpl) Alerts() VisionAlerts {
	return s.AlertsValue
}

// Identifies analytics issues related to frames in a stream that impact episode creation
func (s *VisionDetectorStatsImpl) SetAlerts(v VisionAlerts) VisionDetectorStats {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionAlertsImpl); ok {
		s.AlertsValue = impl
	}
	return s
}

// The time when there was the last detection. Constant updates mean that analytics can detect objects on frames.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s VisionDetectorStatsImpl) LastDetectionAt() *UtcMs {
	return s.LastDetectionAtValue
}

// The time when there was the last detection. Constant updates mean that analytics can detect objects on frames.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s *VisionDetectorStatsImpl) SetLastDetectionAt(v UtcMs) VisionDetectorStats {
	if s == nil {
		return nil
	}
	s.LastDetectionAtValue = &v
	return s
}

// NewVisionDeviceInfo creates a new VisionDeviceInfo instance
func NewVisionDeviceInfo() VisionDeviceInfo {
	return &VisionDeviceInfoImpl{}
}

// Identifier of the hardware device used for videoanalytics inference (if applicable)
// Example: 0
func (s VisionDeviceInfoImpl) DeviceID() *int {
	return s.DeviceIDValue
}

// Identifier of the hardware device used for videoanalytics inference (if applicable)
// Example: 0
func (s *VisionDeviceInfoImpl) SetDeviceID(v int) VisionDeviceInfo {
	if s == nil {
		return nil
	}
	s.DeviceIDValue = &v
	return s
}

// Vendor-defined title of the device
// Examples: AMD Ryzen 7 3700X, NVIDIA GeForce RTX 2070
func (s VisionDeviceInfoImpl) DeviceTitle() *string {
	return s.DeviceTitleValue
}

// Vendor-defined title of the device
// Examples: AMD Ryzen 7 3700X, NVIDIA GeForce RTX 2070
func (s *VisionDeviceInfoImpl) SetDeviceTitle(v string) VisionDeviceInfo {
	if s == nil {
		return nil
	}
	s.DeviceTitleValue = &v
	return s
}

// Hardware device type to be used for a vision process.
func (s VisionDeviceInfoImpl) Hw() VisionHardwareType {
	return s.HwValue
}

// Hardware device type to be used for a vision process.
func (s *VisionDeviceInfoImpl) SetHw(v VisionHardwareType) VisionDeviceInfo {
	if s == nil {
		return nil
	}
	s.HwValue = v
	return s
}

// Runtime statistics for a vision process.
func (s VisionDeviceInfoImpl) Stats() VisionDeviceStats {
	return s.StatsValue
}

// Runtime statistics for a vision process.
func (s *VisionDeviceInfoImpl) SetStats(v VisionDeviceStats) VisionDeviceInfo {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionDeviceStatsImpl); ok {
		s.StatsValue = impl
	}
	return s
}

// NewVisionDeviceStats creates a new VisionDeviceStats instance
func NewVisionDeviceStats() VisionDeviceStats {
	return &VisionDeviceStatsImpl{}
}

// RAM size in bytes (gauge)
// Example: 3.4359738368e+10
func (s VisionDeviceStatsImpl) RamTotalBytes() *int {
	return s.RamTotalBytesValue
}

// RAM size in bytes (gauge)
// Example: 3.4359738368e+10
func (s *VisionDeviceStatsImpl) SetRamTotalBytes(v int) VisionDeviceStats {
	if s == nil {
		return nil
	}
	s.RamTotalBytesValue = &v
	return s
}

// Used RAM size in bytes (gauge)
// Example: 2.2548578304e+10
func (s VisionDeviceStatsImpl) RamUsedBytes() *int {
	return s.RamUsedBytesValue
}

// Used RAM size in bytes (gauge)
// Example: 2.2548578304e+10
func (s *VisionDeviceStatsImpl) SetRamUsedBytes(v int) VisionDeviceStats {
	if s == nil {
		return nil
	}
	s.RamUsedBytesValue = &v
	return s
}

// Utilization percent of the computing device (gauge)
// Example: 87
func (s VisionDeviceStatsImpl) UtilizationPercent() *int {
	return s.UtilizationPercentValue
}

// Utilization percent of the computing device (gauge)
// Example: 87
func (s *VisionDeviceStatsImpl) SetUtilizationPercent(v int) VisionDeviceStats {
	if s == nil {
		return nil
	}
	s.UtilizationPercentValue = &v
	return s
}

// NewVisionEpisodeContextSearch creates a new VisionEpisodeContextSearch instance
func NewVisionEpisodeContextSearch() VisionEpisodeContextSearch {
	return &VisionEpisodeContextSearchImpl{}
}

// The reason for closing the episode.
func (s VisionEpisodeContextSearchImpl) CloseReason() *EpisodeCloseReason {
	return s.CloseReasonValue
}

// The reason for closing the episode.
func (s *VisionEpisodeContextSearchImpl) SetCloseReason(v EpisodeCloseReason) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.CloseReasonValue = &v
	return s
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeContextSearchImpl) ClosedAt() *UtcMs {
	return s.ClosedAtValue
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeContextSearchImpl) SetClosedAt(v UtcMs) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.ClosedAtValue = &v
	return s
}

// The time when the episode appeared in the service relative to the server time.
func (s VisionEpisodeContextSearchImpl) EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return s.EpisodeAppearanceTimestampsValue
}

// The time when the episode appeared in the service relative to the server time.
func (s *VisionEpisodeContextSearchImpl) SetEpisodeAppearanceTimestamps(v EpisodeAppearanceTimestamps) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*EpisodeAppearanceTimestampsImpl); ok {
		s.EpisodeAppearanceTimestampsValue = impl
	}
	return s
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s VisionEpisodeContextSearchImpl) EpisodeID() SnowflakeID {
	return s.EpisodeIDValue
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s *VisionEpisodeContextSearchImpl) SetEpisodeID(v SnowflakeID) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.EpisodeIDValue = v
	return s
}

// Episode matches context search text query
func (s VisionEpisodeContextSearchImpl) EpisodeType() *string {
	return s.EpisodeTypeValue
}

// Episode matches context search text query
func (s *VisionEpisodeContextSearchImpl) SetEpisodeType(v string) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.EpisodeTypeValue = &v
	return s
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s VisionEpisodeContextSearchImpl) FramePreview() *Base64 {
	return s.FramePreviewValue
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s *VisionEpisodeContextSearchImpl) SetFramePreview(v Base64) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.FramePreviewValue = &v
	return s
}

// Maximum matching score between the text query and episode.
// Examples: 0.2345
func (s VisionEpisodeContextSearchImpl) MatchScore() *float64 {
	return s.MatchScoreValue
}

// Maximum matching score between the text query and episode.
// Examples: 0.2345
func (s *VisionEpisodeContextSearchImpl) SetMatchScore(v float64) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.MatchScoreValue = &v
	return s
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s VisionEpisodeContextSearchImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s *VisionEpisodeContextSearchImpl) SetMedia(v MediaName) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeContextSearchImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeContextSearchImpl) SetOpenedAt(v UtcMs) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s VisionEpisodeContextSearchImpl) Preview() *Base64 {
	return s.PreviewValue
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s *VisionEpisodeContextSearchImpl) SetPreview(v Base64) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.PreviewValue = &v
	return s
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeContextSearchImpl) PreviewTimestamp() *UtcMs {
	return s.PreviewTimestampValue
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeContextSearchImpl) SetPreviewTimestamp(v UtcMs) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.PreviewTimestampValue = &v
	return s
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeContextSearchImpl) StartedAt() *UtcMs {
	return s.StartedAtValue
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeContextSearchImpl) SetStartedAt(v UtcMs) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s VisionEpisodeContextSearchImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s *VisionEpisodeContextSearchImpl) SetUpdatedAt(v UtcMs) VisionEpisodeContextSearch {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// NewVisionEpisodeFace creates a new VisionEpisodeFace instance
func NewVisionEpisodeFace() VisionEpisodeFace {
	return &VisionEpisodeFaceImpl{}
}

// The reason for closing the episode.
func (s VisionEpisodeFaceImpl) CloseReason() *EpisodeCloseReason {
	return s.CloseReasonValue
}

// The reason for closing the episode.
func (s *VisionEpisodeFaceImpl) SetCloseReason(v EpisodeCloseReason) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.CloseReasonValue = &v
	return s
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeFaceImpl) ClosedAt() *UtcMs {
	return s.ClosedAtValue
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeFaceImpl) SetClosedAt(v UtcMs) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.ClosedAtValue = &v
	return s
}

// Detections associated with this episode
func (s VisionEpisodeFaceImpl) Detections() []VisionDetectedFace {
	if s.DetectionsValue == nil {
		return nil
	}
	result := make([]VisionDetectedFace, len(s.DetectionsValue))
	for i, item := range s.DetectionsValue {
		result[i] = item
	}
	return result
}

// Detections associated with this episode
func (s *VisionEpisodeFaceImpl) SetDetections(v []VisionDetectedFace) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionDetectedFaceImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionDetectedFaceImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.DetectionsValue = impl
	}
	return s
}

// The time when the episode appeared in the service relative to the server time.
func (s VisionEpisodeFaceImpl) EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return s.EpisodeAppearanceTimestampsValue
}

// The time when the episode appeared in the service relative to the server time.
func (s *VisionEpisodeFaceImpl) SetEpisodeAppearanceTimestamps(v EpisodeAppearanceTimestamps) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*EpisodeAppearanceTimestampsImpl); ok {
		s.EpisodeAppearanceTimestampsValue = impl
	}
	return s
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s VisionEpisodeFaceImpl) EpisodeID() SnowflakeID {
	return s.EpisodeIDValue
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s *VisionEpisodeFaceImpl) SetEpisodeID(v SnowflakeID) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.EpisodeIDValue = v
	return s
}

// Face is detected
func (s VisionEpisodeFaceImpl) EpisodeType() *string {
	return s.EpisodeTypeValue
}

// Face is detected
func (s *VisionEpisodeFaceImpl) SetEpisodeType(v string) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.EpisodeTypeValue = &v
	return s
}

// The fingerprint of the detected face
func (s VisionEpisodeFaceImpl) Fingerprint() VisionFaceFingerprint {
	return s.FingerprintValue
}

// The fingerprint of the detected face
func (s *VisionEpisodeFaceImpl) SetFingerprint(v VisionFaceFingerprint) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionFaceFingerprintImpl); ok {
		s.FingerprintValue = impl
	}
	return s
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s VisionEpisodeFaceImpl) FramePreview() *Base64 {
	return s.FramePreviewValue
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s *VisionEpisodeFaceImpl) SetFramePreview(v Base64) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.FramePreviewValue = &v
	return s
}

// List of matched persons with similarity metric.
// Videoanalytics identification service enriches episode's data and fills this field
// with the list of persons that are similar to the face detected in this episode.
func (s VisionEpisodeFaceImpl) MatchedPersons() []VisionPersonMatch {
	if s.MatchedPersonsValue == nil {
		return nil
	}
	result := make([]VisionPersonMatch, len(s.MatchedPersonsValue))
	for i, item := range s.MatchedPersonsValue {
		result[i] = item
	}
	return result
}

// List of matched persons with similarity metric.
// Videoanalytics identification service enriches episode's data and fills this field
// with the list of persons that are similar to the face detected in this episode.
func (s *VisionEpisodeFaceImpl) SetMatchedPersons(v []VisionPersonMatch) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionPersonMatchImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionPersonMatchImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.MatchedPersonsValue = impl
	}
	return s
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s VisionEpisodeFaceImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s *VisionEpisodeFaceImpl) SetMedia(v MediaName) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeFaceImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeFaceImpl) SetOpenedAt(v UtcMs) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Preview contains an image of person's face and has a resolution about 200 x 200 pixels with maximum size about 10 kilobytes.
// Format: base64 (base64)
func (s VisionEpisodeFaceImpl) Preview() Base64 {
	return s.PreviewValue
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Preview contains an image of person's face and has a resolution about 200 x 200 pixels with maximum size about 10 kilobytes.
// Format: base64 (base64)
func (s *VisionEpisodeFaceImpl) SetPreview(v Base64) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.PreviewValue = v
	return s
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeFaceImpl) PreviewTimestamp() *UtcMs {
	return s.PreviewTimestampValue
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeFaceImpl) SetPreviewTimestamp(v UtcMs) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.PreviewTimestampValue = &v
	return s
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeFaceImpl) StartedAt() *UtcMs {
	return s.StartedAtValue
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeFaceImpl) SetStartedAt(v UtcMs) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s VisionEpisodeFaceImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s *VisionEpisodeFaceImpl) SetUpdatedAt(v UtcMs) VisionEpisodeFace {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// NewVisionEpisodeHuman creates a new VisionEpisodeHuman instance
func NewVisionEpisodeHuman() VisionEpisodeHuman {
	return &VisionEpisodeHumanImpl{}
}

// The reason for closing the episode.
func (s VisionEpisodeHumanImpl) CloseReason() *EpisodeCloseReason {
	return s.CloseReasonValue
}

// The reason for closing the episode.
func (s *VisionEpisodeHumanImpl) SetCloseReason(v EpisodeCloseReason) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.CloseReasonValue = &v
	return s
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeHumanImpl) ClosedAt() *UtcMs {
	return s.ClosedAtValue
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeHumanImpl) SetClosedAt(v UtcMs) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.ClosedAtValue = &v
	return s
}

// Detections associated with this episode
func (s VisionEpisodeHumanImpl) Detections() []VisionDetectedObjectBase {
	if s.DetectionsValue == nil {
		return nil
	}
	result := make([]VisionDetectedObjectBase, len(s.DetectionsValue))
	for i, item := range s.DetectionsValue {
		result[i] = item
	}
	return result
}

// Detections associated with this episode
func (s *VisionEpisodeHumanImpl) SetDetections(v []VisionDetectedObjectBase) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionDetectedObjectBaseImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionDetectedObjectBaseImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.DetectionsValue = impl
	}
	return s
}

// The time when the episode appeared in the service relative to the server time.
func (s VisionEpisodeHumanImpl) EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return s.EpisodeAppearanceTimestampsValue
}

// The time when the episode appeared in the service relative to the server time.
func (s *VisionEpisodeHumanImpl) SetEpisodeAppearanceTimestamps(v EpisodeAppearanceTimestamps) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*EpisodeAppearanceTimestampsImpl); ok {
		s.EpisodeAppearanceTimestampsValue = impl
	}
	return s
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s VisionEpisodeHumanImpl) EpisodeID() SnowflakeID {
	return s.EpisodeIDValue
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s *VisionEpisodeHumanImpl) SetEpisodeID(v SnowflakeID) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.EpisodeIDValue = v
	return s
}

// Human is detected
func (s VisionEpisodeHumanImpl) EpisodeType() *string {
	return s.EpisodeTypeValue
}

// Human is detected
func (s *VisionEpisodeHumanImpl) SetEpisodeType(v string) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.EpisodeTypeValue = &v
	return s
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s VisionEpisodeHumanImpl) FramePreview() *Base64 {
	return s.FramePreviewValue
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s *VisionEpisodeHumanImpl) SetFramePreview(v Base64) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.FramePreviewValue = &v
	return s
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s VisionEpisodeHumanImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s *VisionEpisodeHumanImpl) SetMedia(v MediaName) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeHumanImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeHumanImpl) SetOpenedAt(v UtcMs) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s VisionEpisodeHumanImpl) Preview() *Base64 {
	return s.PreviewValue
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s *VisionEpisodeHumanImpl) SetPreview(v Base64) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.PreviewValue = &v
	return s
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeHumanImpl) PreviewTimestamp() *UtcMs {
	return s.PreviewTimestampValue
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeHumanImpl) SetPreviewTimestamp(v UtcMs) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.PreviewTimestampValue = &v
	return s
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeHumanImpl) StartedAt() *UtcMs {
	return s.StartedAtValue
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeHumanImpl) SetStartedAt(v UtcMs) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s VisionEpisodeHumanImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s *VisionEpisodeHumanImpl) SetUpdatedAt(v UtcMs) VisionEpisodeHuman {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// NewVisionEpisodeQrCode creates a new VisionEpisodeQrCode instance
func NewVisionEpisodeQrCode() VisionEpisodeQrCode {
	return &VisionEpisodeQrCodeImpl{}
}

// The reason for closing the episode.
func (s VisionEpisodeQrCodeImpl) CloseReason() *EpisodeCloseReason {
	return s.CloseReasonValue
}

// The reason for closing the episode.
func (s *VisionEpisodeQrCodeImpl) SetCloseReason(v EpisodeCloseReason) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.CloseReasonValue = &v
	return s
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeQrCodeImpl) ClosedAt() *UtcMs {
	return s.ClosedAtValue
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeQrCodeImpl) SetClosedAt(v UtcMs) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.ClosedAtValue = &v
	return s
}

// The time when the episode appeared in the service relative to the server time.
func (s VisionEpisodeQrCodeImpl) EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return s.EpisodeAppearanceTimestampsValue
}

// The time when the episode appeared in the service relative to the server time.
func (s *VisionEpisodeQrCodeImpl) SetEpisodeAppearanceTimestamps(v EpisodeAppearanceTimestamps) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*EpisodeAppearanceTimestampsImpl); ok {
		s.EpisodeAppearanceTimestampsValue = impl
	}
	return s
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s VisionEpisodeQrCodeImpl) EpisodeID() SnowflakeID {
	return s.EpisodeIDValue
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s *VisionEpisodeQrCodeImpl) SetEpisodeID(v SnowflakeID) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.EpisodeIDValue = v
	return s
}

// QR-code is detected
func (s VisionEpisodeQrCodeImpl) EpisodeType() *string {
	return s.EpisodeTypeValue
}

// QR-code is detected
func (s *VisionEpisodeQrCodeImpl) SetEpisodeType(v string) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.EpisodeTypeValue = &v
	return s
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s VisionEpisodeQrCodeImpl) FramePreview() *Base64 {
	return s.FramePreviewValue
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s *VisionEpisodeQrCodeImpl) SetFramePreview(v Base64) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.FramePreviewValue = &v
	return s
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s VisionEpisodeQrCodeImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s *VisionEpisodeQrCodeImpl) SetMedia(v MediaName) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeQrCodeImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeQrCodeImpl) SetOpenedAt(v UtcMs) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Raw data extracted from QR-code
// Example: WIFI:T:WPA;S:MyOfficeWiFi;P:Mypassword;H:;
func (s VisionEpisodeQrCodeImpl) Payload() *string {
	return s.PayloadValue
}

// Raw data extracted from QR-code
// Example: WIFI:T:WPA;S:MyOfficeWiFi;P:Mypassword;H:;
func (s *VisionEpisodeQrCodeImpl) SetPayload(v string) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.PayloadValue = &v
	return s
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s VisionEpisodeQrCodeImpl) Preview() *Base64 {
	return s.PreviewValue
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Format: base64 (base64)
func (s *VisionEpisodeQrCodeImpl) SetPreview(v Base64) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.PreviewValue = &v
	return s
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeQrCodeImpl) PreviewTimestamp() *UtcMs {
	return s.PreviewTimestampValue
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeQrCodeImpl) SetPreviewTimestamp(v UtcMs) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.PreviewTimestampValue = &v
	return s
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeQrCodeImpl) StartedAt() *UtcMs {
	return s.StartedAtValue
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeQrCodeImpl) SetStartedAt(v UtcMs) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s VisionEpisodeQrCodeImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s *VisionEpisodeQrCodeImpl) SetUpdatedAt(v UtcMs) VisionEpisodeQrCode {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// NewVisionEpisodeVehicle creates a new VisionEpisodeVehicle instance
func NewVisionEpisodeVehicle() VisionEpisodeVehicle {
	return &VisionEpisodeVehicleImpl{}
}

// The reason for closing the episode.
func (s VisionEpisodeVehicleImpl) CloseReason() *EpisodeCloseReason {
	return s.CloseReasonValue
}

// The reason for closing the episode.
func (s *VisionEpisodeVehicleImpl) SetCloseReason(v EpisodeCloseReason) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.CloseReasonValue = &v
	return s
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeVehicleImpl) ClosedAt() *UtcMs {
	return s.ClosedAtValue
}

// Episode emitter can decide that episode considered closed and will not grow further.
// `closed_at` MUST NOT change, it must be emitted only once.
// Episode can live without `closed_at`, in this case you should use `updated_at` as the last time
// of the episode.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeVehicleImpl) SetClosedAt(v UtcMs) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.ClosedAtValue = &v
	return s
}

// Detections associated with this episode
func (s VisionEpisodeVehicleImpl) Detections() []any {
	return s.DetectionsValue
}

// Detections associated with this episode
func (s *VisionEpisodeVehicleImpl) SetDetections(v []any) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.DetectionsValue = v
	return s
}

// The time when the episode appeared in the service relative to the server time.
func (s VisionEpisodeVehicleImpl) EpisodeAppearanceTimestamps() EpisodeAppearanceTimestamps {
	return s.EpisodeAppearanceTimestampsValue
}

// The time when the episode appeared in the service relative to the server time.
func (s *VisionEpisodeVehicleImpl) SetEpisodeAppearanceTimestamps(v EpisodeAppearanceTimestamps) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*EpisodeAppearanceTimestampsImpl); ok {
		s.EpisodeAppearanceTimestampsValue = impl
	}
	return s
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s VisionEpisodeVehicleImpl) EpisodeID() SnowflakeID {
	return s.EpisodeIDValue
}

// Unique identifier of the episode. Must be created by the system that first creates this episode.
// Please, mention that it is assumed to be 64 bit length including time of creation in it (refer to snowflake),
// so you cannot handle it in javascript with simple `JSON.parse()`, you need to use parsed that will properly
// handle very long integers.
// Format: snowflake_id (snowflake_id)
// Examples: 1.722279170848854e+18
func (s *VisionEpisodeVehicleImpl) SetEpisodeID(v SnowflakeID) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.EpisodeIDValue = v
	return s
}

// Vehicle is detected
func (s VisionEpisodeVehicleImpl) EpisodeType() *string {
	return s.EpisodeTypeValue
}

// Vehicle is detected
func (s *VisionEpisodeVehicleImpl) SetEpisodeType(v string) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.EpisodeTypeValue = &v
	return s
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s VisionEpisodeVehicleImpl) FramePreview() *Base64 {
	return s.FramePreviewValue
}

// Small inline image of the entire frame used for direct display in web-browser UI or mobile application.
// Frame preview resolution is about 240p and the maximum image size is not larger then a few tens of kilobytes.
// Format: base64 (base64)
func (s *VisionEpisodeVehicleImpl) SetFramePreview(v Base64) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.FramePreviewValue = &v
	return s
}

// Indicates if no license plate is detected on this vehicle
func (s VisionEpisodeVehicleImpl) LicensePlateMissing() *bool {
	return s.LicensePlateMissingValue
}

// Indicates if no license plate is detected on this vehicle
func (s *VisionEpisodeVehicleImpl) SetLicensePlateMissing(v bool) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.LicensePlateMissingValue = &v
	return s
}

// Recognized vehicle's license plate number
func (s VisionEpisodeVehicleImpl) LicensePlateText() *string {
	return s.LicensePlateTextValue
}

// Recognized vehicle's license plate number
func (s *VisionEpisodeVehicleImpl) SetLicensePlateText(v string) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.LicensePlateTextValue = &v
	return s
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s VisionEpisodeVehicleImpl) Media() MediaName {
	return s.MediaValue
}

// Stream name on which this episode exists.
// Format: media_name (media_name)
func (s *VisionEpisodeVehicleImpl) SetMedia(v MediaName) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.MediaValue = v
	return s
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeVehicleImpl) OpenedAt() UtcMs {
	return s.OpenedAtValue
}

// The time when this episode was created. Naming is standard for whole flussonic ecosystem.
// Usually this time will be the same as `started_at`, but can differ, refer to the description of that field.
// The value of this field is copied into `episode_id`, so sorting by `episode_id` will give you the same
// sort as by `opened_at`
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeVehicleImpl) SetOpenedAt(v UtcMs) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.OpenedAtValue = v
	return s
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Preview contains an image of vehicle's license plate and has a resolution about 160 x 64 pixels with maximum size about 10 kilobytes.
// Format: base64 (base64)
func (s VisionEpisodeVehicleImpl) Preview() Base64 {
	return s.PreviewValue
}

// Small inline image of detected object cropped from the entire frame used for directly display in web-browser UI or mobile application.
// Preview contains an image of vehicle's license plate and has a resolution about 160 x 64 pixels with maximum size about 10 kilobytes.
// Format: base64 (base64)
func (s *VisionEpisodeVehicleImpl) SetPreview(v Base64) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.PreviewValue = v
	return s
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeVehicleImpl) PreviewTimestamp() *UtcMs {
	return s.PreviewTimestampValue
}

// The time when the preview of this episode is available.
// Use it to request preview image via Mediaserver's DVR API (`jpeg_preview_dvr`).
// Visit the [Getting JPEGs from DVR by specific time](https://flussonic.com/doc/thumbnails/#thumbnails-dvr-time) article
// and [JPEG thumbnail from DVR](https://flussonic.com/doc/api/streaming/#tag/image/operation/jpeg_preview_dvr) section of the Mediaserver's API Reference
// for details.
// This field may not be present. If so, you may use the timestamp from the `started_at` field to request the preview image
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeVehicleImpl) SetPreviewTimestamp(v UtcMs) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.PreviewTimestampValue = &v
	return s
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s VisionEpisodeVehicleImpl) StartedAt() *UtcMs {
	return s.StartedAtValue
}

// This field can be used as indication of the fact that some system have checked and ensured that
// this episode has really started at some time, that may differ from `opened_at`.
// For example video analytics will use this field for the time when this episode was confirmed as confident.
// May be not relevant for television systems.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637094994e+12
func (s *VisionEpisodeVehicleImpl) SetStartedAt(v UtcMs) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s VisionEpisodeVehicleImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// The time of last change of the episode.
// System that processes episodes and can send them to other systems, MUST update this field
// on any changes in this episode.
// This field MUST be updated strictly monotonical and increasing. The updater MUST guarantee that
// this `updated_at` can be used as a sort key for fetching fresh updates.
// Consumer of the episodes can use `updated_at` in the following scenario:
// * fetch all exisiting episodes from the source
// * take biggest `updated_at` from this dataset, it will be T
// * ask source for all episodes with `updated_at > T`
// This algorithm can be used for fetching update stream from the source.
// Format: utc_ms (Unix timestamp in milliseconds)
// Examples: 1.637098611e+12
func (s *VisionEpisodeVehicleImpl) SetUpdatedAt(v UtcMs) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// Emergency type of the vehicle.
func (s VisionEpisodeVehicleImpl) VehicleEmergencySubtype() *VisionVehicleEmergencySubtype {
	return s.VehicleEmergencySubtypeValue
}

// Emergency type of the vehicle.
func (s *VisionEpisodeVehicleImpl) SetVehicleEmergencySubtype(v VisionVehicleEmergencySubtype) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.VehicleEmergencySubtypeValue = &v
	return s
}

// Shows from which side the vehicle was detected.
func (s VisionEpisodeVehicleImpl) VehicleFacingSide() *VisionVehicleFacingSide {
	return s.VehicleFacingSideValue
}

// Shows from which side the vehicle was detected.
func (s *VisionEpisodeVehicleImpl) SetVehicleFacingSide(v VisionVehicleFacingSide) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.VehicleFacingSideValue = &v
	return s
}

// The purpose of the vehicle, e.g. emergency or regular.
func (s VisionEpisodeVehicleImpl) VehiclePurpose() *VisionVehiclePurpose {
	return s.VehiclePurposeValue
}

// The purpose of the vehicle, e.g. emergency or regular.
func (s *VisionEpisodeVehicleImpl) SetVehiclePurpose(v VisionVehiclePurpose) VisionEpisodeVehicle {
	if s == nil {
		return nil
	}
	s.VehiclePurposeValue = &v
	return s
}

// NewVisionFaceAttributes creates a new VisionFaceAttributes instance
func NewVisionFaceAttributes() VisionFaceAttributes {
	return &VisionFaceAttributesImpl{}
}

// The fingerprint of the detected face
func (s VisionFaceAttributesImpl) Fingerprint() VisionFaceFingerprint {
	return s.FingerprintValue
}

// The fingerprint of the detected face
func (s *VisionFaceAttributesImpl) SetFingerprint(v VisionFaceFingerprint) VisionFaceAttributes {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionFaceFingerprintImpl); ok {
		s.FingerprintValue = impl
	}
	return s
}

// NewVisionFaceFingerprint creates a new VisionFaceFingerprint instance
func NewVisionFaceFingerprint() VisionFaceFingerprint {
	return &VisionFaceFingerprintImpl{}
}

// Base64 encoded representation of the fingerprint
// Format: base64 (base64)
func (s VisionFaceFingerprintImpl) Data() Base64 {
	return s.DataValue
}

// Base64 encoded representation of the fingerprint
// Format: base64 (base64)
func (s *VisionFaceFingerprintImpl) SetData(v Base64) VisionFaceFingerprint {
	if s == nil {
		return nil
	}
	s.DataValue = v
	return s
}

// Version identifier of the fingerprint's data. The version is assigned automatically.
// Fingerprints of different versions cannot be compared to each other.
// Examples: aabbccdd, c6ba4246
func (s VisionFaceFingerprintImpl) Version() string {
	return s.VersionValue
}

// Version identifier of the fingerprint's data. The version is assigned automatically.
// Fingerprints of different versions cannot be compared to each other.
// Examples: aabbccdd, c6ba4246
func (s *VisionFaceFingerprintImpl) SetVersion(v string) VisionFaceFingerprint {
	if s == nil {
		return nil
	}
	s.VersionValue = v
	return s
}

// NewVisionImageAttributes creates a new VisionImageAttributes instance
func NewVisionImageAttributes() VisionImageAttributes {
	return &VisionImageAttributesImpl{}
}

// Base64-encoded image data
// Format: base64 (base64)
func (s VisionImageAttributesImpl) Data() Base64 {
	return s.DataValue
}

// Base64-encoded image data
// Format: base64 (base64)
func (s *VisionImageAttributesImpl) SetData(v Base64) VisionImageAttributes {
	if s == nil {
		return nil
	}
	s.DataValue = v
	return s
}

// MIME type of the image
func (s VisionImageAttributesImpl) MimeType() *VisionImageMimetype {
	return s.MimeTypeValue
}

// MIME type of the image
func (s *VisionImageAttributesImpl) SetMimeType(v VisionImageMimetype) VisionImageAttributes {
	if s == nil {
		return nil
	}
	s.MimeTypeValue = &v
	return s
}

// Checksum of this image
// Format: hexbinary (hexbinary)
func (s VisionImageAttributesImpl) Sha256() *Hexbinary {
	return s.Sha256Value
}

// Checksum of this image
// Format: hexbinary (hexbinary)
func (s *VisionImageAttributesImpl) SetSha256(v Hexbinary) VisionImageAttributes {
	if s == nil {
		return nil
	}
	s.Sha256Value = &v
	return s
}

// NewVisionInferenceDevice creates a new VisionInferenceDevice instance
func NewVisionInferenceDevice() VisionInferenceDevice {
	return &VisionInferenceDeviceImpl{}
}

// Identifier of the hardware device used for videoanalytics inference (if applicable)
// Example: 0
func (s VisionInferenceDeviceImpl) DeviceID() *int {
	return s.DeviceIDValue
}

// Identifier of the hardware device used for videoanalytics inference (if applicable)
// Example: 0
func (s *VisionInferenceDeviceImpl) SetDeviceID(v int) VisionInferenceDevice {
	if s == nil {
		return nil
	}
	s.DeviceIDValue = &v
	return s
}

// Hardware device type to be used for a vision process.
func (s VisionInferenceDeviceImpl) Hw() VisionHardwareType {
	return s.HwValue
}

// Hardware device type to be used for a vision process.
func (s *VisionInferenceDeviceImpl) SetHw(v VisionHardwareType) VisionInferenceDevice {
	if s == nil {
		return nil
	}
	s.HwValue = v
	return s
}

// NewVisionLicensePlateAttributes creates a new VisionLicensePlateAttributes instance
func NewVisionLicensePlateAttributes() VisionLicensePlateAttributes {
	return &VisionLicensePlateAttributesImpl{}
}

// Shows from which side the vehicle was detected.
func (s VisionLicensePlateAttributesImpl) FacingSide() *VisionVehicleFacingSide {
	return s.FacingSideValue
}

// Shows from which side the vehicle was detected.
func (s *VisionLicensePlateAttributesImpl) SetFacingSide(v VisionVehicleFacingSide) VisionLicensePlateAttributes {
	if s == nil {
		return nil
	}
	s.FacingSideValue = &v
	return s
}

// Recognized vehicle's license plate number
func (s VisionLicensePlateAttributesImpl) PlateText() *string {
	return s.PlateTextValue
}

// Recognized vehicle's license plate number
func (s *VisionLicensePlateAttributesImpl) SetPlateText(v string) VisionLicensePlateAttributes {
	if s == nil {
		return nil
	}
	s.PlateTextValue = &v
	return s
}

// NewVisionMetrics creates a new VisionMetrics instance
func NewVisionMetrics() VisionMetrics {
	return &VisionMetricsImpl{}
}

// The number of decoded frames
func (s VisionMetricsImpl) DecodedFramesCount() *int {
	return s.DecodedFramesCountValue
}

// The number of decoded frames
func (s *VisionMetricsImpl) SetDecodedFramesCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DecodedFramesCountValue = &v
	return s
}

// The number of decoding errors
func (s VisionMetricsImpl) DecoderErrorsCount() *int {
	return s.DecoderErrorsCountValue
}

// The number of decoding errors
func (s *VisionMetricsImpl) SetDecoderErrorsCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DecoderErrorsCountValue = &v
	return s
}

// How many times decoder was restarted
func (s VisionMetricsImpl) DecoderRestartsCount() *int {
	return s.DecoderRestartsCountValue
}

// How many times decoder was restarted
func (s *VisionMetricsImpl) SetDecoderRestartsCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DecoderRestartsCountValue = &v
	return s
}

// Total time spent on decoding
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) DecodingTime() *Milliseconds {
	return s.DecodingTimeValue
}

// Total time spent on decoding
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetDecodingTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DecodingTimeValue = &v
	return s
}

// Total time spent on detection
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) DetectionTime() *Milliseconds {
	return s.DetectionTimeValue
}

// Total time spent on detection
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetDetectionTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionTimeValue = &v
	return s
}

// Cumulative detection size **after** filtering
func (s VisionMetricsImpl) DetectionsAcceptedArea() *float64 {
	return s.DetectionsAcceptedAreaValue
}

// Cumulative detection size **after** filtering
func (s *VisionMetricsImpl) SetDetectionsAcceptedArea(v float64) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionsAcceptedAreaValue = &v
	return s
}

// Cumulative detection confidence **after** filtering
func (s VisionMetricsImpl) DetectionsAcceptedConfidence() *float64 {
	return s.DetectionsAcceptedConfidenceValue
}

// Cumulative detection confidence **after** filtering
func (s *VisionMetricsImpl) SetDetectionsAcceptedConfidence(v float64) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionsAcceptedConfidenceValue = &v
	return s
}

// The number of detected objects **after** filtering
func (s VisionMetricsImpl) DetectionsAcceptedCount() *int {
	return s.DetectionsAcceptedCountValue
}

// The number of detected objects **after** filtering
func (s *VisionMetricsImpl) SetDetectionsAcceptedCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionsAcceptedCountValue = &v
	return s
}

// Cumulative detection size (in fraction of frame area) **before** filtering
func (s VisionMetricsImpl) DetectionsArea() *float64 {
	return s.DetectionsAreaValue
}

// Cumulative detection size (in fraction of frame area) **before** filtering
func (s *VisionMetricsImpl) SetDetectionsArea(v float64) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionsAreaValue = &v
	return s
}

// Total number of detections rejected due to **size** inacceptable for fingerprinting
func (s VisionMetricsImpl) DetectionsAreaRejectedCount() *int {
	return s.DetectionsAreaRejectedCountValue
}

// Total number of detections rejected due to **size** inacceptable for fingerprinting
func (s *VisionMetricsImpl) SetDetectionsAreaRejectedCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionsAreaRejectedCountValue = &v
	return s
}

// Cumulative detection confidences **before** filtering
func (s VisionMetricsImpl) DetectionsConfidence() *float64 {
	return s.DetectionsConfidenceValue
}

// Cumulative detection confidences **before** filtering
func (s *VisionMetricsImpl) SetDetectionsConfidence(v float64) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionsConfidenceValue = &v
	return s
}

// Total number of detections rejected due to inacceptable **confidence**
func (s VisionMetricsImpl) DetectionsConfidenceRejectedCount() *int {
	return s.DetectionsConfidenceRejectedCountValue
}

// Total number of detections rejected due to inacceptable **confidence**
func (s *VisionMetricsImpl) SetDetectionsConfidenceRejectedCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionsConfidenceRejectedCountValue = &v
	return s
}

// Total number of detected objects.
// Consists of 4 buckets: rejected by confidence, size, orientation and accepted detections.
// Each bucket is represented by number of detections in that bucket
// For each rejection reason there is a cumulative _quality_ metric for all detections
// and cumulative _quality_ metric for accepted detections
// For example:
// `detections_confidence` is a cumulative confidence of _all_ detections
// `detections_accepted_confidence` is a cumulative confidence of _accepted_ detections
// `detections_area` is a cumulative size of _all_ detections
// `detections_accepted_area` is a cumulative size of _accepted_ detections
func (s VisionMetricsImpl) DetectionsCount() *int {
	return s.DetectionsCountValue
}

// Total number of detected objects.
// Consists of 4 buckets: rejected by confidence, size, orientation and accepted detections.
// Each bucket is represented by number of detections in that bucket
// For each rejection reason there is a cumulative _quality_ metric for all detections
// and cumulative _quality_ metric for accepted detections
// For example:
// `detections_confidence` is a cumulative confidence of _all_ detections
// `detections_accepted_confidence` is a cumulative confidence of _accepted_ detections
// `detections_area` is a cumulative size of _all_ detections
// `detections_accepted_area` is a cumulative size of _accepted_ detections
func (s *VisionMetricsImpl) SetDetectionsCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionsCountValue = &v
	return s
}

// Total number of detections rejected due to **orientation** inacceptable for fingerprinting
func (s VisionMetricsImpl) DetectionsOrientationRejectedCount() *int {
	return s.DetectionsOrientationRejectedCountValue
}

// Total number of detections rejected due to **orientation** inacceptable for fingerprinting
func (s *VisionMetricsImpl) SetDetectionsOrientationRejectedCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectionsOrientationRejectedCountValue = &v
	return s
}

// Configure the objects that should be detected.
func (s VisionMetricsImpl) Detector() *VisionDetector {
	return s.DetectorValue
}

// Configure the objects that should be detected.
func (s *VisionMetricsImpl) SetDetector(v VisionDetector) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DetectorValue = &v
	return s
}

// Identifier of the hardware device used for videoanalytics inference (if applicable)
func (s VisionMetricsImpl) DeviceID() *int {
	return s.DeviceIDValue
}

// Identifier of the hardware device used for videoanalytics inference (if applicable)
func (s *VisionMetricsImpl) SetDeviceID(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DeviceIDValue = &v
	return s
}

// Time spent on copying the input data (batch of frames) to the inference device
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) DeviceTransferTime() *Milliseconds {
	return s.DeviceTransferTimeValue
}

// Time spent on copying the input data (batch of frames) to the inference device
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetDeviceTransferTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DeviceTransferTimeValue = &v
	return s
}

// How many bytes of the input data (batch of frames) was copied to the inference device
// Format: bytes (bytes)
func (s VisionMetricsImpl) DeviceTransferredBytes() *Bytes {
	return s.DeviceTransferredBytesValue
}

// How many bytes of the input data (batch of frames) was copied to the inference device
// Format: bytes (bytes)
func (s *VisionMetricsImpl) SetDeviceTransferredBytes(v Bytes) VisionMetrics {
	if s == nil {
		return nil
	}
	s.DeviceTransferredBytesValue = &v
	return s
}

// Total minimum distance between detected object and objects in existing episodes
func (s VisionMetricsImpl) EpisodeCreationDistance() *float64 {
	return s.EpisodeCreationDistanceValue
}

// Total minimum distance between detected object and objects in existing episodes
func (s *VisionMetricsImpl) SetEpisodeCreationDistance(v float64) VisionMetrics {
	if s == nil {
		return nil
	}
	s.EpisodeCreationDistanceValue = &v
	return s
}

// Total episode creation latency.
// The latency is calculated by comparing the time of the first detection with the timestamp of the frame from which that detection came.
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) EpisodeCreationLatency() *Milliseconds {
	return s.EpisodeCreationLatencyValue
}

// Total episode creation latency.
// The latency is calculated by comparing the time of the first detection with the timestamp of the frame from which that detection came.
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetEpisodeCreationLatency(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.EpisodeCreationLatencyValue = &v
	return s
}

// Total distance between detected object and object in the existing episode that is updated
func (s VisionMetricsImpl) EpisodeUpdateDistance() *float64 {
	return s.EpisodeUpdateDistanceValue
}

// Total distance between detected object and object in the existing episode that is updated
func (s *VisionMetricsImpl) SetEpisodeUpdateDistance(v float64) VisionMetrics {
	if s == nil {
		return nil
	}
	s.EpisodeUpdateDistanceValue = &v
	return s
}

// The number of _created_ episodes
func (s VisionMetricsImpl) EpisodesCreatedCount() *int {
	return s.EpisodesCreatedCountValue
}

// The number of _created_ episodes
func (s *VisionMetricsImpl) SetEpisodesCreatedCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.EpisodesCreatedCountValue = &v
	return s
}

// Total number of detections assigned to all episodes
func (s VisionMetricsImpl) EpisodesDetectionsCount() *int {
	return s.EpisodesDetectionsCountValue
}

// Total number of detections assigned to all episodes
func (s *VisionMetricsImpl) SetEpisodesDetectionsCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.EpisodesDetectionsCountValue = &v
	return s
}

// Total duration of episodes
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) EpisodesDuration() *Milliseconds {
	return s.EpisodesDurationValue
}

// Total duration of episodes
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetEpisodesDuration(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.EpisodesDurationValue = &v
	return s
}

// Total time spent on making a decision to make a new episode or extend existing one
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) EpisodesFormingTime() *Milliseconds {
	return s.EpisodesFormingTimeValue
}

// Total time spent on making a decision to make a new episode or extend existing one
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetEpisodesFormingTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.EpisodesFormingTimeValue = &v
	return s
}

// Time spent on encoding episode previews into JPEG
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) EpisodesPreviewEncodingTime() *Milliseconds {
	return s.EpisodesPreviewEncodingTimeValue
}

// Time spent on encoding episode previews into JPEG
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetEpisodesPreviewEncodingTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.EpisodesPreviewEncodingTimeValue = &v
	return s
}

// The number of _updates_ of existing episodes
func (s VisionMetricsImpl) EpisodesUpdatedCount() *int {
	return s.EpisodesUpdatedCountValue
}

// The number of _updates_ of existing episodes
func (s *VisionMetricsImpl) SetEpisodesUpdatedCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.EpisodesUpdatedCountValue = &v
	return s
}

// Time spent on serialization of processing results (both detection and fingerprinting) to pass them into the next stage (forming the episode)
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) FingerprintSerializationTime() *Milliseconds {
	return s.FingerprintSerializationTimeValue
}

// Time spent on serialization of processing results (both detection and fingerprinting) to pass them into the next stage (forming the episode)
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetFingerprintSerializationTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.FingerprintSerializationTimeValue = &v
	return s
}

// Total time spent on fingerprinting
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) FingerprintingTime() *Milliseconds {
	return s.FingerprintingTimeValue
}

// Total time spent on fingerprinting
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetFingerprintingTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.FingerprintingTimeValue = &v
	return s
}

// Cumulative fingerprints confidence **after** filtering by confidence threshold
func (s VisionMetricsImpl) FingerprintsAcceptedConfidence() *float64 {
	return s.FingerprintsAcceptedConfidenceValue
}

// Cumulative fingerprints confidence **after** filtering by confidence threshold
func (s *VisionMetricsImpl) SetFingerprintsAcceptedConfidence(v float64) VisionMetrics {
	if s == nil {
		return nil
	}
	s.FingerprintsAcceptedConfidenceValue = &v
	return s
}

// The number of fingerprinted objects
func (s VisionMetricsImpl) FingerprintsAcceptedCount() *int {
	return s.FingerprintsAcceptedCountValue
}

// The number of fingerprinted objects
func (s *VisionMetricsImpl) SetFingerprintsAcceptedCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.FingerprintsAcceptedCountValue = &v
	return s
}

// Cumulative fingerprints confidence **before** filtering by confidence threshold
func (s VisionMetricsImpl) FingerprintsConfidence() *float64 {
	return s.FingerprintsConfidenceValue
}

// Cumulative fingerprints confidence **before** filtering by confidence threshold
func (s *VisionMetricsImpl) SetFingerprintsConfidence(v float64) VisionMetrics {
	if s == nil {
		return nil
	}
	s.FingerprintsConfidenceValue = &v
	return s
}

// Total number of fingerprinted objects
// Consists of 2 buckets: rejected by confidence and accepted fingerprints.
// Each bucket is represented by number of fingerprints in that bucket
// For each rejection reason there is a cumulative _quality_ metric for all fingerprints
// and cumulative _quality_ metric for accepted fingerprints
// For example:
// `fingerprints_confidence` is a cumulative confidence of _all_ fingerprints
// `fingerprints_accepted_confidence` is a cumulative confidence of _accepted_ fingerprints
func (s VisionMetricsImpl) FingerprintsCount() *int {
	return s.FingerprintsCountValue
}

// Total number of fingerprinted objects
// Consists of 2 buckets: rejected by confidence and accepted fingerprints.
// Each bucket is represented by number of fingerprints in that bucket
// For each rejection reason there is a cumulative _quality_ metric for all fingerprints
// and cumulative _quality_ metric for accepted fingerprints
// For example:
// `fingerprints_confidence` is a cumulative confidence of _all_ fingerprints
// `fingerprints_accepted_confidence` is a cumulative confidence of _accepted_ fingerprints
func (s *VisionMetricsImpl) SetFingerprintsCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.FingerprintsCountValue = &v
	return s
}

// Total time spent on frame preprocessing to make a batch. It includes frame resizing and chroma channels planarization, if needed
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) FramePreprocessingTime() *Milliseconds {
	return s.FramePreprocessingTimeValue
}

// Total time spent on frame preprocessing to make a batch. It includes frame resizing and chroma channels planarization, if needed
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetFramePreprocessingTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.FramePreprocessingTimeValue = &v
	return s
}

// Type of the hardware device used for videoanalytics inference
func (s VisionMetricsImpl) Hardware() *VisionHardwareType {
	return s.HardwareValue
}

// Type of the hardware device used for videoanalytics inference
func (s *VisionMetricsImpl) SetHardware(v VisionHardwareType) VisionMetrics {
	if s == nil {
		return nil
	}
	s.HardwareValue = &v
	return s
}

// Time spent on copying the processing results (both detection and fingerprinting) to the host for further postprocessing
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) HostTransferTime() *Milliseconds {
	return s.HostTransferTimeValue
}

// Time spent on copying the processing results (both detection and fingerprinting) to the host for further postprocessing
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetHostTransferTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.HostTransferTimeValue = &v
	return s
}

// How many bytes of the processing results (both detection and fingerprinting) was copied to the host for further postprocessing
// Format: bytes (bytes)
func (s VisionMetricsImpl) HostTransferredBytes() *Bytes {
	return s.HostTransferredBytesValue
}

// How many bytes of the processing results (both detection and fingerprinting) was copied to the host for further postprocessing
// Format: bytes (bytes)
func (s *VisionMetricsImpl) SetHostTransferredBytes(v Bytes) VisionMetrics {
	if s == nil {
		return nil
	}
	s.HostTransferredBytesValue = &v
	return s
}

// The number of frames that was sent by the input.
func (s VisionMetricsImpl) InputFramesCount() *int {
	return s.InputFramesCountValue
}

// The number of frames that was sent by the input.
func (s *VisionMetricsImpl) SetInputFramesCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.InputFramesCountValue = &v
	return s
}

// Unique stream name.
// Format: media_name (media_name)
// Example: cam-1
func (s VisionMetricsImpl) Media() *MediaName {
	return s.MediaValue
}

// Unique stream name.
// Format: media_name (media_name)
// Example: cam-1
func (s *VisionMetricsImpl) SetMedia(v MediaName) VisionMetrics {
	if s == nil {
		return nil
	}
	s.MediaValue = &v
	return s
}

// The number of frames that were processed by videoanalytics.
// This number may be less than `input_frames` because some input frames can be skipped depending on the hardware capabilities.
func (s VisionMetricsImpl) ProcessedFramesCount() *int {
	return s.ProcessedFramesCountValue
}

// The number of frames that were processed by videoanalytics.
// This number may be less than `input_frames` because some input frames can be skipped depending on the hardware capabilities.
func (s *VisionMetricsImpl) SetProcessedFramesCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.ProcessedFramesCountValue = &v
	return s
}

// Total number of processing errors
func (s VisionMetricsImpl) ProcessingErrorsCount() *int {
	return s.ProcessingErrorsCountValue
}

// Total number of processing errors
func (s *VisionMetricsImpl) SetProcessingErrorsCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.ProcessingErrorsCountValue = &v
	return s
}

// Total time spent on processing (includes detection and fingerprinting stages)
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) ProcessingTime() *Milliseconds {
	return s.ProcessingTimeValue
}

// Total time spent on processing (includes detection and fingerprinting stages)
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetProcessingTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.ProcessingTimeValue = &v
	return s
}

// Total delay before a received input frame being started to process.
// This delay is counted only for frames sent to videoanalytics.
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) ProcessingWaitTime() *Milliseconds {
	return s.ProcessingWaitTimeValue
}

// Total delay before a received input frame being started to process.
// This delay is counted only for frames sent to videoanalytics.
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetProcessingWaitTime(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.ProcessingWaitTimeValue = &v
	return s
}

// The number of rejected episodes.
// Episode has being rejected if it contains unsufficient number of detections or total confidence of them.
func (s VisionMetricsImpl) RejectedEpisodesCount() *int {
	return s.RejectedEpisodesCountValue
}

// The number of rejected episodes.
// Episode has being rejected if it contains unsufficient number of detections or total confidence of them.
func (s *VisionMetricsImpl) SetRejectedEpisodesCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.RejectedEpisodesCountValue = &v
	return s
}

// Total number of detections assigned to rejected episodes
func (s VisionMetricsImpl) RejectedEpisodesDetectionsCount() *int {
	return s.RejectedEpisodesDetectionsCountValue
}

// Total number of detections assigned to rejected episodes
func (s *VisionMetricsImpl) SetRejectedEpisodesDetectionsCount(v int) VisionMetrics {
	if s == nil {
		return nil
	}
	s.RejectedEpisodesDetectionsCountValue = &v
	return s
}

// Total duration of rejected episodes
// Format: milliseconds (milliseconds)
func (s VisionMetricsImpl) RejectedEpisodesDuration() *Milliseconds {
	return s.RejectedEpisodesDurationValue
}

// Total duration of rejected episodes
// Format: milliseconds (milliseconds)
func (s *VisionMetricsImpl) SetRejectedEpisodesDuration(v Milliseconds) VisionMetrics {
	if s == nil {
		return nil
	}
	s.RejectedEpisodesDurationValue = &v
	return s
}

// Hashed name of the media
// Format: uuid (uuid)
// Example: 61942420-1b2e-4614-8871-a4c6345da31f
func (s VisionMetricsImpl) SourceID() *UUID {
	return s.SourceIDValue
}

// Hashed name of the media
// Format: uuid (uuid)
// Example: 61942420-1b2e-4614-8871-a4c6345da31f
func (s *VisionMetricsImpl) SetSourceID(v UUID) VisionMetrics {
	if s == nil {
		return nil
	}
	s.SourceIDValue = &v
	return s
}

// NewVisionMetricsEpisode creates a new VisionMetricsEpisode instance
func NewVisionMetricsEpisode() VisionMetricsEpisode {
	return &VisionMetricsEpisodeImpl{}
}

// Total minimum distance between detected object and objects in existing episodes
func (s VisionMetricsEpisodeImpl) EpisodeCreationDistance() *float64 {
	return s.EpisodeCreationDistanceValue
}

// Total minimum distance between detected object and objects in existing episodes
func (s *VisionMetricsEpisodeImpl) SetEpisodeCreationDistance(v float64) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.EpisodeCreationDistanceValue = &v
	return s
}

// Total episode creation latency.
// The latency is calculated by comparing the time of the first detection with the timestamp of the frame from which that detection came.
// Format: milliseconds (milliseconds)
func (s VisionMetricsEpisodeImpl) EpisodeCreationLatency() *Milliseconds {
	return s.EpisodeCreationLatencyValue
}

// Total episode creation latency.
// The latency is calculated by comparing the time of the first detection with the timestamp of the frame from which that detection came.
// Format: milliseconds (milliseconds)
func (s *VisionMetricsEpisodeImpl) SetEpisodeCreationLatency(v Milliseconds) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.EpisodeCreationLatencyValue = &v
	return s
}

// Total distance between detected object and object in the existing episode that is updated
func (s VisionMetricsEpisodeImpl) EpisodeUpdateDistance() *float64 {
	return s.EpisodeUpdateDistanceValue
}

// Total distance between detected object and object in the existing episode that is updated
func (s *VisionMetricsEpisodeImpl) SetEpisodeUpdateDistance(v float64) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.EpisodeUpdateDistanceValue = &v
	return s
}

// The number of _created_ episodes
func (s VisionMetricsEpisodeImpl) EpisodesCreatedCount() *int {
	return s.EpisodesCreatedCountValue
}

// The number of _created_ episodes
func (s *VisionMetricsEpisodeImpl) SetEpisodesCreatedCount(v int) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.EpisodesCreatedCountValue = &v
	return s
}

// Total number of detections assigned to all episodes
func (s VisionMetricsEpisodeImpl) EpisodesDetectionsCount() *int {
	return s.EpisodesDetectionsCountValue
}

// Total number of detections assigned to all episodes
func (s *VisionMetricsEpisodeImpl) SetEpisodesDetectionsCount(v int) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.EpisodesDetectionsCountValue = &v
	return s
}

// Total duration of episodes
// Format: milliseconds (milliseconds)
func (s VisionMetricsEpisodeImpl) EpisodesDuration() *Milliseconds {
	return s.EpisodesDurationValue
}

// Total duration of episodes
// Format: milliseconds (milliseconds)
func (s *VisionMetricsEpisodeImpl) SetEpisodesDuration(v Milliseconds) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.EpisodesDurationValue = &v
	return s
}

// Total time spent on making a decision to make a new episode or extend existing one
// Format: milliseconds (milliseconds)
func (s VisionMetricsEpisodeImpl) EpisodesFormingTime() *Milliseconds {
	return s.EpisodesFormingTimeValue
}

// Total time spent on making a decision to make a new episode or extend existing one
// Format: milliseconds (milliseconds)
func (s *VisionMetricsEpisodeImpl) SetEpisodesFormingTime(v Milliseconds) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.EpisodesFormingTimeValue = &v
	return s
}

// Time spent on encoding episode previews into JPEG
// Format: milliseconds (milliseconds)
func (s VisionMetricsEpisodeImpl) EpisodesPreviewEncodingTime() *Milliseconds {
	return s.EpisodesPreviewEncodingTimeValue
}

// Time spent on encoding episode previews into JPEG
// Format: milliseconds (milliseconds)
func (s *VisionMetricsEpisodeImpl) SetEpisodesPreviewEncodingTime(v Milliseconds) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.EpisodesPreviewEncodingTimeValue = &v
	return s
}

// The number of _updates_ of existing episodes
func (s VisionMetricsEpisodeImpl) EpisodesUpdatedCount() *int {
	return s.EpisodesUpdatedCountValue
}

// The number of _updates_ of existing episodes
func (s *VisionMetricsEpisodeImpl) SetEpisodesUpdatedCount(v int) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.EpisodesUpdatedCountValue = &v
	return s
}

// The number of rejected episodes.
// Episode has being rejected if it contains unsufficient number of detections or total confidence of them.
func (s VisionMetricsEpisodeImpl) RejectedEpisodesCount() *int {
	return s.RejectedEpisodesCountValue
}

// The number of rejected episodes.
// Episode has being rejected if it contains unsufficient number of detections or total confidence of them.
func (s *VisionMetricsEpisodeImpl) SetRejectedEpisodesCount(v int) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.RejectedEpisodesCountValue = &v
	return s
}

// Total number of detections assigned to rejected episodes
func (s VisionMetricsEpisodeImpl) RejectedEpisodesDetectionsCount() *int {
	return s.RejectedEpisodesDetectionsCountValue
}

// Total number of detections assigned to rejected episodes
func (s *VisionMetricsEpisodeImpl) SetRejectedEpisodesDetectionsCount(v int) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.RejectedEpisodesDetectionsCountValue = &v
	return s
}

// Total duration of rejected episodes
// Format: milliseconds (milliseconds)
func (s VisionMetricsEpisodeImpl) RejectedEpisodesDuration() *Milliseconds {
	return s.RejectedEpisodesDurationValue
}

// Total duration of rejected episodes
// Format: milliseconds (milliseconds)
func (s *VisionMetricsEpisodeImpl) SetRejectedEpisodesDuration(v Milliseconds) VisionMetricsEpisode {
	if s == nil {
		return nil
	}
	s.RejectedEpisodesDurationValue = &v
	return s
}

// NewVisionMetricsGeneric creates a new VisionMetricsGeneric instance
func NewVisionMetricsGeneric() VisionMetricsGeneric {
	return &VisionMetricsGenericImpl{}
}

// The number of decoded frames
func (s VisionMetricsGenericImpl) DecodedFramesCount() *int {
	return s.DecodedFramesCountValue
}

// The number of decoded frames
func (s *VisionMetricsGenericImpl) SetDecodedFramesCount(v int) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.DecodedFramesCountValue = &v
	return s
}

// The number of decoding errors
func (s VisionMetricsGenericImpl) DecoderErrorsCount() *int {
	return s.DecoderErrorsCountValue
}

// The number of decoding errors
func (s *VisionMetricsGenericImpl) SetDecoderErrorsCount(v int) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.DecoderErrorsCountValue = &v
	return s
}

// How many times decoder was restarted
func (s VisionMetricsGenericImpl) DecoderRestartsCount() *int {
	return s.DecoderRestartsCountValue
}

// How many times decoder was restarted
func (s *VisionMetricsGenericImpl) SetDecoderRestartsCount(v int) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.DecoderRestartsCountValue = &v
	return s
}

// Total time spent on decoding
// Format: milliseconds (milliseconds)
func (s VisionMetricsGenericImpl) DecodingTime() *Milliseconds {
	return s.DecodingTimeValue
}

// Total time spent on decoding
// Format: milliseconds (milliseconds)
func (s *VisionMetricsGenericImpl) SetDecodingTime(v Milliseconds) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.DecodingTimeValue = &v
	return s
}

// Total time spent on frame preprocessing to make a batch. It includes frame resizing and chroma channels planarization, if needed
// Format: milliseconds (milliseconds)
func (s VisionMetricsGenericImpl) FramePreprocessingTime() *Milliseconds {
	return s.FramePreprocessingTimeValue
}

// Total time spent on frame preprocessing to make a batch. It includes frame resizing and chroma channels planarization, if needed
// Format: milliseconds (milliseconds)
func (s *VisionMetricsGenericImpl) SetFramePreprocessingTime(v Milliseconds) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.FramePreprocessingTimeValue = &v
	return s
}

// The number of frames that was sent by the input.
func (s VisionMetricsGenericImpl) InputFramesCount() *int {
	return s.InputFramesCountValue
}

// The number of frames that was sent by the input.
func (s *VisionMetricsGenericImpl) SetInputFramesCount(v int) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.InputFramesCountValue = &v
	return s
}

// The number of frames that were processed by videoanalytics.
// This number may be less than `input_frames` because some input frames can be skipped depending on the hardware capabilities.
func (s VisionMetricsGenericImpl) ProcessedFramesCount() *int {
	return s.ProcessedFramesCountValue
}

// The number of frames that were processed by videoanalytics.
// This number may be less than `input_frames` because some input frames can be skipped depending on the hardware capabilities.
func (s *VisionMetricsGenericImpl) SetProcessedFramesCount(v int) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.ProcessedFramesCountValue = &v
	return s
}

// Total number of processing errors
func (s VisionMetricsGenericImpl) ProcessingErrorsCount() *int {
	return s.ProcessingErrorsCountValue
}

// Total number of processing errors
func (s *VisionMetricsGenericImpl) SetProcessingErrorsCount(v int) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.ProcessingErrorsCountValue = &v
	return s
}

// Total time spent on processing (includes detection and fingerprinting stages)
// Format: milliseconds (milliseconds)
func (s VisionMetricsGenericImpl) ProcessingTime() *Milliseconds {
	return s.ProcessingTimeValue
}

// Total time spent on processing (includes detection and fingerprinting stages)
// Format: milliseconds (milliseconds)
func (s *VisionMetricsGenericImpl) SetProcessingTime(v Milliseconds) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.ProcessingTimeValue = &v
	return s
}

// Total delay before a received input frame being started to process.
// This delay is counted only for frames sent to videoanalytics.
// Format: milliseconds (milliseconds)
func (s VisionMetricsGenericImpl) ProcessingWaitTime() *Milliseconds {
	return s.ProcessingWaitTimeValue
}

// Total delay before a received input frame being started to process.
// This delay is counted only for frames sent to videoanalytics.
// Format: milliseconds (milliseconds)
func (s *VisionMetricsGenericImpl) SetProcessingWaitTime(v Milliseconds) VisionMetricsGeneric {
	if s == nil {
		return nil
	}
	s.ProcessingWaitTimeValue = &v
	return s
}

// NewVisionMetricsInference creates a new VisionMetricsInference instance
func NewVisionMetricsInference() VisionMetricsInference {
	return &VisionMetricsInferenceImpl{}
}

// Total time spent on detection
// Format: milliseconds (milliseconds)
func (s VisionMetricsInferenceImpl) DetectionTime() *Milliseconds {
	return s.DetectionTimeValue
}

// Total time spent on detection
// Format: milliseconds (milliseconds)
func (s *VisionMetricsInferenceImpl) SetDetectionTime(v Milliseconds) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionTimeValue = &v
	return s
}

// Cumulative detection size **after** filtering
func (s VisionMetricsInferenceImpl) DetectionsAcceptedArea() *float64 {
	return s.DetectionsAcceptedAreaValue
}

// Cumulative detection size **after** filtering
func (s *VisionMetricsInferenceImpl) SetDetectionsAcceptedArea(v float64) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionsAcceptedAreaValue = &v
	return s
}

// Cumulative detection confidence **after** filtering
func (s VisionMetricsInferenceImpl) DetectionsAcceptedConfidence() *float64 {
	return s.DetectionsAcceptedConfidenceValue
}

// Cumulative detection confidence **after** filtering
func (s *VisionMetricsInferenceImpl) SetDetectionsAcceptedConfidence(v float64) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionsAcceptedConfidenceValue = &v
	return s
}

// The number of detected objects **after** filtering
func (s VisionMetricsInferenceImpl) DetectionsAcceptedCount() *int {
	return s.DetectionsAcceptedCountValue
}

// The number of detected objects **after** filtering
func (s *VisionMetricsInferenceImpl) SetDetectionsAcceptedCount(v int) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionsAcceptedCountValue = &v
	return s
}

// Cumulative detection size (in fraction of frame area) **before** filtering
func (s VisionMetricsInferenceImpl) DetectionsArea() *float64 {
	return s.DetectionsAreaValue
}

// Cumulative detection size (in fraction of frame area) **before** filtering
func (s *VisionMetricsInferenceImpl) SetDetectionsArea(v float64) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionsAreaValue = &v
	return s
}

// Total number of detections rejected due to **size** inacceptable for fingerprinting
func (s VisionMetricsInferenceImpl) DetectionsAreaRejectedCount() *int {
	return s.DetectionsAreaRejectedCountValue
}

// Total number of detections rejected due to **size** inacceptable for fingerprinting
func (s *VisionMetricsInferenceImpl) SetDetectionsAreaRejectedCount(v int) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionsAreaRejectedCountValue = &v
	return s
}

// Cumulative detection confidences **before** filtering
func (s VisionMetricsInferenceImpl) DetectionsConfidence() *float64 {
	return s.DetectionsConfidenceValue
}

// Cumulative detection confidences **before** filtering
func (s *VisionMetricsInferenceImpl) SetDetectionsConfidence(v float64) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionsConfidenceValue = &v
	return s
}

// Total number of detections rejected due to inacceptable **confidence**
func (s VisionMetricsInferenceImpl) DetectionsConfidenceRejectedCount() *int {
	return s.DetectionsConfidenceRejectedCountValue
}

// Total number of detections rejected due to inacceptable **confidence**
func (s *VisionMetricsInferenceImpl) SetDetectionsConfidenceRejectedCount(v int) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionsConfidenceRejectedCountValue = &v
	return s
}

// Total number of detected objects.
// Consists of 4 buckets: rejected by confidence, size, orientation and accepted detections.
// Each bucket is represented by number of detections in that bucket
// For each rejection reason there is a cumulative _quality_ metric for all detections
// and cumulative _quality_ metric for accepted detections
// For example:
// `detections_confidence` is a cumulative confidence of _all_ detections
// `detections_accepted_confidence` is a cumulative confidence of _accepted_ detections
// `detections_area` is a cumulative size of _all_ detections
// `detections_accepted_area` is a cumulative size of _accepted_ detections
func (s VisionMetricsInferenceImpl) DetectionsCount() *int {
	return s.DetectionsCountValue
}

// Total number of detected objects.
// Consists of 4 buckets: rejected by confidence, size, orientation and accepted detections.
// Each bucket is represented by number of detections in that bucket
// For each rejection reason there is a cumulative _quality_ metric for all detections
// and cumulative _quality_ metric for accepted detections
// For example:
// `detections_confidence` is a cumulative confidence of _all_ detections
// `detections_accepted_confidence` is a cumulative confidence of _accepted_ detections
// `detections_area` is a cumulative size of _all_ detections
// `detections_accepted_area` is a cumulative size of _accepted_ detections
func (s *VisionMetricsInferenceImpl) SetDetectionsCount(v int) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionsCountValue = &v
	return s
}

// Total number of detections rejected due to **orientation** inacceptable for fingerprinting
func (s VisionMetricsInferenceImpl) DetectionsOrientationRejectedCount() *int {
	return s.DetectionsOrientationRejectedCountValue
}

// Total number of detections rejected due to **orientation** inacceptable for fingerprinting
func (s *VisionMetricsInferenceImpl) SetDetectionsOrientationRejectedCount(v int) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DetectionsOrientationRejectedCountValue = &v
	return s
}

// Time spent on copying the input data (batch of frames) to the inference device
// Format: milliseconds (milliseconds)
func (s VisionMetricsInferenceImpl) DeviceTransferTime() *Milliseconds {
	return s.DeviceTransferTimeValue
}

// Time spent on copying the input data (batch of frames) to the inference device
// Format: milliseconds (milliseconds)
func (s *VisionMetricsInferenceImpl) SetDeviceTransferTime(v Milliseconds) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DeviceTransferTimeValue = &v
	return s
}

// How many bytes of the input data (batch of frames) was copied to the inference device
// Format: bytes (bytes)
func (s VisionMetricsInferenceImpl) DeviceTransferredBytes() *Bytes {
	return s.DeviceTransferredBytesValue
}

// How many bytes of the input data (batch of frames) was copied to the inference device
// Format: bytes (bytes)
func (s *VisionMetricsInferenceImpl) SetDeviceTransferredBytes(v Bytes) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.DeviceTransferredBytesValue = &v
	return s
}

// Time spent on serialization of processing results (both detection and fingerprinting) to pass them into the next stage (forming the episode)
// Format: milliseconds (milliseconds)
func (s VisionMetricsInferenceImpl) FingerprintSerializationTime() *Milliseconds {
	return s.FingerprintSerializationTimeValue
}

// Time spent on serialization of processing results (both detection and fingerprinting) to pass them into the next stage (forming the episode)
// Format: milliseconds (milliseconds)
func (s *VisionMetricsInferenceImpl) SetFingerprintSerializationTime(v Milliseconds) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.FingerprintSerializationTimeValue = &v
	return s
}

// Total time spent on fingerprinting
// Format: milliseconds (milliseconds)
func (s VisionMetricsInferenceImpl) FingerprintingTime() *Milliseconds {
	return s.FingerprintingTimeValue
}

// Total time spent on fingerprinting
// Format: milliseconds (milliseconds)
func (s *VisionMetricsInferenceImpl) SetFingerprintingTime(v Milliseconds) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.FingerprintingTimeValue = &v
	return s
}

// Cumulative fingerprints confidence **after** filtering by confidence threshold
func (s VisionMetricsInferenceImpl) FingerprintsAcceptedConfidence() *float64 {
	return s.FingerprintsAcceptedConfidenceValue
}

// Cumulative fingerprints confidence **after** filtering by confidence threshold
func (s *VisionMetricsInferenceImpl) SetFingerprintsAcceptedConfidence(v float64) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.FingerprintsAcceptedConfidenceValue = &v
	return s
}

// The number of fingerprinted objects
func (s VisionMetricsInferenceImpl) FingerprintsAcceptedCount() *int {
	return s.FingerprintsAcceptedCountValue
}

// The number of fingerprinted objects
func (s *VisionMetricsInferenceImpl) SetFingerprintsAcceptedCount(v int) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.FingerprintsAcceptedCountValue = &v
	return s
}

// Cumulative fingerprints confidence **before** filtering by confidence threshold
func (s VisionMetricsInferenceImpl) FingerprintsConfidence() *float64 {
	return s.FingerprintsConfidenceValue
}

// Cumulative fingerprints confidence **before** filtering by confidence threshold
func (s *VisionMetricsInferenceImpl) SetFingerprintsConfidence(v float64) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.FingerprintsConfidenceValue = &v
	return s
}

// Total number of fingerprinted objects
// Consists of 2 buckets: rejected by confidence and accepted fingerprints.
// Each bucket is represented by number of fingerprints in that bucket
// For each rejection reason there is a cumulative _quality_ metric for all fingerprints
// and cumulative _quality_ metric for accepted fingerprints
// For example:
// `fingerprints_confidence` is a cumulative confidence of _all_ fingerprints
// `fingerprints_accepted_confidence` is a cumulative confidence of _accepted_ fingerprints
func (s VisionMetricsInferenceImpl) FingerprintsCount() *int {
	return s.FingerprintsCountValue
}

// Total number of fingerprinted objects
// Consists of 2 buckets: rejected by confidence and accepted fingerprints.
// Each bucket is represented by number of fingerprints in that bucket
// For each rejection reason there is a cumulative _quality_ metric for all fingerprints
// and cumulative _quality_ metric for accepted fingerprints
// For example:
// `fingerprints_confidence` is a cumulative confidence of _all_ fingerprints
// `fingerprints_accepted_confidence` is a cumulative confidence of _accepted_ fingerprints
func (s *VisionMetricsInferenceImpl) SetFingerprintsCount(v int) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.FingerprintsCountValue = &v
	return s
}

// Time spent on copying the processing results (both detection and fingerprinting) to the host for further postprocessing
// Format: milliseconds (milliseconds)
func (s VisionMetricsInferenceImpl) HostTransferTime() *Milliseconds {
	return s.HostTransferTimeValue
}

// Time spent on copying the processing results (both detection and fingerprinting) to the host for further postprocessing
// Format: milliseconds (milliseconds)
func (s *VisionMetricsInferenceImpl) SetHostTransferTime(v Milliseconds) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.HostTransferTimeValue = &v
	return s
}

// How many bytes of the processing results (both detection and fingerprinting) was copied to the host for further postprocessing
// Format: bytes (bytes)
func (s VisionMetricsInferenceImpl) HostTransferredBytes() *Bytes {
	return s.HostTransferredBytesValue
}

// How many bytes of the processing results (both detection and fingerprinting) was copied to the host for further postprocessing
// Format: bytes (bytes)
func (s *VisionMetricsInferenceImpl) SetHostTransferredBytes(v Bytes) VisionMetricsInference {
	if s == nil {
		return nil
	}
	s.HostTransferredBytesValue = &v
	return s
}

// NewVisionPerson creates a new VisionPerson instance
func NewVisionPerson() VisionPerson {
	return &VisionPersonImpl{}
}

// When this person was marked as deleted
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637095014573e+12
func (s VisionPersonImpl) DeletedAt() *UtcMs {
	return s.DeletedAtValue
}

// When this person was marked as deleted
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637095014573e+12
func (s *VisionPersonImpl) SetDeletedAt(v UtcMs) VisionPerson {
	if s == nil {
		return nil
	}
	s.DeletedAtValue = &v
	return s
}

// Identifier of the person in the external system.
// Use it when supplying the recognition results further into the external system
// (e.g. for access level check) if the person identifiers in the external system
// are different from the ones in Flussonic Identification database.
// This field may contain `null` when video analytics detects a new person
// which explicitly has no association in the external system (i.e. if `originator=identification_service`).
// Examples: dedcc8e8
func (s VisionPersonImpl) ExternalID() *string {
	return s.ExternalIDValue
}

// Identifier of the person in the external system.
// Use it when supplying the recognition results further into the external system
// (e.g. for access level check) if the person identifiers in the external system
// are different from the ones in Flussonic Identification database.
// This field may contain `null` when video analytics detects a new person
// which explicitly has no association in the external system (i.e. if `originator=identification_service`).
// Examples: dedcc8e8
func (s *VisionPersonImpl) SetExternalID(v string) VisionPerson {
	if s == nil {
		return nil
	}
	s.ExternalIDValue = &v
	return s
}

// Digital fingerprints of the person.
// Videoanalytics makes digital fingerprint of the person
// using uploaded photos or videostreams being processed
func (s VisionPersonImpl) Fingerprints() []VisionFaceFingerprint {
	if s.FingerprintsValue == nil {
		return nil
	}
	result := make([]VisionFaceFingerprint, len(s.FingerprintsValue))
	for i, item := range s.FingerprintsValue {
		result[i] = item
	}
	return result
}

// Digital fingerprints of the person.
// Videoanalytics makes digital fingerprint of the person
// using uploaded photos or videostreams being processed
func (s *VisionPersonImpl) SetFingerprints(v []VisionFaceFingerprint) VisionPerson {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionFaceFingerprintImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionFaceFingerprintImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.FingerprintsValue = impl
	}
	return s
}

// Indicates the way this person was created:
// manually via an api or automatically in the identification service.
func (s VisionPersonImpl) Originator() VisionPersonOriginator {
	return s.OriginatorValue
}

// Indicates the way this person was created:
// manually via an api or automatically in the identification service.
func (s *VisionPersonImpl) SetOriginator(v VisionPersonOriginator) VisionPerson {
	if s == nil {
		return nil
	}
	s.OriginatorValue = v
	return s
}

// Identifier of the person
// Format: snowflake_id (snowflake_id)
// Examples: 7.036001172460667e+18
func (s VisionPersonImpl) PersonID() SnowflakeID {
	return s.PersonIDValue
}

// Identifier of the person
// Format: snowflake_id (snowflake_id)
// Examples: 7.036001172460667e+18
func (s *VisionPersonImpl) SetPersonID(v SnowflakeID) VisionPerson {
	if s == nil {
		return nil
	}
	s.PersonIDValue = v
	return s
}

// When this person was last updated
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637034282845e+12
func (s VisionPersonImpl) UpdatedAt() UtcMs {
	return s.UpdatedAtValue
}

// When this person was last updated
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637034282845e+12
func (s *VisionPersonImpl) SetUpdatedAt(v UtcMs) VisionPerson {
	if s == nil {
		return nil
	}
	s.UpdatedAtValue = v
	return s
}

// NewVisionPersonMatch creates a new VisionPersonMatch instance
func NewVisionPersonMatch() VisionPersonMatch {
	return &VisionPersonMatchImpl{}
}

// Score of the match with person. 1.0 means absolute match
func (s VisionPersonMatchImpl) MatchScore() float64 {
	return s.MatchScoreValue
}

// Score of the match with person. 1.0 means absolute match
func (s *VisionPersonMatchImpl) SetMatchScore(v float64) VisionPersonMatch {
	if s == nil {
		return nil
	}
	s.MatchScoreValue = v
	return s
}

// Matched person
func (s VisionPersonMatchImpl) Person() VisionPerson {
	return s.PersonValue
}

// Matched person
func (s *VisionPersonMatchImpl) SetPerson(v VisionPerson) VisionPersonMatch {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionPersonImpl); ok {
		s.PersonValue = impl
	}
	return s
}

// NewVisionPoint creates a new VisionPoint instance
func NewVisionPoint() VisionPoint {
	return &VisionPointImpl{}
}

// X coordinate. Fraction of full frame width
// Examples: 0.54, 0.78
func (s VisionPointImpl) X() float64 {
	return s.XValue
}

// X coordinate. Fraction of full frame width
// Examples: 0.54, 0.78
func (s *VisionPointImpl) SetX(v float64) VisionPoint {
	if s == nil {
		return nil
	}
	s.XValue = v
	return s
}

// Y coordinate. Fraction of full frame height
// Examples: 0.12, 0.38
func (s VisionPointImpl) Y() float64 {
	return s.YValue
}

// Y coordinate. Fraction of full frame height
// Examples: 0.12, 0.38
func (s *VisionPointImpl) SetY(v float64) VisionPoint {
	if s == nil {
		return nil
	}
	s.YValue = v
	return s
}

// NewVisionProcessResult creates a new VisionProcessResult instance
func NewVisionProcessResult() VisionProcessResult {
	return &VisionProcessResultImpl{}
}

// List of detected episodes
func (s VisionProcessResultImpl) Episodes() []Episode {
	if s.EpisodesValue == nil {
		return nil
	}
	result := make([]Episode, len(s.EpisodesValue))
	for i, item := range s.EpisodesValue {
		result[i] = item
	}
	return result
}

// List of detected episodes
func (s *VisionProcessResultImpl) SetEpisodes(v []Episode) VisionProcessResult {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*EpisodeImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*EpisodeImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.EpisodesValue = impl
	}
	return s
}

// NewVisionServerDevices creates a new VisionServerDevices instance
func NewVisionServerDevices() VisionServerDevices {
	return &VisionServerDevicesImpl{}
}

// Devices list available for running vision.
func (s VisionServerDevicesImpl) Devices() []VisionDeviceInfo {
	if s.DevicesValue == nil {
		return nil
	}
	result := make([]VisionDeviceInfo, len(s.DevicesValue))
	for i, item := range s.DevicesValue {
		result[i] = item
	}
	return result
}

// Devices list available for running vision.
func (s *VisionServerDevicesImpl) SetDevices(v []VisionDeviceInfo) VisionServerDevices {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionDeviceInfoImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionDeviceInfoImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.DevicesValue = impl
	}
	return s
}

// NewVisionServerInfo creates a new VisionServerInfo instance
func NewVisionServerInfo() VisionServerInfo {
	return &VisionServerInfoImpl{}
}

// Build version
// Example: 235
func (s VisionServerInfoImpl) Build() *int {
	return s.BuildValue
}

// Build version
// Example: 235
func (s *VisionServerInfoImpl) SetBuild(v int) VisionServerInfo {
	if s == nil {
		return nil
	}
	s.BuildValue = &v
	return s
}

// Server's current timestamp
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.639337825e+12
func (s VisionServerInfoImpl) Now() *UtcMs {
	return s.NowValue
}

// Server's current timestamp
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.639337825e+12
func (s *VisionServerInfoImpl) SetNow(v UtcMs) VisionServerInfo {
	if s == nil {
		return nil
	}
	s.NowValue = &v
	return s
}

// API schema revision implemented in this version of the server
// Example: 5e5e91d8
func (s VisionServerInfoImpl) SchemaVersion() *string {
	return s.SchemaVersionValue
}

// API schema revision implemented in this version of the server
// Example: 5e5e91d8
func (s *VisionServerInfoImpl) SetSchemaVersion(v string) VisionServerInfo {
	if s == nil {
		return nil
	}
	s.SchemaVersionValue = &v
	return s
}

// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
// Format: server_version (server_version)
// Example: 21.12
func (s VisionServerInfoImpl) ServerVersion() *ServerVersion {
	return s.ServerVersionValue
}

// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
// Format: server_version (server_version)
// Example: 21.12
func (s *VisionServerInfoImpl) SetServerVersion(v ServerVersion) VisionServerInfo {
	if s == nil {
		return nil
	}
	s.ServerVersionValue = &v
	return s
}

// Timestamp when this instance was started
// Format: utc (Unix timestamp in seconds)
// Example: 1.639337825e+09
func (s VisionServerInfoImpl) StartedAt() *Utc {
	return s.StartedAtValue
}

// Timestamp when this instance was started
// Format: utc (Unix timestamp in seconds)
// Example: 1.639337825e+09
func (s *VisionServerInfoImpl) SetStartedAt(v Utc) VisionServerInfo {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}

// NewVisionSpec creates a new VisionSpec instance
func NewVisionSpec() VisionSpec {
	return &VisionSpecImpl{}
}

// The algorithm used for video analytics.
// Example: faces
func (s VisionSpecImpl) Alg() *VisionSpecAlg {
	return s.AlgValue
}

// The algorithm used for video analytics.
// Example: faces
func (s *VisionSpecImpl) SetAlg(v VisionSpecAlg) VisionSpec {
	if s == nil {
		return nil
	}
	s.AlgValue = &v
	return s
}

// This parameter allows you to select specific polygonal area(s) for detection.
// By default, it is empty, and the recognition system searches over the entire camera field of view.
// Each area is specified as a sequence of comma-separated coordinates of vertices of the polygon: `x0,y0,x1,y1,x2,y2,...`.
// The vertices are specified in a counter-clockwise direction. Multiple areas are separated by `:`.
func (s VisionSpecImpl) Areas() *string {
	return s.AreasValue
}

// This parameter allows you to select specific polygonal area(s) for detection.
// By default, it is empty, and the recognition system searches over the entire camera field of view.
// Each area is specified as a sequence of comma-separated coordinates of vertices of the polygon: `x0,y0,x1,y1,x2,y2,...`.
// The vertices are specified in a counter-clockwise direction. Multiple areas are separated by `:`.
func (s *VisionSpecImpl) SetAreas(v string) VisionSpec {
	if s == nil {
		return nil
	}
	s.AreasValue = &v
	return s
}

// Configuration of videoanalytics modules.
// This configuration supersedes `alg` and `areas` parameters.
// If this field is specified, values of `alg` and `areas` fields are being ignored.
func (s VisionSpecImpl) Detectors() []VisionDetectorConfig {
	if s.DetectorsValue == nil {
		return nil
	}
	result := make([]VisionDetectorConfig, len(s.DetectorsValue))
	for i, item := range s.DetectorsValue {
		result[i] = item
	}
	return result
}

// Configuration of videoanalytics modules.
// This configuration supersedes `alg` and `areas` parameters.
// If this field is specified, values of `alg` and `areas` fields are being ignored.
func (s *VisionSpecImpl) SetDetectors(v []VisionDetectorConfig) VisionSpec {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionDetectorConfigImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionDetectorConfigImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.DetectorsValue = impl
	}
	return s
}

// Deprecated field.
// Runtime information about the vision process.
func (s VisionSpecImpl) Stats() VisionStats {
	return s.StatsValue
}

// Deprecated field.
// Runtime information about the vision process.
func (s *VisionSpecImpl) SetStats(v VisionStats) VisionSpec {
	if s == nil {
		return nil
	}
	if impl, ok := v.(*VisionStatsImpl); ok {
		s.StatsValue = impl
	}
	return s
}

// NewVisionStats creates a new VisionStats instance
func NewVisionStats() VisionStats {
	return &VisionStatsImpl{}
}

// The time when there was the last detection. Constant updates mean that analytics can detect objects on frames.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s VisionStatsImpl) LastDetectionAt() *UtcMs {
	return s.LastDetectionAtValue
}

// The time when there was the last detection. Constant updates mean that analytics can detect objects on frames.
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.637094994e+12
func (s *VisionStatsImpl) SetLastDetectionAt(v UtcMs) VisionStats {
	if s == nil {
		return nil
	}
	s.LastDetectionAtValue = &v
	return s
}

// NewVisionVehicleAttributes creates a new VisionVehicleAttributes instance
func NewVisionVehicleAttributes() VisionVehicleAttributes {
	return &VisionVehicleAttributesImpl{}
}

// Indicates if no license plate is detected on this vehicle
func (s VisionVehicleAttributesImpl) LicensePlateMissing() *bool {
	return s.LicensePlateMissingValue
}

// Indicates if no license plate is detected on this vehicle
func (s *VisionVehicleAttributesImpl) SetLicensePlateMissing(v bool) VisionVehicleAttributes {
	if s == nil {
		return nil
	}
	s.LicensePlateMissingValue = &v
	return s
}

// The purpose of the vehicle, e.g. emergency or regular.
func (s VisionVehicleAttributesImpl) Purpose() *VisionVehiclePurpose {
	return s.PurposeValue
}

// The purpose of the vehicle, e.g. emergency or regular.
func (s *VisionVehicleAttributesImpl) SetPurpose(v VisionVehiclePurpose) VisionVehicleAttributes {
	if s == nil {
		return nil
	}
	s.PurposeValue = &v
	return s
}

// NewVisionWorkerStats creates a new VisionWorkerStats instance
func NewVisionWorkerStats() VisionWorkerStats {
	return &VisionWorkerStatsImpl{}
}

// Build version
// Example: 235
func (s VisionWorkerStatsImpl) Build() *int {
	return s.BuildValue
}

// Build version
// Example: 235
func (s *VisionWorkerStatsImpl) SetBuild(v int) VisionWorkerStats {
	if s == nil {
		return nil
	}
	s.BuildValue = &v
	return s
}

// Devices list available for running vision.
func (s VisionWorkerStatsImpl) Devices() []VisionDeviceInfo {
	if s.DevicesValue == nil {
		return nil
	}
	result := make([]VisionDeviceInfo, len(s.DevicesValue))
	for i, item := range s.DevicesValue {
		result[i] = item
	}
	return result
}

// Devices list available for running vision.
func (s *VisionWorkerStatsImpl) SetDevices(v []VisionDeviceInfo) VisionWorkerStats {
	if s == nil {
		return nil
	}
	if v != nil {
		impl := make([]*VisionDeviceInfoImpl, len(v))
		for i, item := range v {
			if itemImpl, ok := item.(*VisionDeviceInfoImpl); ok {
				impl[i] = itemImpl
			}
		}
		s.DevicesValue = impl
	}
	return s
}

// Server's current timestamp
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.639337825e+12
func (s VisionWorkerStatsImpl) Now() *UtcMs {
	return s.NowValue
}

// Server's current timestamp
// Format: utc_ms (Unix timestamp in milliseconds)
// Example: 1.639337825e+12
func (s *VisionWorkerStatsImpl) SetNow(v UtcMs) VisionWorkerStats {
	if s == nil {
		return nil
	}
	s.NowValue = &v
	return s
}

// API schema revision implemented in this version of the server
// Example: 5e5e91d8
func (s VisionWorkerStatsImpl) SchemaVersion() *string {
	return s.SchemaVersionValue
}

// API schema revision implemented in this version of the server
// Example: 5e5e91d8
func (s *VisionWorkerStatsImpl) SetSchemaVersion(v string) VisionWorkerStats {
	if s == nil {
		return nil
	}
	s.SchemaVersionValue = &v
	return s
}

// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
// Format: server_version (server_version)
// Example: 21.12
func (s VisionWorkerStatsImpl) ServerVersion() *ServerVersion {
	return s.ServerVersionValue
}

// Package version of the server. Might be simple a number of release like 21.11 or longer if you have a rolling release installed.
// Format: server_version (server_version)
// Example: 21.12
func (s *VisionWorkerStatsImpl) SetServerVersion(v ServerVersion) VisionWorkerStats {
	if s == nil {
		return nil
	}
	s.ServerVersionValue = &v
	return s
}

// Timestamp when this instance was started
// Format: utc (Unix timestamp in seconds)
// Example: 1.639337825e+09
func (s VisionWorkerStatsImpl) StartedAt() *Utc {
	return s.StartedAtValue
}

// Timestamp when this instance was started
// Format: utc (Unix timestamp in seconds)
// Example: 1.639337825e+09
func (s *VisionWorkerStatsImpl) SetStartedAt(v Utc) VisionWorkerStats {
	if s == nil {
		return nil
	}
	s.StartedAtValue = &v
	return s
}
